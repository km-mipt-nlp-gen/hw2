{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Подготовка окружения"
      ],
      "metadata": {
        "id": "H7oG_dTWfllX"
      },
      "id": "H7oG_dTWfllX"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Установка пакетов и импорт зависимостей"
      ],
      "metadata": {
        "id": "4JQkfTdQoxQK"
      },
      "id": "4JQkfTdQoxQK"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets\n",
        "!pip install pandas\n",
        "!pip install faiss-gpu\n",
        "!pip install faiss-cpu\n",
        "!pip install flask\n",
        "!pip install pyngrok\n",
        "!pip install pytest\n",
        "!pip install plotly\n",
        "!pip install optuna"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eqTb75Y-2qUS",
        "outputId": "40fa3ded-3990-4d8a-f673-9c3d92042557"
      },
      "id": "eqTb75Y-2qUS",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-2.17.1-py3-none-any.whl (536 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.7/536.7 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.13.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Collecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.20.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.4->datasets) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: dill, multiprocess, datasets\n",
            "Successfully installed datasets-2.17.1 dill-0.3.8 multiprocess-0.70.16\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.25.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
            "Collecting faiss-gpu\n",
            "  Downloading faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (85.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 MB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-gpu\n",
            "Successfully installed faiss-gpu-1.7.2\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.7.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m74.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.7.4\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.10/dist-packages (2.2.5)\n",
            "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from flask) (3.0.1)\n",
            "Requirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from flask) (3.1.3)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from flask) (2.1.2)\n",
            "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from flask) (8.1.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.0->flask) (2.1.5)\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.1.2-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.1)\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-7.1.2\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.10/dist-packages (7.4.4)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.10/dist-packages (from pytest) (2.0.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from pytest) (23.2)\n",
            "Requirement already satisfied: pluggy<2.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from pytest) (1.4.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /usr/local/lib/python3.10/dist-packages (from pytest) (1.2.0)\n",
            "Requirement already satisfied: tomli>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pytest) (2.0.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (5.15.0)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly) (8.2.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from plotly) (23.2)\n",
            "Collecting optuna\n",
            "  Downloading optuna-3.5.0-py3-none-any.whl (413 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m413.4/413.4 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.13.1-py3-none-any.whl (233 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.4/233.4 kB\u001b[0m \u001b[31m32.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.8.2-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (23.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.27)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.66.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0.1)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna)\n",
            "  Downloading Mako-1.3.2-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.9.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna) (3.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.1.5)\n",
            "Installing collected packages: Mako, colorlog, alembic, optuna\n",
            "Successfully installed Mako-1.3.2 alembic-1.13.1 colorlog-6.8.2 optuna-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "35fc1c4b-8327-4498-9b56-5f2680c93aaf",
      "metadata": {
        "id": "35fc1c4b-8327-4498-9b56-5f2680c93aaf"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import random\n",
        "from multiprocessing import cpu_count\n",
        "from getpass import getpass\n",
        "\n",
        "import logging\n",
        "\n",
        "from typing import Tuple\n",
        "from google.colab import drive\n",
        "from joblib import dump, load\n",
        "\n",
        "import faiss\n",
        "import torch\n",
        "from transformers import AutoTokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Настройка окружения"
      ],
      "metadata": {
        "id": "qbYo3xdzojRD"
      },
      "id": "qbYo3xdzojRD"
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "743P1zlT_rH2",
        "outputId": "994352b6-aa00-43dc-8e15-5f8e0f56d385"
      },
      "id": "743P1zlT_rH2",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "72b83cd8-0b5a-4228-83d8-d2315a2b19dd",
      "metadata": {
        "id": "72b83cd8-0b5a-4228-83d8-d2315a2b19dd"
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
        "dump(tokenizer, constants.TOKENIZER_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Клонирование исходных кодов проекта"
      ],
      "metadata": {
        "id": "hc3mIRiI8gu4"
      },
      "id": "hc3mIRiI8gu4"
    },
    {
      "cell_type": "code",
      "source": [
        "def clone_pull_github_src(pull: bool = True):\n",
        "    \"\"\"\n",
        "    Клонирует или обновляет репозиторий GitHub в локальный каталог для последующей работы.\n",
        "\n",
        "    Parameters:\n",
        "    pull (bool): Указывает, следует ли выполнять pull для существующего репозитория. Если True, выполняется git pull.\n",
        "                 Если False, репозиторий клонируется в указанный каталог.\n",
        "\n",
        "    Returns:\n",
        "    Constants: Экземпляр класса Constants, содержащий константы проекта.\n",
        "    \"\"\"\n",
        "    WORKSPACE_PATH = '/content/drive/MyDrive/docs/keepForever/mipt/nlp/hw1_4sem/'\n",
        "    WORKSPACE_TMP = WORKSPACE_PATH + '/tmp/'\n",
        "    GIT_HUB_PROJECT_PATH = WORKSPACE_PATH + 'code/'\n",
        "\n",
        "    token = getpass('Введите GitHub token: ')\n",
        "    repo_url = 'https://github.com/km-mipt-nlp-gen/hw1.git'\n",
        "    repo_url_with_token = repo_url.replace('https://', f'https://{token}@')\n",
        "\n",
        "    os.chdir(GIT_HUB_PROJECT_PATH)\n",
        "\n",
        "    if pull:\n",
        "        !git pull origin main\n",
        "    else:\n",
        "        !git clone {repo_url_with_token} \"$GIT_HUB_PROJECT_PATH\"\n",
        "\n",
        "    del token\n",
        "\n",
        "    sys.path.append(f\"{GIT_HUB_PROJECT_PATH}/web_app/src/\")\n",
        "    from constants_module import Constants\n",
        "\n",
        "    return Constants()\n",
        "\n",
        "constants = clone_pull_github_src()\n",
        "from constants_module import Constants\n",
        "from chat_util_module import ChatUtil"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H9sNEaZmx9uu",
        "outputId": "d63d3d03-5031-4ee9-9cca-b04b0c4ea718"
      },
      "id": "H9sNEaZmx9uu",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Введите GitHub token: ··········\n",
            "remote: Enumerating objects: 8, done.\u001b[K\n",
            "remote: Counting objects: 100% (8/8), done.\u001b[K\n",
            "remote: Compressing objects: 100% (5/5), done.\u001b[K\n",
            "remote: Total 5 (delta 1), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (5/5), 74.47 KiB | 990.00 KiB/s, done.\n",
            "From https://github.com/km-mipt-nlp-gen/hw1\n",
            " * branch            main       -> FETCH_HEAD\n",
            "   438840f..10e324f  main       -> origin/main\n",
            "Updating 438840f..10e324f\n",
            "Fast-forward\n",
            " ml/notebook/features_preprocessing_notebook.ipynb | 9415 \u001b[32m+++++++++++++++++++++++++++++++++++++++++\u001b[m\n",
            " 1 file changed, 9415 insertions(+)\n",
            " create mode 100644 ml/notebook/features_preprocessing_notebook.ipynb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Тренировка моделей и создание ембеддингов"
      ],
      "metadata": {
        "id": "Mls4VGhyGPmx"
      },
      "id": "Mls4VGhyGPmx"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Обновление модулей"
      ],
      "metadata": {
        "id": "jdivzagRbqD8"
      },
      "id": "jdivzagRbqD8"
    },
    {
      "cell_type": "code",
      "source": [
        "def reload_modules(constants: Constants) -> Tuple[Constants, ChatUtil]:\n",
        "    \"\"\"\n",
        "    Перезагружает модули проекта для обновления изменений в коде без перезапуска среды выполнения.\n",
        "\n",
        "    Parameters:\n",
        "    constants (Constants): Экземпляр класса Constants, содержащий постоянные поля.\n",
        "\n",
        "    Returns:\n",
        "    Tuple[Constants, ChatUtil]: Кортеж, содержащий обновленный экземпляр класса Constants и экземпляр ChatUtil.\n",
        "    \"\"\"\n",
        "    import sys\n",
        "    sys.path.append(f\"{constants.GIT_HUB_PROJECT_PATH}/web_app/src/\")\n",
        "    sys.path.append(f\"{constants.GIT_HUB_PROJECT_PATH}/ml/src/train/\")\n",
        "\n",
        "    import importlib\n",
        "    import chat_service_accelerator_module\n",
        "    import chat_repository_module\n",
        "    import chat_service_module\n",
        "    import chat_controller_module\n",
        "    import chat_util_module\n",
        "    import constants_module\n",
        "    import models_zoo_module\n",
        "    import siamese_bi_encoder_training_pipeline_module\n",
        "    import cross_encoder_training_pipeline_module\n",
        "\n",
        "    importlib.reload(chat_service_accelerator_module)\n",
        "    importlib.reload(chat_repository_module)\n",
        "    importlib.reload(chat_service_module)\n",
        "    importlib.reload(chat_controller_module)\n",
        "    importlib.reload(chat_util_module)\n",
        "    importlib.reload(constants_module)\n",
        "    importlib.reload(models_zoo_module)\n",
        "    importlib.reload(siamese_bi_encoder_training_pipeline_module)\n",
        "    importlib.reload(cross_encoder_training_pipeline_module)\n",
        "\n",
        "    from constants_module import Constants\n",
        "    from chat_util_module import ChatUtil\n",
        "    from chat_service_accelerator_module import ChatServiceAccelerator\n",
        "    from chat_repository_module import ChatRepository\n",
        "    from chat_service_module import ChatService\n",
        "    from chat_controller_module import ChatController\n",
        "    from siamese_bi_encoder_training_pipeline_module import SiameseBiEncoderTrainingPipeline\n",
        "    from cross_encoder_training_pipeline_module import CrossEncoderTrainingPipeline\n",
        "    from models_zoo_module import SiameseBiEncoder\n",
        "    from models_zoo_module import CrossEncoder\n",
        "\n",
        "    constants = Constants()\n",
        "\n",
        "    return constants, ChatUtil(logging.DEBUG, constants)\n",
        "\n",
        "constants, chat_util = reload_modules(constants)\n",
        "preprocessed_data = load(constants.PROCESSED_QA_PATH)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1bd28e1f-61a5-4ccc-fa66-e1dfe916c4f0",
        "id": "eMT6JF88bqEB"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DEVICE: cuda:0\n",
            "Число процессов для использования: 12\n"
          ]
        }
      ],
      "id": "eMT6JF88bqEB"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Тренировка моделей"
      ],
      "metadata": {
        "id": "wqDtVLkWV4A3"
      },
      "id": "wqDtVLkWV4A3"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Тренировка Siamese Bi-Encoder"
      ],
      "metadata": {
        "id": "Ml0M68mZRmOf"
      },
      "id": "Ml0M68mZRmOf"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Кросс-валидационный поиск в пространстве гиперпараметров Siamese-Bi-Encoder и тренировка на основе лучших"
      ],
      "metadata": {
        "id": "1iLkB_DWR_zK"
      },
      "id": "1iLkB_DWR_zK"
    },
    {
      "cell_type": "code",
      "source": [
        "best_params = SiameseBiEncoderTrainingPipeline(preprocessed_data, constants, chat_util).do_hyperparam_search(SiameseBiEncoder, n_trials=4, n_epochs=1, val_interval=32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qMSfTT13DcS6",
        "outputId": "92774575-551a-462f-85ec-59b9e353ed50"
      },
      "id": "qMSfTT13DcS6",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:chat_util_module:Старт поиска в пространстве гиперпараметров..\n",
            "[I 2024-02-25 04:52:30,855] A new study created in memory with name: no-name-6ff33eb1-a768-422a-8052-79d9e802a5f7\n",
            "INFO:chat_util_module:Поиск гиперпараметров: кросс-валидация для набора параметров \"opt_learning_rate\"=1.0029518072924353e-05; \"scheduler_type\"=linear\n",
            "INFO:chat_util_module:Поиск гиперпараметров: кросс-валидация - обучение на KFold 1\n",
            "INFO:chat_util_module:Training step     0/602, loss =  0.674\n",
            "INFO:chat_util_module:Validation step     0/602, val_loss =  0.696\n",
            "INFO:chat_util_module:Training step    32/602, loss =  0.678\n",
            "INFO:chat_util_module:Validation step    32/602, val_loss =  0.676\n",
            "INFO:chat_util_module:Training step    64/602, loss =  0.347\n",
            "INFO:chat_util_module:Validation step    64/602, val_loss =  0.314\n",
            "INFO:chat_util_module:Training step    96/602, loss =  0.136\n",
            "INFO:chat_util_module:Validation step    96/602, val_loss =  0.055\n",
            "INFO:chat_util_module:Training step   128/602, loss =  0.014\n",
            "INFO:chat_util_module:Validation step   128/602, val_loss =  0.037\n",
            "INFO:chat_util_module:Training step   160/602, loss =  0.009\n",
            "INFO:chat_util_module:Validation step   160/602, val_loss =  0.034\n",
            "INFO:chat_util_module:Training step   192/602, loss =  0.195\n",
            "INFO:chat_util_module:Validation step   192/602, val_loss =  0.034\n",
            "INFO:chat_util_module:Training step   224/602, loss =  0.139\n",
            "INFO:chat_util_module:Validation step   224/602, val_loss =  0.028\n",
            "INFO:chat_util_module:Training step   256/602, loss =  0.008\n",
            "INFO:chat_util_module:Validation step   256/602, val_loss =  0.025\n",
            "INFO:chat_util_module:Training step   288/602, loss =  0.005\n",
            "INFO:chat_util_module:Validation step   288/602, val_loss =  0.027\n",
            "INFO:chat_util_module:Training step   320/602, loss =  0.005\n",
            "INFO:chat_util_module:Validation step   320/602, val_loss =  0.023\n",
            "INFO:chat_util_module:Training step   352/602, loss =  0.004\n",
            "INFO:chat_util_module:Validation step   352/602, val_loss =  0.026\n",
            "INFO:chat_util_module:Training step   384/602, loss =  0.004\n",
            "INFO:chat_util_module:Validation step   384/602, val_loss =  0.024\n",
            "INFO:chat_util_module:Training step   416/602, loss =  0.005\n",
            "INFO:chat_util_module:Validation step   416/602, val_loss =  0.022\n",
            "INFO:chat_util_module:Training step   448/602, loss =  0.009\n",
            "INFO:chat_util_module:Validation step   448/602, val_loss =  0.021\n",
            "INFO:chat_util_module:Training step   480/602, loss =  0.004\n",
            "INFO:chat_util_module:Validation step   480/602, val_loss =  0.022\n",
            "INFO:chat_util_module:Training step   512/602, loss =  0.012\n",
            "INFO:chat_util_module:Validation step   512/602, val_loss =  0.022\n",
            "INFO:chat_util_module:Training step   544/602, loss =  0.012\n",
            "INFO:chat_util_module:Validation step   544/602, val_loss =  0.022\n",
            "INFO:chat_util_module:Training step   576/602, loss =  0.006\n",
            "INFO:chat_util_module:Validation step   576/602, val_loss =  0.022\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"cac906a9-a72a-4c76-8792-b81e38f1d77f\" class=\"plotly-graph-div\" style=\"height:600px; width:800px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"cac906a9-a72a-4c76-8792-b81e38f1d77f\")) {                    Plotly.newPlot(                        \"cac906a9-a72a-4c76-8792-b81e38f1d77f\",                        [{\"mode\":\"lines\",\"name\":\"Train batch losses\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518,519,520,521,522,523,524,525,526,527,528,529,530,531,532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549,550,551,552,553,554,555,556,557,558,559,560,561,562,563,564,565,566,567,568,569],\"y\":[0.6931973751634359,0.6933079361915588,0.6931532882153988,0.6926045715808868,0.6917521599680185,0.6902147941291332,0.6894132420420647,0.688553174957633,0.6876017209142447,0.6870093401521444,0.6838554050773382,0.68176712654531,0.6820544470101595,0.6821263879537582,0.6800713501870632,0.6776930801570415,0.676850326359272,0.6748693883419037,0.6752163488417864,0.6721282247453928,0.6690841242671013,0.6676749661564827,0.6643536482006311,0.6594493594020605,0.6544615719467402,0.6500645205378532,0.6476620882749557,0.6439300440251827,0.6375798648223281,0.6322304392233491,0.6237310012802482,0.6139145605266094,0.6050529517233372,0.5947012789547443,0.5843756683170795,0.5721135651692748,0.561111512593925,0.5481259198859334,0.5344737027771771,0.5191344036720693,0.5048661129549146,0.48913423530757427,0.4751399103552103,0.45903794560581446,0.4421245837584138,0.42378247808665037,0.4066657160874456,0.38982092565856874,0.37233804096467793,0.3591577874030918,0.34171688300557435,0.32709735189564526,0.31036562053486705,0.2924451897852123,0.2751326001016423,0.2612761278869584,0.24596442969050258,0.22992890374734998,0.2133143888786435,0.19708201952744275,0.1833297685952857,0.1678090374916792,0.15696766914334148,0.14638499659486115,0.13675427273847163,0.1301636581774801,0.11989194218767807,0.11156039871275425,0.10302614374086261,0.09662531514186412,0.09223773737903684,0.09465843846555799,0.08914742944762111,0.09136103047057986,0.0869959337869659,0.08354717999463901,0.0795848383277189,0.07665898150298744,0.07557739468757063,0.07304292445769534,0.07043580984463915,0.06433436297811568,0.06011781352572143,0.05639439556398429,0.05496700099320151,0.05428811002639122,0.0537165776186157,0.05192615746636875,0.051368369051488116,0.05055538800661452,0.04965103036374785,0.04869172794860788,0.048041053843917325,0.047569940536050126,0.04648669020389207,0.0458442579547409,0.04410720136365853,0.040309582283953205,0.03989100063336082,0.03936772755696438,0.038070490496465936,0.03697511329664849,0.03427598156849854,0.02674953851965256,0.026263820938766003,0.018716167920501903,0.018702280736761168,0.018640751484781504,0.01848869418608956,0.01839668262982741,0.017037102981703356,0.016804867889732122,0.016399300133343786,0.016119953797897324,0.015723472999525256,0.015876875768299215,0.015743071053293534,0.014648748896433972,0.01406406554451678,0.02270402958674822,0.02225057857867796,0.021987994579831138,0.02128859917866066,0.02143646834883839,0.02124111572629772,0.020774014163180254,0.020695401253760792,0.020617194662918337,0.020386208008858375,0.020230629728757776,0.02012631959223654,0.019981084173195995,0.019600228188210167,0.019516637723427266,0.019443294004304335,0.019162257754942402,0.01909105127560906,0.01899477731785737,0.018675002589588985,0.018481658727978356,0.018407429786748253,0.018292859473149292,0.01872694971098099,0.018576629503513686,0.018610838436870836,0.018719593543210067,0.025722941878484562,0.025443055186769925,0.02537294889043551,0.025241050723707303,0.025109835449256934,0.015859310631640255,0.015791777754202485,0.015777443870319985,0.02408673109312076,0.03099427955748979,0.03092511800059583,0.03100187997915782,0.030944793339585885,0.031018651730846614,0.03091535731800832,0.03671973617747426,0.036698876006994396,0.042726726533146575,0.04285161374718882,0.05066995804372709,0.05112344592635054,0.051673479334567674,0.05235599742445629,0.05724385172652546,0.05767661573190708,0.0581212664837949,0.05919328404706903,0.05937334199552424,0.05940003783325665,0.06399520419654436,0.06519277443294413,0.06549126942991279,0.05889993396704085,0.05988922256801743,0.060260838115937077,0.06054643215611577,0.060623173354542814,0.06081721623195335,0.06129806989338249,0.0669875520397909,0.05859893070010003,0.051430815961793996,0.05142316386627499,0.05134153434482869,0.05166390411613975,0.05146943635190837,0.05140226396906655,0.04966040623548906,0.04974438146746252,0.043718685119529255,0.043593352267635055,0.03582439040474128,0.0353755116375396,0.03466208673489746,0.033904031035490334,0.029203511454397812,0.02873443927092012,0.033861286225146614,0.03303331516508479,0.04019462714495603,0.03954650122614112,0.03496998464106582,0.03369758298504166,0.033281510608503595,0.03292480212985538,0.03187589131994173,0.03185598342679441,0.03183422761503607,0.031770116271218285,0.03162070576217957,0.03135756167466752,0.025699879246531054,0.02568158641224727,0.02604289274313487,0.026112969062523916,0.02627453109016642,0.025995837087975815,0.03341140136762988,0.033413637487683445,0.029308206751011312,0.029246708087157458,0.029145326683647,0.029048412965494208,0.02907529285585042,0.028967995560378768,0.028965073186554946,0.029231161170173436,0.02916091392398812,0.029190059678512625,0.023760779949952848,0.023490150226280093,0.01608912904339377,0.01607494864583714,0.01613846739201108,0.016608054495009128,0.024265780673886184,0.024189518073399086,0.024166898605471943,0.023800744405889418,0.023633048396732192,0.023627963026228826,0.024282567137561273,0.024030359672906343,0.023995015981199685,0.023975354510184843,0.023534953223133925,0.023387975561490748,0.023130274792492855,0.023103633044229355,0.015773396466101985,0.015741579372843262,0.015644436098227743,0.015474890176847111,0.01546972864161944,0.021573420286586042,0.026250310584146064,0.026243788895953912,0.02620864158961922,0.02595485615893267,0.025810954277403653,0.035350546560948715,0.03523848968325183,0.03642448612663429,0.0365332622313872,0.03654368380375672,0.03639364943956025,0.03584248079278041,0.0281998763239244,0.028234128185431473,0.038320870415191166,0.03871959907701239,0.03875337282079272,0.03879840174340643,0.05649386587901972,0.056601859323563986,0.05706492355966475,0.0573766166344285,0.05799593418487348,0.058435818675206974,0.058684049581643194,0.05863608878280502,0.05855033099942375,0.06339077903248835,0.06339232729806099,0.06430778879439458,0.06508309823402669,0.05899817089084536,0.05459213501308113,0.05456896490068175,0.05464464560645865,0.05491244523000205,0.05491755971888779,0.045726691889285576,0.045813279306457844,0.04460513467347482,0.044440381294407416,0.04457551940868143,0.0451152861060109,0.045370720894425176,0.045482756846467964,0.04569009465922136,0.035608787497039884,0.035335798253072426,0.03515981809323421,0.035064975898421835,0.016579275856202003,0.016425392328528687,0.015901065024081618,0.01563178389915265,0.02626622948446311,0.025781398406252265,0.02556393538543489,0.02547285202308558,0.025411908951355144,0.020630355138564482,0.02059858546272153,0.019681948564539198,0.018955667306727264,0.01890780473331688,0.018511143622163218,0.01855286389036337,0.01847815672226716,0.018127935829397757,0.018273485729878303,0.01790107387205353,0.017634720366913825,0.024251982787973247,0.024306577106472105,0.02423820448166225,0.023699462617514655,0.0234143507987028,0.028706812867312692,0.02901952482352499,0.028990996841457672,0.028870122318039648,0.036980244818551,0.037023856632004026,0.03709491925110342,0.03708138794900151,0.03717847511143191,0.03709995181270642,0.026118001107533928,0.026100363000296056,0.026065279977046885,0.026178023894317448,0.026246351801091805,0.026329202752094716,0.026328594780352432,0.026313315487641376,0.026212915232463274,0.026380611561762635,0.026399747068353463,0.02644414624228375,0.026606115454342216,0.02661319637991255,0.026436489286425058,0.040267754906381015,0.04031837984803133,0.03981145584839396,0.03977082412166055,0.03973101622250397,0.039812453906051815,0.03981602740532253,0.034325306696700864,0.03369294528965838,0.03378817311022431,0.035995385493151844,0.027921128217712976,0.02826519904192537,0.028388863982399926,0.02864687877445249,0.028578770281455945,0.028548214679176454,0.028355106616800185,0.03375602718733717,0.03377162560354918,0.03878891980275512,0.03886505260015838,0.038938306766794994,0.03897500588209368,0.03904339960718062,0.04262091848067939,0.04269347313675098,0.04347626643721014,0.048298411624273285,0.04812539930571802,0.048206462888629176,0.055883018649183214,0.04195869727846002,0.041962119248637464,0.036099335200560745,0.036132649511273485,0.03614673599804519,0.03611152240046067,0.036159822273475584,0.036080290032259654,0.03624020858114818,0.03639883684081724,0.03440423809661297,0.034587549867865164,0.03440487106126966,0.03696150324685732,0.037141184679057915,0.03732913667772664,0.03761373542511137,0.03752511779748602,0.032164362906769384,0.03239814840344479,0.027631471275526565,0.02770571753353579,0.027549667393031996,0.027676046353008132,0.027658170110953506,0.024173788748157676,0.023957688004884403,0.023157815805461723,0.018249765002110507,0.01826164392696228,0.018201116952695884,0.010929416006547399,0.015174541440501343,0.015167777506576385,0.015241325505485293,0.01541153102152748,0.015668281652324367,0.015894736723566893,0.01580573801038554,0.01581868505309103,0.015675723079766612,0.01539772122487193,0.015165172320848797,0.015034350704809185,0.014782314879994374,0.012118782869947609,0.011747833974368405,0.01157396051712567,0.011454183790192474,0.011454601255536545,0.011944653633690905,0.01166760407795664,0.01157892336777877,0.016502136757480912,0.016450649811304174,0.016277608476229943,0.016585902849328704,0.016699887448339723,0.021568015232332982,0.021529504636419006,0.021487977195647545,0.026477966363017913,0.026421706716064364,0.025968160065531265,0.021693388262065127,0.02177470424794592,0.02184503580792807,0.021999494201736525,0.021677443401131313,0.021379801561124623,0.021767246318631805,0.021923912936472334,0.022073250365792774,0.022117608241387643,0.022054105553252157,0.021973608592816163,0.022016298469679896,0.02204602116398746,0.022402516049623955,0.022320893265714403,0.022346636884321924,0.022296327180811204,0.021840296089067124,0.022058119349821936,0.021912353236984927,0.01679867224447662,0.016780387457401957,0.01703516465931898,0.01662720956664998,0.016583132310188375,0.01166800459031947,0.011747797645512037,0.016943129565333948,0.012010112695861608,0.012137986828747671,0.012153897361713462,0.012307792705541942,0.012183111975900829,0.011713967462128494,0.011639131706033368,0.011656148577458225,0.011664294957881793,0.01141693041427061,0.011308915942208841,0.011114076020021457,0.011255790370341856,0.011635499467956834,0.01208902096550446,0.012154222305980511,0.011994557338766754,0.01156784595514182,0.01165512201259844,0.011581593702430837,0.01163760417693993,0.011592891103646252,0.011592391303565819,0.017370715584547725,0.017611817362194415,0.017808386248361785,0.017828318530519027,0.017876401609100867,0.017711422304273583,0.017971459485124797,0.017943548009498045,0.013085059472359717,0.013137482383172028,0.01309904620575253,0.013172620412660763,0.020641618757508695,0.020714582897198852,0.02862631254538428,0.02838244142185431,0.028448885743273422,0.03655640420765849,0.036407597799552605,0.036345457745483145,0.03633186263323296,0.03642843874695245,0.03624660456262063,0.03586836846079677,0.046375522593734786,0.046573906918638386,0.046700576960574836,0.046629272794234566,0.046519053270458244,0.04647242273495067,0.046435661301075015,0.04619518561230507,0.040460015370626934,0.040157378592994064,0.03992826696776319,0.03973378357477486,0.039748239571054,0.03987006198440213,0.03978922039095778,0.03996504434326198,0.03974525397643447,0.03966665736516006,0.03993299070862122,0.039839934652263764,0.03232055644184584,0.03230893813451985,0.024400589216384105,0.024562597056501545,0.024544286789023317,0.016565743411774747,0.016598180591245182,0.016572540378547274,0.016680852153513115,0.016422106396930758,0.016452697054774035,0.016490842746861745,0.005881087912712246,0.005685507654561661,0.005565406987443566,0.005566060266573913],\"type\":\"scatter\"},{\"mode\":\"lines\",\"name\":\"Validation mean loss\",\"x\":[0,32,64,96,128,160,192,224,256,288,320,352,384,416,448,480,512],\"y\":[0.6860611806577226,0.495267676653656,0.18478204061561868,0.04620131696350068,0.035604691898304834,0.03403959895191758,0.030870940551150937,0.026322587655642167,0.025722702982254556,0.025002790723739354,0.02453050284677006,0.02480684768851766,0.022723999316398014,0.02149432910147179,0.021638670011575913,0.02174984897038995,0.021737474314265103],\"type\":\"scatter\"}],                        {\"title\":{\"text\":\"\\u041f\\u043e\\u0438\\u0441\\u043a \\u0433\\u0438\\u043f\\u0435\\u0440\\u043f\\u0430\\u0440\\u0430\\u043c\\u0435\\u0442\\u0440\\u043e\\u0432: \\u043a\\u0440\\u043e\\u0441\\u0441-\\u0432\\u0430\\u043b\\u0438\\u0434\\u0430\\u0446\\u0438\\u044f (\\\"opt_learning_rate\\\"=1.0029518072924353e-05; \\\"scheduler_type\\\"=linear, KFold=1) Siamese-Bi-Encoder: Train (per batch) and Validation (per 32 batches) Losses\"},\"xaxis\":{\"title\":{\"text\":\"Batch Number\"}},\"yaxis\":{\"title\":{\"text\":\"Train Loss (SMA)\"}},\"xaxis2\":{\"anchor\":\"y2\",\"overlaying\":\"x\",\"side\":\"top\",\"title\":{\"text\":\"Validation Interval (in Batches)\"}},\"yaxis2\":{\"overlaying\":\"y\",\"side\":\"right\",\"title\":{\"text\":\"Validation Loss\"}},\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"legend\":{\"title\":{\"text\":\"Loss Type\"}},\"height\":600,\"width\":800},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('cac906a9-a72a-4c76-8792-b81e38f1d77f');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:chat_util_module:Поиск гиперпараметров: кросс-валидация - обучение на KFold 2\n",
            "INFO:chat_util_module:Training step     0/602, loss =  0.695\n",
            "INFO:chat_util_module:Validation step     0/602, val_loss =  0.690\n",
            "INFO:chat_util_module:Training step    32/602, loss =  0.658\n",
            "INFO:chat_util_module:Validation step    32/602, val_loss =  0.673\n",
            "INFO:chat_util_module:Training step    64/602, loss =  0.370\n",
            "INFO:chat_util_module:Validation step    64/602, val_loss =  0.311\n",
            "INFO:chat_util_module:Training step    96/602, loss =  0.033\n",
            "INFO:chat_util_module:Validation step    96/602, val_loss =  0.052\n",
            "INFO:chat_util_module:Training step   128/602, loss =  0.012\n",
            "INFO:chat_util_module:Validation step   128/602, val_loss =  0.033\n",
            "INFO:chat_util_module:Training step   160/602, loss =  0.011\n",
            "INFO:chat_util_module:Validation step   160/602, val_loss =  0.029\n",
            "INFO:chat_util_module:Training step   192/602, loss =  0.009\n",
            "INFO:chat_util_module:Validation step   192/602, val_loss =  0.026\n",
            "INFO:chat_util_module:Training step   224/602, loss =  0.006\n",
            "INFO:chat_util_module:Validation step   224/602, val_loss =  0.025\n",
            "INFO:chat_util_module:Training step   256/602, loss =  0.005\n",
            "INFO:chat_util_module:Validation step   256/602, val_loss =  0.022\n",
            "INFO:chat_util_module:Training step   288/602, loss =  0.179\n",
            "INFO:chat_util_module:Validation step   288/602, val_loss =  0.023\n",
            "INFO:chat_util_module:Training step   320/602, loss =  0.010\n",
            "INFO:chat_util_module:Validation step   320/602, val_loss =  0.021\n",
            "INFO:chat_util_module:Training step   352/602, loss =  0.006\n",
            "INFO:chat_util_module:Validation step   352/602, val_loss =  0.022\n",
            "INFO:chat_util_module:Training step   384/602, loss =  0.002\n",
            "INFO:chat_util_module:Validation step   384/602, val_loss =  0.021\n",
            "INFO:chat_util_module:Training step   416/602, loss =  0.005\n",
            "INFO:chat_util_module:Validation step   416/602, val_loss =  0.021\n",
            "INFO:chat_util_module:Training step   448/602, loss =  0.008\n",
            "INFO:chat_util_module:Validation step   448/602, val_loss =  0.021\n",
            "INFO:chat_util_module:Training step   480/602, loss =  0.002\n",
            "INFO:chat_util_module:Validation step   480/602, val_loss =  0.021\n",
            "INFO:chat_util_module:Training step   512/602, loss =  0.008\n",
            "INFO:chat_util_module:Validation step   512/602, val_loss =  0.020\n",
            "INFO:chat_util_module:Training step   544/602, loss =  0.016\n",
            "INFO:chat_util_module:Validation step   544/602, val_loss =  0.020\n",
            "INFO:chat_util_module:Training step   576/602, loss =  0.004\n",
            "INFO:chat_util_module:Validation step   576/602, val_loss =  0.020\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"2d932a74-02b6-4a8f-bb64-292f0a5a4146\" class=\"plotly-graph-div\" style=\"height:600px; width:800px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"2d932a74-02b6-4a8f-bb64-292f0a5a4146\")) {                    Plotly.newPlot(                        \"2d932a74-02b6-4a8f-bb64-292f0a5a4146\",                        [{\"mode\":\"lines\",\"name\":\"Train batch losses\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518,519,520,521,522,523,524,525,526,527,528,529,530,531,532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549,550,551,552,553,554,555,556,557,558,559,560,561,562,563,564,565,566,567,568,569],\"y\":[0.6890629809349775,0.6878964118659496,0.687378216534853,0.6867585126310587,0.6857551094144583,0.6843212377279997,0.6837765872478485,0.6828068420290947,0.6821048185229301,0.6804375778883696,0.6792761944234371,0.678079828619957,0.6769099216908216,0.6754269972443581,0.6730882078409195,0.672441653907299,0.6711675841361284,0.6713548917323351,0.6692898478358984,0.6682567726820707,0.6653353478759527,0.6626036092638969,0.6579798199236393,0.6545481160283089,0.6511569935828447,0.647424902766943,0.6428525950759649,0.6376672582700849,0.6331256134435534,0.6255186898633838,0.6190781192854047,0.6107053495943546,0.6011051386594772,0.5921172183007002,0.5799413183704019,0.5694264499470592,0.5555703332647681,0.5428960816934705,0.5327077386900783,0.5208878992125392,0.506894264370203,0.49111927207559347,0.47527109924703836,0.46299705328419805,0.44925413094460964,0.4327205833978951,0.42091095028445125,0.4035339970141649,0.38620993681252,0.3672746103256941,0.35629345290362835,0.33922547148540616,0.3224259982816875,0.30576643208041787,0.29602138325572014,0.2800621469505131,0.26409236271865666,0.24838505126535892,0.23256774269975722,0.21835145843215287,0.20346339861862361,0.19039385009091347,0.17689441924449056,0.16660333645995706,0.15516173746436834,0.14461841469164938,0.13617610710207373,0.12689269392285496,0.12020013469737023,0.1133284562965855,0.10295458807377145,0.10720675642369315,0.10153829993214458,0.09744576609227806,0.09276361961383373,0.08573615743080154,0.07962936512194574,0.07669243752025068,0.0696503899525851,0.06737214687746018,0.06513486470794305,0.0629123330290895,0.05531305933254771,0.05241345023387112,0.05065454982104711,0.049007148132659495,0.04250775126274675,0.040765203069895506,0.039565481536556035,0.03870691708289087,0.03769097660551779,0.04505247899214737,0.04429075782536529,0.05002032869379036,0.0490264969994314,0.04612972497125156,0.045458583161234856,0.04478845925768837,0.04433943858020939,0.04403557983459905,0.04362382568069734,0.04317384184105322,0.043013893970055506,0.030275274912128225,0.031410504336236045,0.031196190451737493,0.031008053745608777,0.030882755090715364,0.03070250162272714,0.03050474909832701,0.03030996650340967,0.030063475656788796,0.029919112042989582,0.030001280800206587,0.029719271551584825,0.02954656901420094,0.029412521224003285,0.02922469741315581,0.028763248963514343,0.02851059741806239,0.028820854146033525,0.028603195649338886,0.02850978315109387,0.027877251210156828,0.02776024457125459,0.021283237685565837,0.029351919525652193,0.03625540751090739,0.03620227052306291,0.03619038527540397,0.036011906326166354,0.03581154796120245,0.04211083774862345,0.04202011619054247,0.04183212814677972,0.041730379991349764,0.04026985746168066,0.04009187388874125,0.040214853375800885,0.040439190619508736,0.04075755963276606,0.046485759390634485,0.04644209203252103,0.046575459084124304,0.04642194374173414,0.046206452811020426,0.0523949116904987,0.05264937200990971,0.05270652750914451,0.05314945492136758,0.05346604353690054,0.053533961370703764,0.05305454331391957,0.053057653436553665,0.05311038931540679,0.04562325820734259,0.045836570498067886,0.04579407977871597,0.041837644996121526,0.034781709269736893,0.0414006963983411,0.04134769430675078,0.04127446915663313,0.04139698237122502,0.03619218022504356,0.036103380713029765,0.03627330881136004,0.036648629829869606,0.03641727048670873,0.03646052209660411,0.0362663101113867,0.036045070068212226,0.035613468498922884,0.029790913977194577,0.029829625942511484,0.02954614066402428,0.02944311911414843,0.02945327055931557,0.02319193209405057,0.023040728294290602,0.02297856312361546,0.02242761840170715,0.023159683172707446,0.02287464585970156,0.023015288170427084,0.02286004606867209,0.02296303425100632,0.0225704576150747,0.02415123143873643,0.02424519853957463,0.02005614478548523,0.019935765289119445,0.013278150887344964,0.013185458097723313,0.013119557464960963,0.013081708020763472,0.011686504425597377,0.011812492171884514,0.011607983004068956,0.011079491021519061,0.01117087194143096,0.011062184341426473,0.01872941670444561,0.018434038262057584,0.024530435817723628,0.025712518334330525,0.02556826874933904,0.02559865434159292,0.025635641715780366,0.031810396794753615,0.03183856873511104,0.03174701358511811,0.037617373767716344,0.03768238856719108,0.03679758628277341,0.03760902545036515,0.037507530323637184,0.0378704451941303,0.03792490498017287,0.038013641991710756,0.03628651967301266,0.036243988732167054,0.036644527957832906,0.03668125051626703,0.03749675105063943,0.03743874455540208,0.03740081285650376,0.03725619401666336,0.03730418071791064,0.03736282805039082,0.0373646030202508,0.037576901355350856,0.03738979317131452,0.03739316400606185,0.029606468146084808,0.029654987185494974,0.023628458759048954,0.02240676962537691,0.02918053840403445,0.03584448096808046,0.0360294840647839,0.029743818697170354,0.02968875737860799,0.02960021533363033,0.02362338174134493,0.02356140298070386,0.02333422386436723,0.02248585755296517,0.022355088891345076,0.022335023546474986,0.022189824972883798,0.022096933680586517,0.021969759836792946,0.02181018705596216,0.021362739673350006,0.02139227850420866,0.020631781211704947,0.026094237764482386,0.03165654821350472,0.03173581713781459,0.03173368222633144,0.031543517667159904,0.03145282759942347,0.03128818222467089,0.03144066584354732,0.03154145900043659,0.03166828215762507,0.031659063723054715,0.031954425809090026,0.032032898991019465,0.02521421694109449,0.01842687179305358,0.018147395523556042,0.018013854591117706,0.018158366154239047,0.018080210844345856,0.018217146302049514,0.018273327114002313,0.018186146968218964,0.023674167699937243,0.02366996095952345,0.023343184795521665,0.02352985266043106,0.023705526888079476,0.02367770599812502,0.023845388474001084,0.023908637966087554,0.023870806056947913,0.02373241379245883,0.018433500626997557,0.012860730705142487,0.012822436321584973,0.012730073409329634,0.012741749749693554,0.012957800143340137,0.013074663460429292,0.012944335299835075,0.013117016969772521,0.012959838401002344,0.01299666325940052,0.012600000140082557,0.012390546755341347,0.012468647109926678,0.01246987422928214,0.012548982471344061,0.012545642857730854,0.01229067146050511,0.012316156826273073,0.012056182233209256,0.011988972990366165,0.012019399982818868,0.006431527181121055,0.0063057373045012355,0.006257569133595098,0.005931672531005461,0.005827890105138067,0.005847737709700596,0.005936695430136751,0.005798688864160795,0.00577766072092345,0.005833175870066043,0.005724560724047478,0.005686140058969613,0.0055745004574419,0.005566828942392021,0.005466253278427757,0.005267166372505017,0.005061321455286816,0.011155880507430993,0.01077685958443908,0.010804965473653283,0.010717468612710945,0.010634016551193781,0.010637760220561177,0.01055694223032333,0.010613443839247338,0.010723708153818734,0.010764794606075156,0.010808077531692106,0.010716170269006398,0.010840739727427717,0.010751600595540367,0.010797511218697764,0.010841031020390801,0.01097622230736306,0.018409135576803237,0.018361589492997155,0.01828309586562682,0.01818448569974862,0.01791733554273378,0.017995297923334874,0.018074534775223583,0.018201097729615867,0.018075822183163837,0.01808392325619934,0.01810748932621209,0.018212110502645373,0.018326634846744128,0.01840274326968938,0.018536926378146745,0.01835846774338279,0.018388623429927975,0.018311364292458165,0.018388364027487114,0.018479944847058505,0.01859782391693443,0.01863453196710907,0.018577977069071494,0.018370686593698338,0.01831157012929907,0.03078484870638931,0.030916885218175594,0.031003673509985674,0.031230033448082395,0.03123296840931289,0.03135191659384873,0.03136930053005926,0.02390336101234425,0.023831092068576254,0.023774123808834702,0.02382578513061162,0.023799113776476588,0.023745031277940143,0.02374904626776697,0.0291295765855466,0.02921605985466158,0.029404771528788842,0.02931849937158404,0.035113740457745735,0.035132832497765776,0.03505018512805691,0.03503702213492943,0.029114827957528178,0.02913143167097587,0.029236397436761763,0.029235793692350853,0.02922828074224526,0.029095499812683556,0.029172103510063607,0.029078334562655073,0.028993048006668687,0.028992763567657676,0.016457586556498427,0.016552752342249732,0.01638504845323041,0.016161874344106764,0.01610993960639462,0.015923224804282654,0.01594873934664065,0.016070802572357934,0.016083794173027854,0.016102855872304644,0.016094765764137264,0.016243430407484993,0.01631485906546004,0.016174536598555278,0.010665885354683269,0.010748905602667946,0.010747566331701819,0.010748669556051027,0.004912785479973536,0.004762570715683978,0.0047817784288781695,0.004661290244257543,0.004806157514394727,0.004753695029648952,0.00944546407845337,0.009474521124502644,0.009446910524275154,0.009428536679479294,0.00948338460875675,0.009487061914114747,0.009511159238172695,0.009491316435742192,0.009724132716655731,0.00958860204264056,0.00955097177211428,0.00958413119224133,0.009829937953327317,0.009953964850865304,0.015627450397005305,0.015496073312533554,0.01936922087770654,0.019338663849339355,0.019347066190675832,0.01931255598901771,0.019340555343660526,0.01944980091502657,0.01969605230988236,0.019511098511429736,0.019333172309416113,0.0193341217127454,0.019341919371072436,0.019539356992027024,0.02626990010685404,0.02640881436309428,0.026396153789391974,0.026559843488939805,0.02199722562727402,0.033323197942081606,0.03323725490554352,0.033259183412155835,0.03319513894894044,0.03321525796854985,0.03333690307408688,0.033418197086575674,0.038748690061765956,0.038916946043173084,0.04406067851596163,0.044049425228877226,0.044225298162928084,0.04430186900208355,0.03843896645048517,0.03847641050015227,0.034588060381793184,0.034789057270245394,0.03496809363787179,0.03496878798250691,0.03490936842354131,0.03553939289486152,0.03518854601497878,0.03539509254187578,0.03584758477518335,0.03590937673288863,0.035855529124091845,0.03568416756752413,0.028860558406449854,0.02886990377737675,0.0289924271783093,0.028801444754208205,0.028831358340539737,0.01738308751009754,0.01750726139653125,0.017598676287889248,0.017451467869250337,0.02236772369724349,0.02241724521809374,0.02264416159960092,0.017170564915431896,0.01709256292451755,0.012035311494400958,0.01199614638244384,0.011473563161416678,0.011275977969489759,0.011284631847956916,0.011466148844192503,0.017125688234955305,0.016935572213697014,0.016720358191378182,0.021536220006964868,0.021571132758253952,0.02082846115445136,0.020893184973829193,0.021125881914485944,0.02069237480100128,0.025218275473889662,0.025599382399377646,0.025747271454747533,0.02640401258759084,0.02644156780661433,0.026247055542626185,0.030987583493697457,0.030712400664924644,0.030840550403809175,0.0309394059877377,0.030829105970042292,0.03124426127760671,0.02636971525498666,0.026208279967249837,0.02590036139736185,0.03042868476040894,0.030296792690933216,0.030209739808924496,0.03057477792026475,0.030947201732487883,0.03095562459930079,0.030964353958552238,0.030912169320799876,0.025367274873133283,0.025437772172153927,0.025540975446347147,0.020632777828723192,0.020580210999469273,0.020607488841051236,0.020559055425110273,0.02019073741394095,0.02037069184007123,0.01618345989845693,0.015968990104738623,0.016162286541657522,0.015864769520703703,0.021825271105626598,0.022448513846029527,0.017863363013020717,0.01809185509046074,0.02217485239089001,0.022476639584056102,0.02259951629821444,0.022249296082009096,0.022328831408231054,0.02229556550446432,0.02253605506848544,0.01795900375873316,0.01792980141908629,0.018097037740517408,0.022541858546901494,0.022181745676789433,0.022274826405919157,0.029854577318474185,0.029713536219787784],\"type\":\"scatter\"},{\"mode\":\"lines\",\"name\":\"Validation mean loss\",\"x\":[0,32,64,96,128,160,192,224,256,288,320,352,384,416,448,480,512],\"y\":[0.6817644541940816,0.4922453712956652,0.1818048710125712,0.04279486145019729,0.031228362664617475,0.027283731888611475,0.025188447460276927,0.023630089718079585,0.022703131339419945,0.02212960810355681,0.021603673550902102,0.021633256950216104,0.02110774150499966,0.0207681553680032,0.020575950372588213,0.020412607668849496,0.020313582260782777],\"type\":\"scatter\"}],                        {\"title\":{\"text\":\"\\u041f\\u043e\\u0438\\u0441\\u043a \\u0433\\u0438\\u043f\\u0435\\u0440\\u043f\\u0430\\u0440\\u0430\\u043c\\u0435\\u0442\\u0440\\u043e\\u0432: \\u043a\\u0440\\u043e\\u0441\\u0441-\\u0432\\u0430\\u043b\\u0438\\u0434\\u0430\\u0446\\u0438\\u044f (\\\"opt_learning_rate\\\"=1.0029518072924353e-05; \\\"scheduler_type\\\"=linear, KFold=2) Siamese-Bi-Encoder: Train (per batch) and Validation (per 32 batches) Losses\"},\"xaxis\":{\"title\":{\"text\":\"Batch Number\"}},\"yaxis\":{\"title\":{\"text\":\"Train Loss (SMA)\"}},\"xaxis2\":{\"anchor\":\"y2\",\"overlaying\":\"x\",\"side\":\"top\",\"title\":{\"text\":\"Validation Interval (in Batches)\"}},\"yaxis2\":{\"overlaying\":\"y\",\"side\":\"right\",\"title\":{\"text\":\"Validation Loss\"}},\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"legend\":{\"title\":{\"text\":\"Loss Type\"}},\"height\":600,\"width\":800},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('2d932a74-02b6-4a8f-bb64-292f0a5a4146');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-02-25 05:05:01,329] Trial 0 finished with value: 0.020892692084228497 and parameters: {'opt_learning_rate': 1.0029518072924353e-05, 'scheduler_type': 'linear'}. Best is trial 0 with value: 0.020892692084228497.\n",
            "INFO:chat_util_module:Поиск гиперпараметров: кросс-валидация для набора параметров \"opt_learning_rate\"=7.390685482893155e-06; \"scheduler_type\"=linear\n",
            "INFO:chat_util_module:Поиск гиперпараметров: кросс-валидация - обучение на KFold 1\n",
            "INFO:chat_util_module:Training step     0/602, loss =  0.700\n",
            "INFO:chat_util_module:Validation step     0/602, val_loss =  0.694\n",
            "INFO:chat_util_module:Training step    32/602, loss =  0.683\n",
            "INFO:chat_util_module:Validation step    32/602, val_loss =  0.685\n",
            "INFO:chat_util_module:Training step    64/602, loss =  0.583\n",
            "INFO:chat_util_module:Validation step    64/602, val_loss =  0.587\n",
            "INFO:chat_util_module:Training step    96/602, loss =  0.087\n",
            "INFO:chat_util_module:Validation step    96/602, val_loss =  0.109\n",
            "INFO:chat_util_module:Training step   128/602, loss =  0.038\n",
            "INFO:chat_util_module:Validation step   128/602, val_loss =  0.060\n",
            "INFO:chat_util_module:Training step   160/602, loss =  0.020\n",
            "INFO:chat_util_module:Validation step   160/602, val_loss =  0.036\n",
            "INFO:chat_util_module:Training step   192/602, loss =  0.275\n",
            "INFO:chat_util_module:Validation step   192/602, val_loss =  0.032\n",
            "INFO:chat_util_module:Training step   224/602, loss =  0.010\n",
            "INFO:chat_util_module:Validation step   224/602, val_loss =  0.033\n",
            "INFO:chat_util_module:Training step   256/602, loss =  0.011\n",
            "INFO:chat_util_module:Validation step   256/602, val_loss =  0.029\n",
            "INFO:chat_util_module:Training step   288/602, loss =  0.013\n",
            "INFO:chat_util_module:Validation step   288/602, val_loss =  0.027\n",
            "INFO:chat_util_module:Training step   320/602, loss =  0.006\n",
            "INFO:chat_util_module:Validation step   320/602, val_loss =  0.028\n",
            "INFO:chat_util_module:Training step   352/602, loss =  0.008\n",
            "INFO:chat_util_module:Validation step   352/602, val_loss =  0.028\n",
            "INFO:chat_util_module:Training step   384/602, loss =  0.026\n",
            "INFO:chat_util_module:Validation step   384/602, val_loss =  0.024\n",
            "INFO:chat_util_module:Training step   416/602, loss =  0.009\n",
            "INFO:chat_util_module:Validation step   416/602, val_loss =  0.025\n",
            "INFO:chat_util_module:Training step   448/602, loss =  0.006\n",
            "INFO:chat_util_module:Validation step   448/602, val_loss =  0.026\n",
            "INFO:chat_util_module:Training step   480/602, loss =  0.006\n",
            "INFO:chat_util_module:Validation step   480/602, val_loss =  0.026\n",
            "INFO:chat_util_module:Training step   512/602, loss =  0.132\n",
            "INFO:chat_util_module:Validation step   512/602, val_loss =  0.026\n",
            "INFO:chat_util_module:Training step   544/602, loss =  0.008\n",
            "INFO:chat_util_module:Validation step   544/602, val_loss =  0.026\n",
            "INFO:chat_util_module:Training step   576/602, loss =  0.006\n",
            "INFO:chat_util_module:Validation step   576/602, val_loss =  0.026\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"bbbc6e04-3116-4132-ae1d-e0de3c7e9b8f\" class=\"plotly-graph-div\" style=\"height:600px; width:800px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"bbbc6e04-3116-4132-ae1d-e0de3c7e9b8f\")) {                    Plotly.newPlot(                        \"bbbc6e04-3116-4132-ae1d-e0de3c7e9b8f\",                        [{\"mode\":\"lines\",\"name\":\"Train batch losses\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518,519,520,521,522,523,524,525,526,527,528,529,530,531,532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549,550,551,552,553,554,555,556,557,558,559,560,561,562,563,564,565,566,567,568,569],\"y\":[0.694818664342165,0.6942811291664839,0.6943414751440287,0.6937665026634932,0.6939204446971416,0.6933315582573414,0.6931898836046457,0.6923838276416063,0.6911383345723152,0.6900136433541775,0.6896443478763103,0.6891688965260983,0.6881805993616581,0.6874963939189911,0.6870927792042494,0.6866792645305395,0.6866003014147282,0.685172788798809,0.6844972483813763,0.6840021014213562,0.6830553356558084,0.6813545860350132,0.6815019641071558,0.6817547976970673,0.6795515939593315,0.6772964410483837,0.6781403925269842,0.6767115108668804,0.6768552232533693,0.6749919969588518,0.6710676737129688,0.6686631701886654,0.6691355258226395,0.6660012286156416,0.6633069757372141,0.6621290668845177,0.6585415415465832,0.6561718247830868,0.6507722400128841,0.6472328323870897,0.6419177558273077,0.6382906157523394,0.6331085041165352,0.6267693070694804,0.6181141538545489,0.6094068689271808,0.6007636804133654,0.5899419710040092,0.5797047847881913,0.5686111422255635,0.5569263659417629,0.544754583388567,0.533042972907424,0.5202842690050602,0.5087832510471344,0.49290873808786273,0.47912302846089005,0.46459914837032557,0.4478172934614122,0.43570446828380227,0.4184706173837185,0.40560430381447077,0.3974704025313258,0.38232165831141174,0.364165052305907,0.34867620118893683,0.33337466954253614,0.31584200938232243,0.300250462256372,0.28446416882798076,0.2698645582422614,0.2600821256637573,0.24621655500959605,0.23042016744147986,0.2219451068667695,0.20983236085157841,0.19941427663434297,0.18848835304379463,0.17742211476434022,0.16810134006664157,0.15868616406805813,0.15100995893590152,0.14299488789401948,0.14003168209455907,0.13271473511122167,0.12621175951790065,0.11707547144033015,0.11569847003556788,0.11159012361895293,0.11317175428848714,0.10865919815842062,0.10089045175118372,0.09713760198792443,0.09184893924975768,0.08284576277947053,0.08039118623128161,0.07853764801984653,0.07699706038692966,0.07493610313395038,0.0725892580812797,0.07056168658891693,0.07524038344854489,0.0746578619000502,0.07011370157124475,0.06921423523453996,0.07414126786170527,0.0670744611416012,0.0682830682490021,0.06666937191039324,0.06624171504518017,0.065393942524679,0.06460680696181953,0.06438793579582125,0.06359765777597204,0.06299722444964573,0.05803394684335217,0.05735245568212122,0.056745609384961426,0.056138685264158994,0.051850660936906934,0.050913427490741014,0.044806404679547995,0.04458071745466441,0.044436986674554646,0.04425019695190713,0.04372188774868846,0.04331863397965208,0.042748624458909035,0.04212170804385096,0.04157473839586601,0.040986707725096494,0.04662926262244582,0.046457081072730944,0.03927601739997044,0.038161791453603655,0.0364110695081763,0.03583830138086341,0.02980325822136365,0.029420899663819,0.026238255231874064,0.03185791478608735,0.0313402718747966,0.03088720387313515,0.030975083296652883,0.03012939155451022,0.036711111111799255,0.03642403526464477,0.03707806492457166,0.04208236571867019,0.042677999939769506,0.04253049867111258,0.05015638264012523,0.0500070511479862,0.049898369470611215,0.04961914010345936,0.049331081652780995,0.04921027709497139,0.04885785179794766,0.04880193815915845,0.04915810711099766,0.05266871742787771,0.0606421013653744,0.060595282033318654,0.06020972286933102,0.06014040583977476,0.060577684111194685,0.06053448302554898,0.059517577377846465,0.059730553126428276,0.059969482594169676,0.060274370945990086,0.060500290244817734,0.05848376639187336,0.05896467043203302,0.05969568600994535,0.0595730316999834,0.06011894776020199,0.053486557852011174,0.05371954423026182,0.05308479236555286,0.04803092425572686,0.04741070358431898,0.04755488276714459,0.03990440000779927,0.039886709972051904,0.03984776942525059,0.0399741395667661,0.04024444054812193,0.040048657305305824,0.040017386665567756,0.039797551435185596,0.03933876144583337,0.04131313876132481,0.03301026203553192,0.032862987951375544,0.027350402058800682,0.034802354202838615,0.03430631713126786,0.034042190527543426,0.03387534632929601,0.03355631037265994,0.03309217977221124,0.03267589054303244,0.03229462294257246,0.028217457875143737,0.02764166204724461,0.02704406570410356,0.02679390416597016,0.026083350894623436,0.025731209650984965,0.025394587297341786,0.024952567750005983,0.024608667081338353,0.024480549691361375,0.024300852484884672,0.02432500546274241,0.025244240401661955,0.025156666888506152,0.0249271363572916,0.024605027385405265,0.02481357335636858,0.024613992471131496,0.024585766092059202,0.031352582984254695,0.02561042933666613,0.025651685151387937,0.025687483328511007,0.02554297806636896,0.024186616166844033,0.024102996874717064,0.02420026958861854,0.024244118816568516,0.024210986113757826,0.02408652832673397,0.02419246690988075,0.024224279812187888,0.024174930789740756,0.024039848110987805,0.0239178965712199,0.024261411323095672,0.02452193936915137,0.024647028127219528,0.024632703745737672,0.024524807231500745,0.024486311682267115,0.02473746144096367,0.030254954821430147,0.03008997137658298,0.029247288417536765,0.029237707291031256,0.029185507766669616,0.029135354547179304,0.03519571009383071,0.035320328272064216,0.03529337725194637,0.02844041089701932,0.028364055207930505,0.028417935856850818,0.0283436731697293,0.028263848449569196,0.02212497525033541,0.02209573582513258,0.021898074279306456,0.02175669596181251,0.021839203458512202,0.02189592702779919,0.03132720760186203,0.03134910893277265,0.03145291113469284,0.03168872409150936,0.03159236960345879,0.03116497832525056,0.030956743241404183,0.030832200558506884,0.030852045048959553,0.03084061705158092,0.030785680733970366,0.030384347090148367,0.024710199868422933,0.03340919683978427,0.03319886763347313,0.03310851915739477,0.03310062956006732,0.033209373214049265,0.026985271833837032,0.026935783738736063,0.026957124820910394,0.026849260277231224,0.02684892769320868,0.026628310908563435,0.02656183719227556,0.02660199200909119,0.026479461695998907,0.02646916755475104,0.03139328982797451,0.03126226789026987,0.031140912542468868,0.038381048405426554,0.028812868680688553,0.028761686393409036,0.028720823014737107,0.028404760072589852,0.028445326825021766,0.028476487670559436,0.028432640436221845,0.028231498959939927,0.028301382219069637,0.02839830234006513,0.0284231822588481,0.02834872150560841,0.028435357729904354,0.02018066623713821,0.02033348685654346,0.02026592061156407,0.020286319908336736,0.02018697778112255,0.020031720385304652,0.019935156320570968,0.019947646142099984,0.019889018280082382,0.019912949530407786,0.01999488624278456,0.020109783305088058,0.02015109888452571,0.020234742376487702,0.020297441631555557,0.015442211966728792,0.02375534897146281,0.023720034761936404,0.016376851097447798,0.01638231180550065,0.016317756206262857,0.0161535507068038,0.016244516329606995,0.016102364592370577,0.021844318151124753,0.02179958319175057,0.03129771594831254,0.031192456881399266,0.03104221999819856,0.03097770745807793,0.03886289529327769,0.04410881160583813,0.05139025051903445,0.051257887011161074,0.05128087868797593,0.051430301304208115,0.051345883912290446,0.051488102006260306,0.051516329651349224,0.051566319350968115,0.05169467814266682,0.051939314711489715,0.05250377986521926,0.05265707986836787,0.052670921562821604,0.05317493488837499,0.05318640718178358,0.05320159197435714,0.045270724658621475,0.04523959703510627,0.04539187693444546,0.053148957988014445,0.05368560408533085,0.05373718596820254,0.05404931765224319,0.054492298659170046,0.0488977937202435,0.04895295950700529,0.039762739586876705,0.0401079872099217,0.04010733160248492,0.04030706921184901,0.032595280979876406,0.02723567264911253,0.025192299697664566,0.025158109405310825,0.025149286855594255,0.025068605566048063,0.0251629926788155,0.02520284804631956,0.025186580343870446,0.025128395529463887,0.025175302900606766,0.024916933005442843,0.024386089120525867,0.024172970370273106,0.02422663576726336,0.023543773568235338,0.023373317082587164,0.02337160494789714,0.02310053114342736,0.023074410833942238,0.022900822797964793,0.015142001888307277,0.014975427337049041,0.014963705856644083,0.014601257928006817,0.014173142168147024,0.014228752283088397,0.014171306051139254,0.013826078233250882,0.01348152357240906,0.013568090282205958,0.013378634677792434,0.013152139748854097,0.013314679490576964,0.007506501679017674,0.0075477285354281776,0.0077566695617861114,0.007720804547716398,0.007685094278713223,0.007460279877705034,0.00758081777166808,0.007633629553311039,0.00749699031439377,0.007382404350209981,0.007278627628693357,0.007275576310348697,0.007128421508241445,0.007169189673732035,0.007306148290808778,0.007264311039762106,0.023204809804155957,0.023282438567548525,0.02329924297373509,0.02375747529004002,0.023323513385548722,0.030097843664407264,0.030126430072414223,0.030097869610472117,0.029903714887041133,0.02987302641122369,0.029907735624874476,0.029861969560442958,0.02971201124455547,0.029646494942426216,0.0295915735696326,0.029412114097794984,0.029291283593920525,0.02934151372028282,0.02907616454467643,0.02914205371052958,0.029119919461663812,0.029134372030966915,0.028969546532607637,0.028898625620058738,0.028832538839196786,0.028926194361702073,0.028931772052601445,0.02884281981823733,0.028851297836808953,0.028829461349232588,0.028724376570608,0.028882667211291846,0.012879639070888516,0.019282673390989657,0.019308381095470395,0.01882771809323458,0.01882088069396559,0.01205049107375089,0.01208263260195963,0.012154362222645432,0.012398489445331506,0.012380154425045475,0.012477123382268474,0.012581909919390455,0.012539261879283004,0.012734894015011378,0.012800788987078704,0.012781299417838454,0.012863010924775153,0.012705559558526147,0.01274473374360241,0.012579176836879924,0.012675739359110594,0.012725454056635499,0.012763487247866578,0.012864466858445667,0.012860391958383843,0.012852380503318273,0.016788464432465844,0.016852620625286363,0.016813709371490404,0.016795553048723377,0.01684033768833615,0.01667583588277921,0.01659535391809186,0.01010989800124662,0.016926690143009182,0.016996992337226402,0.017003441738779657,0.016961174696916714,0.016875892702955753,0.01692804465710651,0.016620402660919353,0.016634440151392482,0.016529419255675748,0.01643141300883144,0.016578949784161523,0.01663134922273457,0.016532230758457445,0.01654706971021369,0.016570481209782884,0.01665587205934571,0.016716246733267326,0.016707146460248623,0.01658126324036857,0.016500097583048046,0.016686305156326853,0.01645635057502659,0.016522296027687844,0.016500665900821332,0.012629948709218297,0.012625795490748715,0.012654445839871187,0.012745075386192184,0.012700151033641305,0.012699895734840538,0.0129241248650942,0.012902451839181595,0.012651379380258732,0.012773476817528717,0.012926057985168882,0.013061334582744166,0.013112614542478696,0.013070741217234172,0.013009250156756025,0.01300268401246285,0.013023801417148206,0.013018696183280554,0.012916880667035002,0.0126342297080555,0.012670327931118663,0.012677480066486169,0.012778179392626043,0.012768940687237773,0.012810822801839095,0.012805097430828027,0.012803836521925405,0.012805785110685974,0.012554905406432226,0.012636587220185902,0.012555981338664424,0.012737360993924085,0.012664841742662247,0.01281205552368192,0.012883814859378617,0.012817256538255606,0.012856860346801113,0.013529643147194292,0.013416098801826593,0.013422007941699121,0.006836807988293003,0.006608824020077009,0.006474074652942363,0.006369960181473289,0.006409099332813639,0.006307486437435728,0.00638701806019526,0.0063968649628805,0.006406057305866852,0.006417191601940431,0.006453442401834764,0.006552457271027379,0.006537449327879585,0.013318079829332419,0.013232411438366398,0.013256442281999625,0.013223850779468194],\"type\":\"scatter\"},{\"mode\":\"lines\",\"name\":\"Validation mean loss\",\"x\":[0,32,64,96,128,160,192,224,256,288,320,352,384,416,448,480,512],\"y\":[0.6890456429450615,0.635782371699018,0.3481873031024917,0.08472228300389509,0.04822520662154817,0.03426467259553728,0.032767785480439335,0.031311656905150975,0.028256970929195394,0.02782158849067039,0.028045890888197665,0.025897461390339358,0.024324175945608456,0.025158727914501022,0.025695520240145944,0.02570278085849443,0.025911043368785046],\"type\":\"scatter\"}],                        {\"title\":{\"text\":\"\\u041f\\u043e\\u0438\\u0441\\u043a \\u0433\\u0438\\u043f\\u0435\\u0440\\u043f\\u0430\\u0440\\u0430\\u043c\\u0435\\u0442\\u0440\\u043e\\u0432: \\u043a\\u0440\\u043e\\u0441\\u0441-\\u0432\\u0430\\u043b\\u0438\\u0434\\u0430\\u0446\\u0438\\u044f (\\\"opt_learning_rate\\\"=7.390685482893155e-06; \\\"scheduler_type\\\"=linear, KFold=1) Siamese-Bi-Encoder: Train (per batch) and Validation (per 32 batches) Losses\"},\"xaxis\":{\"title\":{\"text\":\"Batch Number\"}},\"yaxis\":{\"title\":{\"text\":\"Train Loss (SMA)\"}},\"xaxis2\":{\"anchor\":\"y2\",\"overlaying\":\"x\",\"side\":\"top\",\"title\":{\"text\":\"Validation Interval (in Batches)\"}},\"yaxis2\":{\"overlaying\":\"y\",\"side\":\"right\",\"title\":{\"text\":\"Validation Loss\"}},\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"legend\":{\"title\":{\"text\":\"Loss Type\"}},\"height\":600,\"width\":800},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('bbbc6e04-3116-4132-ae1d-e0de3c7e9b8f');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:chat_util_module:Поиск гиперпараметров: кросс-валидация - обучение на KFold 2\n",
            "INFO:chat_util_module:Training step     0/602, loss =  0.725\n",
            "INFO:chat_util_module:Validation step     0/602, val_loss =  0.705\n",
            "INFO:chat_util_module:Training step    32/602, loss =  0.702\n",
            "INFO:chat_util_module:Validation step    32/602, val_loss =  0.690\n",
            "INFO:chat_util_module:Training step    64/602, loss =  0.605\n",
            "INFO:chat_util_module:Validation step    64/602, val_loss =  0.606\n",
            "INFO:chat_util_module:Training step    96/602, loss =  0.119\n",
            "INFO:chat_util_module:Validation step    96/602, val_loss =  0.123\n",
            "INFO:chat_util_module:Training step   128/602, loss =  0.025\n",
            "INFO:chat_util_module:Validation step   128/602, val_loss =  0.061\n",
            "INFO:chat_util_module:Training step   160/602, loss =  0.018\n",
            "INFO:chat_util_module:Validation step   160/602, val_loss =  0.053\n",
            "INFO:chat_util_module:Training step   192/602, loss =  0.019\n",
            "INFO:chat_util_module:Validation step   192/602, val_loss =  0.048\n",
            "INFO:chat_util_module:Training step   224/602, loss =  0.012\n",
            "INFO:chat_util_module:Validation step   224/602, val_loss =  0.046\n",
            "INFO:chat_util_module:Training step   256/602, loss =  0.014\n",
            "INFO:chat_util_module:Validation step   256/602, val_loss =  0.038\n",
            "INFO:chat_util_module:Training step   288/602, loss =  0.013\n",
            "INFO:chat_util_module:Validation step   288/602, val_loss =  0.040\n",
            "INFO:chat_util_module:Training step   320/602, loss =  0.012\n",
            "INFO:chat_util_module:Validation step   320/602, val_loss =  0.034\n",
            "INFO:chat_util_module:Training step   352/602, loss =  0.007\n",
            "INFO:chat_util_module:Validation step   352/602, val_loss =  0.034\n",
            "INFO:chat_util_module:Training step   384/602, loss =  0.005\n",
            "INFO:chat_util_module:Validation step   384/602, val_loss =  0.027\n",
            "INFO:chat_util_module:Training step   416/602, loss =  0.008\n",
            "INFO:chat_util_module:Validation step   416/602, val_loss =  0.027\n",
            "INFO:chat_util_module:Training step   448/602, loss =  0.293\n",
            "INFO:chat_util_module:Validation step   448/602, val_loss =  0.025\n",
            "INFO:chat_util_module:Training step   480/602, loss =  0.004\n",
            "INFO:chat_util_module:Validation step   480/602, val_loss =  0.026\n",
            "INFO:chat_util_module:Training step   512/602, loss =  0.013\n",
            "INFO:chat_util_module:Validation step   512/602, val_loss =  0.025\n",
            "INFO:chat_util_module:Training step   544/602, loss =  0.218\n",
            "INFO:chat_util_module:Validation step   544/602, val_loss =  0.025\n",
            "INFO:chat_util_module:Training step   576/602, loss =  0.014\n",
            "INFO:chat_util_module:Validation step   576/602, val_loss =  0.025\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"9831aa43-9a8c-4ecd-a025-1bbc9e3f688b\" class=\"plotly-graph-div\" style=\"height:600px; width:800px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"9831aa43-9a8c-4ecd-a025-1bbc9e3f688b\")) {                    Plotly.newPlot(                        \"9831aa43-9a8c-4ecd-a025-1bbc9e3f688b\",                        [{\"mode\":\"lines\",\"name\":\"Train batch losses\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518,519,520,521,522,523,524,525,526,527,528,529,530,531,532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549,550,551,552,553,554,555,556,557,558,559,560,561,562,563,564,565,566,567,568,569],\"y\":[0.6982595026493073,0.69755544885993,0.6967321690171957,0.6962399147450924,0.6954251807183027,0.6959335450083017,0.6940250061452389,0.6940830033272505,0.6938110738992691,0.6939508374780416,0.6927367635071278,0.6921942066401243,0.6930872276425362,0.6930737365037203,0.693186491727829,0.6921788118779659,0.6910249274224043,0.6900007259100676,0.6893942765891552,0.6894837636500597,0.688443111255765,0.6877214256674051,0.6865784246474504,0.6851120516657829,0.6842088960111141,0.6833677943795919,0.6819917652755976,0.680897019803524,0.6805649884045124,0.6799092572182417,0.6781861484050751,0.6759342141449451,0.6749704964458942,0.6719176694750786,0.6705337483435869,0.6677728909999132,0.6642574481666088,0.6603454016149044,0.6572332475334406,0.651785297319293,0.6467980798333883,0.6405878933146596,0.6340207261964679,0.6270365277305245,0.6203733645379543,0.6133775021880865,0.6032380610704422,0.592389221303165,0.5845117531716824,0.573289766907692,0.5616131760179996,0.5492940982803702,0.5369349895045161,0.524741904810071,0.512004497461021,0.49950042366981506,0.4845768050290644,0.4707506336271763,0.4565195990726352,0.4406256037764251,0.4278811910189688,0.4125136248767376,0.39698116946965456,0.3812478806357831,0.36981143499724567,0.3546415497548878,0.3386404514312744,0.3228935617953539,0.30739384051412344,0.29239668720401824,0.2767082890495658,0.26319701317697763,0.24981297459453344,0.2363900898490101,0.22327734529972076,0.21047550975345075,0.1968055812176317,0.18650621990673244,0.17597431421745569,0.16691867425106466,0.15536672063171864,0.14718133013229817,0.13880060450173914,0.13053678185679018,0.12356872903183103,0.11628434422891587,0.10942192014772445,0.10300345486029983,0.09802731883246452,0.0924487718148157,0.08699254086241126,0.08319493068847805,0.07539499824633822,0.07088966871378943,0.0677427114569582,0.06498407397884876,0.056522500060964376,0.05358257418265566,0.0507022071396932,0.055981060839258134,0.053881188679952174,0.05168854334624484,0.050075960461981595,0.06355349079240113,0.060801547951996326,0.05924810917349532,0.057994364586193115,0.05643811507616192,0.05542058061109856,0.051599516795249656,0.05078173536458053,0.049919982644496486,0.048996157333021984,0.04854085881379433,0.05492852992028929,0.05423191739828326,0.053510827594436705,0.0527243884280324,0.06408547866158187,0.0708936502924189,0.07032523036468774,0.06975276235607453,0.06949823800823651,0.06898885514237918,0.06875175461755134,0.08198958417051472,0.08181955790496431,0.08168835463584401,0.08143746384303086,0.08122191866277717,0.08118088086484931,0.07351679701241665,0.0734808775887359,0.07359380947309546,0.07355887020821683,0.0576997495663818,0.06375389356981032,0.06371525532449596,0.06363507127389312,0.06376268161693588,0.0638321106089279,0.0639775822928641,0.07031699703657068,0.07850929812411778,0.07841039902996272,0.07802330353297293,0.07087623176630586,0.07080085619236343,0.07214876415673643,0.07231402973411605,0.06052570918109268,0.05306351976469159,0.053223646187689155,0.05336191793321632,0.06130471537471749,0.061376625642878935,0.0612406317377463,0.04784452525200322,0.04757683794014156,0.04747010482242331,0.054210464644711465,0.05424310837406665,0.054033087682910264,0.053986569109838456,0.05392381420824677,0.05364760186057538,0.05367383733391762,0.054828189779073,0.056639970280230045,0.05660410545533523,0.05654969430179335,0.05634263655520044,0.0560314578760881,0.05588016175897792,0.0493379341205582,0.04122742818435654,0.04113017479539849,0.04100333122187294,0.040993568632984534,0.047975347901228815,0.051576924917753786,0.05138283089036122,0.05114158851210959,0.05087463770178147,0.05902209223131649,0.06748362854705192,0.059359251987189054,0.05909680901095271,0.05924487629090436,0.05915251359692775,0.06863943286589347,0.06879273502272554,0.0620180873083882,0.06178020455990918,0.0684970962756779,0.06826705206185579,0.06825713513535447,0.06823241672827862,0.0680985045619309,0.0669305546907708,0.059331752883736044,0.05923244942096062,0.06504126361687668,0.06520584222744219,0.07088568669860251,0.07112645520828664,0.0711297904199455,0.07108537666499615,0.07826053514145315,0.07902436348376796,0.07898378410027362,0.07209983156644739,0.067392223427305,0.06749223251244985,0.06732561183162034,0.06731905287597328,0.05914499843493104,0.05069423868553713,0.050680303684202954,0.05087212784565054,0.05086542366188951,0.050689616589806974,0.04117705623502843,0.04103297524852678,0.04105928310309537,0.04111825383733958,0.04021730867680162,0.04038576452876441,0.0403283029445447,0.04505504068220034,0.0450417730899062,0.04500836395891383,0.04466115930699743,0.049603393708821386,0.049238533654715866,0.04903810445102863,0.043651439977111295,0.04367089763400145,0.043683692754711956,0.05206128329155035,0.04498632127069868,0.04412594944005832,0.04425318821449764,0.044031185447238386,0.043658424430759624,0.043462643545353785,0.04348496362217702,0.04331505068694241,0.04323481777100824,0.043065425008535385,0.04295860233833082,0.04292050548247062,0.04271932243136689,0.04270177538273856,0.042655314202420413,0.042617657920345664,0.042625064379535615,0.0425946204632055,0.04056417613173835,0.040342089312616736,0.042474521324038506,0.037650436512194574,0.03761731387930922,0.03769507782999426,0.03934028357616626,0.03435619318042882,0.028852229414042085,0.02877496730070561,0.028530444746138528,0.02807157571078278,0.02804649359313771,0.019616904464783147,0.019372906172065996,0.019392494883504696,0.02502357390767429,0.025016175597556867,0.03099919376836624,0.03106089618813712,0.031131312120123766,0.031860791830695234,0.03153767735057045,0.0313980527134845,0.03128550518886186,0.031007564393803477,0.030856379700708203,0.03077574681083206,0.03094898162817117,0.030846611902234145,0.030778182335780002,0.030748863689950667,0.026895696893916465,0.027084351153462194,0.02501734574616421,0.024971656312118284,0.024888840285711922,0.024582011450547725,0.022774032957386225,0.02277201783726923,0.022836431919131428,0.022811374452430755,0.022744485118892044,0.02270301993121393,0.022515311051392928,0.02255711075849831,0.023058361883158796,0.0230250177992275,0.017262090943404473,0.017152271830127575,0.011106695033959113,0.010949127885396592,0.010798052098834887,0.01011229315190576,0.010387046029791236,0.010344564521801658,0.010472406371263787,0.010484562866622582,0.010491580658708699,0.010496252929442562,0.010201328419498168,0.01028725078504067,0.010148751534870826,0.010005583200836554,0.009992137929657474,0.009714810352306813,0.009828213340369985,0.00975437622400932,0.009670805695350282,0.018650972400791943,0.018764637381536886,0.018933698040200397,0.018751467927359045,0.018760071572614834,0.018778860016027465,0.018876727524911985,0.018910443352069706,0.020481839776039124,0.01995999058999587,0.019925765649531968,0.019714038629899733,0.019693221736815758,0.019701530851307325,0.019780409449595027,0.019793746585492045,0.019662739839986898,0.01934142214304302,0.01929857858340256,0.01917465717997402,0.019132384317344986,0.019237348533351906,0.019088573928456753,0.019083636347204447,0.01893469264905434,0.018892813663114794,0.01883118014666252,0.01875348316389136,0.01875825581373647,0.0183955994725693,0.018392604586551897,0.018357299763010815,0.009402996802236885,0.00921365586691536,0.008971656352514401,0.008881229136022739,0.008779430107097141,0.00881679575832095,0.00872967837494798,0.008675989578478038,0.006814885826315731,0.006829590245615691,0.006793590364395641,0.0067452074436005205,0.006753512367140502,0.0072008196148090065,0.007158874737797305,0.007195922953542322,0.007243427433422767,0.007242610023240559,0.007285230065463111,0.007226202622405253,0.007118380584870465,0.00695982453180477,0.0069382719084387645,0.012496388939325698,0.01253554991853889,0.0125051074574003,0.012605943324160762,0.012566266828798689,0.012639563487027772,0.012656471008085646,0.012720622413326055,0.020229116140399128,0.020142751556704752,0.020053860993357375,0.020039589537191205,0.020240087585989386,0.027144260122440755,0.027024847382563166,0.02701871127646882,0.026980814698617905,0.027142876526340842,0.02736249471490737,0.027366385984350927,0.02743865874072071,0.033297039815806784,0.03274450798926409,0.03262671000265982,0.03869511750235688,0.038629249451332726,0.03867417979927268,0.03879646272980608,0.03883203743316699,0.0439344436454121,0.044242816875339486,0.044478299518232234,0.038968783235759474,0.03905571860377677,0.03899695151631022,0.047906856903864536,0.04789107829128625,0.04783236348157516,0.04804327003512299,0.04799492184974952,0.04056312356988201,0.04060070757259382,0.04064069806918269,0.04067646200564923,0.041155317339871544,0.034279504798178095,0.03465887624042807,0.03465513258561259,0.034670870467380155,0.03508793866058113,0.03490030888497131,0.039873416993941646,0.040034794837993104,0.03440491806395585,0.034625137988768984,0.034768480581988115,0.028836628778662998,0.028819450693845283,0.028995491644309368,0.028801994638342876,0.0377032313044765,0.03264622959977714,0.03331079769850476,0.03315038230357459,0.033060237918107305,0.0330177039213595,0.03325054232846014,0.024215366749558598,0.02441116829868406,0.03308887789899018,0.032834500627359375,0.03291815082775429,0.03282368159852922,0.03284020580758806,0.03288721007993445,0.03300545806996524,0.03720900713233277,0.037212681854725815,0.03676901018479839,0.036825714123551734,0.036814720049733296,0.03648015795624815,0.03661053514224477,0.03212680961587466,0.03198218384932261,0.031762197191710584,0.03188296545704361,0.03212570601317566,0.03191956953378394,0.032037072189268656,0.03196075999585446,0.03219222143525258,0.023439425218384713,0.023431485489709303,0.022618639952270314,0.02745687947026454,0.034116325157810934,0.034061637401464395,0.042563021488604136,0.04284017394820694,0.04266044858377427,0.03402154447394423,0.03417020993947517,0.03434728832507972,0.034464022814063355,0.034386524581350386,0.03440969862276688,0.03436497788061388,0.03588810985093005,0.03589453261520248,0.035905241820728406,0.0357826648541959,0.035866996680852026,0.035606525460025296,0.03540047771821264,0.035001743483007886,0.034960784803843126,0.0349657578044571,0.03476437527569942,0.039575538743520156,0.03950678573164623,0.03936324263486313,0.03932147517480189,0.03916273668437498,0.03929112971673021,0.03945446240686579,0.04638182900816901,0.04157807637966471,0.03499354785162723,0.03531784278311534,0.026790744384925347,0.03318269779992988,0.03338741660263622,0.03325587185827317,0.03330343063134933,0.03306034325942164,0.03308753889723448,0.033156063880596776,0.03318708524602698,0.033157176403619815,0.026877703821810428,0.026958691516483668,0.026951148589432705,0.027004503361240495,0.026921606688119937,0.027045383882068563,0.02712610476737609,0.027133781077282038,0.02716903216060018,0.02713775580195943,0.02727676273934776,0.022351677594997454,0.02244253672688501,0.022608686282183044,0.022574642338440754,0.022613550754613243,0.022319767420412973,0.02216772393148858,0.015106838181964122,0.01505160506349057,0.015196144973742776,0.014999251856352203,0.014932688252883963,0.008572238803026266,0.009156674743280746,0.009247756766853854,0.009102839772822335,0.009386259349412285,0.009662404845585115,0.009724590039695613,0.014194215254974551,0.014226723185856827,0.01573119945533108,0.015610750750056468,0.015754583888337947,0.015826079121325165,0.01582372719713021,0.015805741932126693,0.015968626059475355,0.01594922957883682,0.015893803283688612,0.0158748455287423,0.015672357272705995,0.015464648167835549,0.015359730110503733,0.01521480992960278,0.015266158690792508,0.015419757823110558],\"type\":\"scatter\"},{\"mode\":\"lines\",\"name\":\"Validation mean loss\",\"x\":[0,32,64,96,128,160,192,224,256,288,320,352,384,416,448,480,512],\"y\":[0.6977717826433751,0.6482795384833187,0.36480379436301236,0.092161733114108,0.0571255930080589,0.050868907252224496,0.047252820261701495,0.041866604715239175,0.03888824562529764,0.03705360950550925,0.033750509529179615,0.03049399008788014,0.02702359270545781,0.025605906346585428,0.02512648102283583,0.025222626045203932,0.024653739542460557],\"type\":\"scatter\"}],                        {\"title\":{\"text\":\"\\u041f\\u043e\\u0438\\u0441\\u043a \\u0433\\u0438\\u043f\\u0435\\u0440\\u043f\\u0430\\u0440\\u0430\\u043c\\u0435\\u0442\\u0440\\u043e\\u0432: \\u043a\\u0440\\u043e\\u0441\\u0441-\\u0432\\u0430\\u043b\\u0438\\u0434\\u0430\\u0446\\u0438\\u044f (\\\"opt_learning_rate\\\"=7.390685482893155e-06; \\\"scheduler_type\\\"=linear, KFold=2) Siamese-Bi-Encoder: Train (per batch) and Validation (per 32 batches) Losses\"},\"xaxis\":{\"title\":{\"text\":\"Batch Number\"}},\"yaxis\":{\"title\":{\"text\":\"Train Loss (SMA)\"}},\"xaxis2\":{\"anchor\":\"y2\",\"overlaying\":\"x\",\"side\":\"top\",\"title\":{\"text\":\"Validation Interval (in Batches)\"}},\"yaxis2\":{\"overlaying\":\"y\",\"side\":\"right\",\"title\":{\"text\":\"Validation Loss\"}},\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"legend\":{\"title\":{\"text\":\"Loss Type\"}},\"height\":600,\"width\":800},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('9831aa43-9a8c-4ecd-a025-1bbc9e3f688b');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-02-25 05:17:31,892] Trial 1 finished with value: 0.024327071058715496 and parameters: {'opt_learning_rate': 7.390685482893155e-06, 'scheduler_type': 'linear'}. Best is trial 0 with value: 0.020892692084228497.\n",
            "INFO:chat_util_module:Поиск гиперпараметров: кросс-валидация для набора параметров \"opt_learning_rate\"=1.4634158668829792e-05; \"scheduler_type\"=cosine\n",
            "INFO:chat_util_module:Поиск гиперпараметров: кросс-валидация - обучение на KFold 1\n",
            "INFO:chat_util_module:Training step     0/602, loss =  0.707\n",
            "INFO:chat_util_module:Validation step     0/602, val_loss =  0.704\n",
            "INFO:chat_util_module:Training step    32/602, loss =  0.645\n",
            "INFO:chat_util_module:Validation step    32/602, val_loss =  0.673\n",
            "INFO:chat_util_module:Training step    64/602, loss =  0.114\n",
            "INFO:chat_util_module:Validation step    64/602, val_loss =  0.115\n",
            "INFO:chat_util_module:Training step    96/602, loss =  0.028\n",
            "INFO:chat_util_module:Validation step    96/602, val_loss =  0.040\n",
            "INFO:chat_util_module:Training step   128/602, loss =  0.008\n",
            "INFO:chat_util_module:Validation step   128/602, val_loss =  0.042\n",
            "INFO:chat_util_module:Training step   160/602, loss =  0.007\n",
            "INFO:chat_util_module:Validation step   160/602, val_loss =  0.027\n",
            "INFO:chat_util_module:Training step   192/602, loss =  0.046\n",
            "INFO:chat_util_module:Validation step   192/602, val_loss =  0.037\n",
            "INFO:chat_util_module:Training step   224/602, loss =  0.004\n",
            "INFO:chat_util_module:Validation step   224/602, val_loss =  0.028\n",
            "INFO:chat_util_module:Training step   256/602, loss =  0.002\n",
            "INFO:chat_util_module:Validation step   256/602, val_loss =  0.022\n",
            "INFO:chat_util_module:Training step   288/602, loss =  0.004\n",
            "INFO:chat_util_module:Validation step   288/602, val_loss =  0.023\n",
            "INFO:chat_util_module:Training step   320/602, loss =  0.004\n",
            "INFO:chat_util_module:Validation step   320/602, val_loss =  0.022\n",
            "INFO:chat_util_module:Training step   352/602, loss =  0.002\n",
            "INFO:chat_util_module:Validation step   352/602, val_loss =  0.023\n",
            "INFO:chat_util_module:Training step   384/602, loss =  0.003\n",
            "INFO:chat_util_module:Validation step   384/602, val_loss =  0.022\n",
            "INFO:chat_util_module:Training step   416/602, loss =  0.003\n",
            "INFO:chat_util_module:Validation step   416/602, val_loss =  0.020\n",
            "INFO:chat_util_module:Training step   448/602, loss =  0.002\n",
            "INFO:chat_util_module:Validation step   448/602, val_loss =  0.020\n",
            "INFO:chat_util_module:Training step   480/602, loss =  0.002\n",
            "INFO:chat_util_module:Validation step   480/602, val_loss =  0.020\n",
            "INFO:chat_util_module:Training step   512/602, loss =  0.010\n",
            "INFO:chat_util_module:Validation step   512/602, val_loss =  0.020\n",
            "INFO:chat_util_module:Training step   544/602, loss =  0.002\n",
            "INFO:chat_util_module:Validation step   544/602, val_loss =  0.020\n",
            "INFO:chat_util_module:Training step   576/602, loss =  0.010\n",
            "INFO:chat_util_module:Validation step   576/602, val_loss =  0.020\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"60ca62c9-44b5-4a15-adc0-194cd4244996\" class=\"plotly-graph-div\" style=\"height:600px; width:800px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"60ca62c9-44b5-4a15-adc0-194cd4244996\")) {                    Plotly.newPlot(                        \"60ca62c9-44b5-4a15-adc0-194cd4244996\",                        [{\"mode\":\"lines\",\"name\":\"Train batch losses\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518,519,520,521,522,523,524,525,526,527,528,529,530,531,532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549,550,551,552,553,554,555,556,557,558,559,560,561,562,563,564,565,566,567,568,569],\"y\":[0.6964208800345659,0.6944939531385899,0.6933155432343483,0.6946643348783255,0.6942473445087671,0.6933785378932953,0.6917887590825558,0.6891049668192863,0.6873747948557138,0.6854271162301302,0.6835455857217312,0.681485028937459,0.6793492622673512,0.6761742271482944,0.6739212516695261,0.6719171274453402,0.6673071924597025,0.664270531386137,0.6586728654801846,0.6537014171481133,0.648652633652091,0.643540732562542,0.6354158231988549,0.6278456710278988,0.6187965394929051,0.6077109631150961,0.6000919053331017,0.5884889969602227,0.5745353484526277,0.5591366705484688,0.5429944577626884,0.5265235649421811,0.5079174702987075,0.49131714715622365,0.4778562586288899,0.45965237938798964,0.4413455384783447,0.4218210044782609,0.40306104079354554,0.3882266852306202,0.36899764847476035,0.35076907044276595,0.33178833022248,0.3132370465900749,0.2972089247778058,0.2821676661260426,0.26398503745440394,0.24531813169596717,0.2280263039865531,0.20990977867040783,0.19434313953388482,0.17765634731040336,0.17122417819336988,0.1557475776935462,0.14262694932403974,0.13752539988490753,0.13164281166973524,0.1249730400450062,0.11254688416374847,0.10365611402085051,0.09645075065782294,0.09088467858964577,0.08624739712104201,0.08234898064984009,0.07916570804081857,0.07649543887237087,0.06944486452266574,0.07420888636261225,0.07223688677186146,0.07106607651803643,0.0697167806501966,0.06469460154767148,0.06388467925717123,0.062477602245053276,0.06906810982036404,0.06836715945973992,0.06531756554613821,0.061251402425114065,0.060687018441967666,0.06215806008549407,0.06198242146638222,0.06190974419587292,0.06188053198275156,0.0620842365315184,0.05253965003066696,0.052265330916270614,0.052102013112744316,0.04328581326990388,0.04246118021546863,0.03905748117540497,0.038969609784544446,0.03882517594320234,0.03835367904684972,0.038030396986869164,0.03780571361130569,0.03730199018900748,0.03683546440151986,0.036214596024365164,0.03571785186068155,0.02796185130137019,0.027289283054415137,0.027188395528355613,0.02726164081832394,0.026395738605060615,0.026121291564777493,0.02595751007902436,0.018470603070454672,0.018259349875734188,0.018080416732118465,0.017797315973439254,0.01765984285157174,0.015630995214451104,0.015360878358478658,0.014992312819231302,0.01597402460174635,0.015423711520270444,0.015230392236844636,0.015055800104164518,0.014850108374957927,0.014548739723977633,0.009206924485624768,0.009213108729454689,0.009143921139184386,0.009046684295753948,0.01718402023834642,0.017051493021426722,0.0167085767025128,0.01655250934709329,0.0186349426076049,0.01859221667109523,0.01862524528405629,0.018444811154040508,0.018365716183325276,0.024884857644792646,0.024598069707280956,0.024913442466640845,0.024874818351236172,0.024755285296123475,0.024658230671775527,0.02480006084078923,0.024842969243763946,0.025069656010600738,0.02504898700863123,0.025095884135225788,0.02521365824213717,0.025218005903298035,0.028181036963360384,0.0282440807641251,0.028101084011723287,0.02817475401388947,0.028294483126956038,0.0283327021606965,0.028393689877702855,0.02845098960096948,0.03441034820571076,0.03770401768269949,0.029546109406510368,0.029929401542176493,0.03590908301703166,0.03620076019433327,0.03481536710751243,0.03603371750796214,0.03735001201857813,0.03800925602263305,0.03806157290819101,0.031660012929933146,0.03187201595574152,0.03153803299937863,0.03173406723362859,0.031802211044123396,0.031753486138768494,0.03159401650191285,0.031572403328027576,0.03130054630310042,0.0314510461394093,0.03138702606520383,0.031207380387058947,0.03113092519924976,0.02668043621815741,0.0270352638035547,0.027016867577913217,0.026863654122280423,0.026702101800765377,0.026641009986633435,0.0266467525070766,0.026516844183788635,0.020591247550328262,0.017290546456933953,0.01720384154759813,0.016865700599737465,0.010827018631971441,0.010470383160281926,0.00959535212314222,0.008276548483991064,0.006820854323450476,0.023640920931939036,0.023508358557592146,0.023097574114217423,0.022842512567876838,0.022865863400511444,0.022694768907967955,0.022582355872145854,0.02269427920691669,0.02262036229512887,0.022537079094036017,0.022666396354907192,0.022414018443669192,0.022433748774346896,0.022579502372536808,0.022698318563925568,0.02263899993704399,0.022181702028319705,0.022184527515491936,0.0221844261905062,0.02221808200556552,0.022281120574916713,0.022220709259272553,0.022192648088093847,0.022232344781514257,0.022283089987467974,0.02227943149046041,0.022192909898876678,0.022282406433077995,0.022304464713670313,0.022322412456560414,0.022271888657996897,0.022251370006415527,0.004703483231423888,0.004777672053023707,0.004688330729550216,0.004634088349121157,0.004543435679806862,0.004404574152431451,0.004438167699845508,0.004288978401746135,0.004263753929990344,0.004239642759785056,0.0040785073942970484,0.004090698043000884,0.003980477726145182,0.003822798033070285,0.003698358115798328,0.0036672662463388406,0.0036879594990750775,0.003707044685143046,0.003671478436444886,0.003747035123524256,0.003710236182087101,0.003761797008337453,0.003742167478776537,0.0035879036295227706,0.003525451335008256,0.0034045621287077665,0.0034699927564361133,0.010502524273761082,0.01049371570115909,0.010588751152681652,0.010652819801180158,0.010720372847572435,0.01704470501135802,0.01693391253866139,0.016924730196478777,0.017005313027766533,0.01706694977474399,0.017240841807506513,0.023606494614796247,0.023608445830177516,0.023807408462744206,0.0239353159267921,0.028209746757056564,0.028247550377273,0.02825071469123941,0.02827119695575675,0.028724857307679486,0.028746569725626614,0.028927695399033837,0.028892914473544806,0.02906417195481481,0.02913776697096182,0.02911928114190232,0.029316648418898694,0.03160231110814493,0.03176702046766877,0.03188287213561125,0.04083710011036601,0.040871976962080225,0.034060906822560355,0.03411948728899006,0.03431336104404181,0.034288876377104316,0.03440433755895356,0.028172492668090854,0.02830746730978717,0.028665030375123024,0.02868760999990627,0.028651042754063383,0.028562409337610006,0.022099942030763486,0.022101173741248203,0.021973870094370795,0.021995265557052335,0.01772216054450837,0.017825313148932764,0.01783922003596672,0.017804768274800153,0.017439993393054465,0.01743819666808122,0.022946099172258982,0.022986327840044396,0.030889553196175257,0.03068275466284831,0.03071123067275039,0.030469940229522763,0.02819814026224776,0.02815914887105464,0.027994334228424123,0.019030133364140056,0.019012957549421117,0.018693255828111432,0.018616206718434114,0.018342029907216784,0.01828611385280965,0.018364620649663266,0.018266220482473727,0.018142495784559287,0.01787741329462733,0.017783033261366654,0.017986436148930807,0.01787946706463117,0.018023679567704676,0.018022169027972268,0.01800364516748232,0.01787399284876301,0.01802313360167318,0.017946648604265647,0.01801799334862153,0.018213834195194067,0.01821156364530907,0.01819581273230142,0.012454069354134845,0.012574681171827251,0.004645857410650933,0.004773255222971784,0.004701697242126102,0.004714422615506919,0.00466096592208487,0.0184787189537019,0.01846799304621527,0.018787571829307126,0.023575335453642765,0.023586953302583424,0.02374656344545656,0.02376843145248131,0.02381400562808267,0.023582098536280682,0.02372961974106147,0.023931416511913994,0.029773423597362125,0.034326636563491775,0.03425888913261588,0.034368663113127695,0.034301196898013586,0.039019739069772186,0.039155124035460176,0.04401743379639811,0.04445649508488714,0.044421076479920885,0.044295236013567774,0.04410268821447971,0.04415707659427426,0.04414977491614991,0.04446014471977833,0.044242409658181714,0.04439773537524161,0.044271233291510725,0.04497577839720179,0.045371914504357846,0.04901450575925992,0.03500408744366723,0.03501853560010204,0.03471189006086206,0.030107937280263286,0.030325585074024275,0.03417993517359719,0.03420413717685733,0.03420557425124571,0.034168684207543265,0.034497352309699636,0.03450452643301105,0.028782177912944462,0.02452604858990526,0.02431233078823425,0.024269806199299637,0.024254405572719406,0.019959027813456487,0.023381415048788767,0.01851768357300898,0.018261002107465174,0.01836604925483698,0.0183601299613656,0.01845693515133462,0.018297453825653065,0.01865205050125951,0.01832902825117344,0.01902068709023297,0.018838389150914736,0.018813862232491374,0.018482909857993945,0.018171656207414344,0.014562662407115567,0.014684670342830941,0.019257154111983255,0.01926918474782724,0.019060972190345638,0.02217068632307928,0.01824408800166566,0.018168490467360243,0.018141065302188508,0.01812124059506459,0.017641052880208008,0.017557019877131097,0.017569806790561415,0.017359799283440225,0.01735791923420038,0.0173905092451605,0.02004324309382355,0.01959381219057832,0.02226327838434372,0.02239256202301476,0.02241385965317022,0.02226547210739227,0.022718982207152294,0.022658560093987035,0.02314539718645392,0.022954921885684598,0.026483515895961318,0.02581796245794976,0.025919264960975852,0.02598982479685219,0.026184217749687377,0.026036731898784637,0.02613206652313238,0.026010748311819043,0.02198068433062872,0.02199161130556604,0.022740309497748967,0.01951186604128452,0.01963179218728328,0.019832069832773414,0.019826080933853518,0.020316720903792884,0.020377575856400654,0.020253227165085264,0.02027251930849161,0.020514982388704084,0.020557216703309678,0.02085211504891049,0.0182581902918173,0.01857210767775541,0.012309044184803497,0.012502713820140343,0.012349912045465317,0.012357093757600524,0.011932221226743422,0.011884913648827933,0.011401158102671616,0.011228854004002642,0.008138169585436117,0.008295537663798314,0.008085948960797396,0.008058355153480079,0.007527628309617285,0.007809289832948707,0.007745493989204988,0.008184817095752805,0.007912690081866458,0.00827183437650092,0.007461995686753653,0.01149358635302633,0.011512326105730608,0.011359243566403165,0.01161662356753368,0.011566724992007948,0.012318229550146498,0.016799525183159858,0.01685662244562991,0.016529682849068195,0.01650687650544569,0.016104871378047392,0.0159891485091066,0.015680776501540095,0.022442448214860633,0.02210699655552162,0.021861151108168997,0.022174753845320083,0.02238742022018414,0.0225727917131735,0.022619333321927115,0.02301259962405311,0.022585645376238972,0.02244411550782388,0.02251277457253309,0.022484776854980737,0.022763505097827874,0.022755725905881263,0.022698214033880504,0.022523661977174925,0.0222303047812602,0.021840601330040954,0.0218397582648322,0.023505917168222368,0.026385803561424837,0.026667824800824746,0.026411455997731537,0.034286451584193856,0.03367518959566951,0.03783313278108835,0.04277527015074156,0.043049330823123455,0.04308346370089566,0.04318083762336755,0.04318483208771795,0.0433227159519447,0.03677245271683205,0.03677916500600986,0.03705603871640051,0.03673390406038379,0.03650794801797019,0.03645602118194802,0.0363956425608194,0.036019798022607574,0.03603065188872279,0.03598192538265721,0.03590742147207493,0.036098576994845644,0.03578685245884117,0.03550455869844882,0.0356604283915658,0.03539592191737029,0.03547211073964718,0.04818327762768604,0.04842998328967951,0.04285645778873004,0.039848247935879044,0.039502898980572354,0.03973979426518781,0.031418871563801076,0.031263323697203305,0.022712806945492048,0.01768888295191573,0.017473429841629695,0.017448712031182367,0.018049215686914977,0.01860323482833337,0.018993356512510218,0.019052523610298522,0.019065252359723672,0.018895486457040533,0.01888023063656874,0.019074964584433474,0.022276547795627266,0.022282403442659415,0.02228656486113323,0.022518043318996206,0.022548087996256072,0.02265828679446713,0.02266089743716293,0.030711422576132463,0.030688134207593976,0.031149929676757893],\"type\":\"scatter\"},{\"mode\":\"lines\",\"name\":\"Validation mean loss\",\"x\":[0,32,64,96,128,160,192,224,256,288,320,352,384,416,448,480,512],\"y\":[0.6884747435187184,0.3940617772673204,0.077325354984256,0.04078731139285638,0.0342756890917299,0.031807579753566156,0.03236139186089812,0.025094894243174532,0.022812190583156363,0.022747701270599767,0.022685313152932124,0.02261515355762172,0.0213123328450149,0.02032077100229074,0.020195982384629257,0.02010381657144239,0.02006238881921886],\"type\":\"scatter\"}],                        {\"title\":{\"text\":\"\\u041f\\u043e\\u0438\\u0441\\u043a \\u0433\\u0438\\u043f\\u0435\\u0440\\u043f\\u0430\\u0440\\u0430\\u043c\\u0435\\u0442\\u0440\\u043e\\u0432: \\u043a\\u0440\\u043e\\u0441\\u0441-\\u0432\\u0430\\u043b\\u0438\\u0434\\u0430\\u0446\\u0438\\u044f (\\\"opt_learning_rate\\\"=1.4634158668829792e-05; \\\"scheduler_type\\\"=cosine, KFold=1) Siamese-Bi-Encoder: Train (per batch) and Validation (per 32 batches) Losses\"},\"xaxis\":{\"title\":{\"text\":\"Batch Number\"}},\"yaxis\":{\"title\":{\"text\":\"Train Loss (SMA)\"}},\"xaxis2\":{\"anchor\":\"y2\",\"overlaying\":\"x\",\"side\":\"top\",\"title\":{\"text\":\"Validation Interval (in Batches)\"}},\"yaxis2\":{\"overlaying\":\"y\",\"side\":\"right\",\"title\":{\"text\":\"Validation Loss\"}},\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"legend\":{\"title\":{\"text\":\"Loss Type\"}},\"height\":600,\"width\":800},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('60ca62c9-44b5-4a15-adc0-194cd4244996');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:chat_util_module:Поиск гиперпараметров: кросс-валидация - обучение на KFold 2\n",
            "INFO:chat_util_module:Training step     0/602, loss =  0.716\n",
            "INFO:chat_util_module:Validation step     0/602, val_loss =  0.695\n",
            "INFO:chat_util_module:Training step    32/602, loss =  0.713\n",
            "INFO:chat_util_module:Validation step    32/602, val_loss =  0.667\n",
            "INFO:chat_util_module:Training step    64/602, loss =  0.256\n",
            "INFO:chat_util_module:Validation step    64/602, val_loss =  0.130\n",
            "INFO:chat_util_module:Training step    96/602, loss =  0.047\n",
            "INFO:chat_util_module:Validation step    96/602, val_loss =  0.079\n",
            "INFO:chat_util_module:Training step   128/602, loss =  0.011\n",
            "INFO:chat_util_module:Validation step   128/602, val_loss =  0.054\n",
            "INFO:chat_util_module:Training step   160/602, loss =  0.035\n",
            "INFO:chat_util_module:Validation step   160/602, val_loss =  0.024\n",
            "INFO:chat_util_module:Training step   192/602, loss =  0.006\n",
            "INFO:chat_util_module:Validation step   192/602, val_loss =  0.027\n",
            "INFO:chat_util_module:Training step   224/602, loss =  0.007\n",
            "INFO:chat_util_module:Validation step   224/602, val_loss =  0.024\n",
            "INFO:chat_util_module:Training step   256/602, loss =  0.002\n",
            "INFO:chat_util_module:Validation step   256/602, val_loss =  0.026\n",
            "INFO:chat_util_module:Training step   288/602, loss =  0.002\n",
            "INFO:chat_util_module:Validation step   288/602, val_loss =  0.023\n",
            "INFO:chat_util_module:Training step   320/602, loss =  0.003\n",
            "INFO:chat_util_module:Validation step   320/602, val_loss =  0.022\n",
            "INFO:chat_util_module:Training step   352/602, loss =  0.011\n",
            "INFO:chat_util_module:Validation step   352/602, val_loss =  0.023\n",
            "INFO:chat_util_module:Training step   384/602, loss =  0.004\n",
            "INFO:chat_util_module:Validation step   384/602, val_loss =  0.023\n",
            "INFO:chat_util_module:Training step   416/602, loss =  0.001\n",
            "INFO:chat_util_module:Validation step   416/602, val_loss =  0.022\n",
            "INFO:chat_util_module:Training step   448/602, loss =  0.018\n",
            "INFO:chat_util_module:Validation step   448/602, val_loss =  0.022\n",
            "INFO:chat_util_module:Training step   480/602, loss =  0.010\n",
            "INFO:chat_util_module:Validation step   480/602, val_loss =  0.022\n",
            "INFO:chat_util_module:Training step   512/602, loss =  0.014\n",
            "INFO:chat_util_module:Validation step   512/602, val_loss =  0.022\n",
            "INFO:chat_util_module:Training step   544/602, loss =  0.008\n",
            "INFO:chat_util_module:Validation step   544/602, val_loss =  0.022\n",
            "INFO:chat_util_module:Training step   576/602, loss =  0.010\n",
            "INFO:chat_util_module:Validation step   576/602, val_loss =  0.022\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"853d8f77-60fb-4c14-9f5c-16cd3d251a7b\" class=\"plotly-graph-div\" style=\"height:600px; width:800px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"853d8f77-60fb-4c14-9f5c-16cd3d251a7b\")) {                    Plotly.newPlot(                        \"853d8f77-60fb-4c14-9f5c-16cd3d251a7b\",                        [{\"mode\":\"lines\",\"name\":\"Train batch losses\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518,519,520,521,522,523,524,525,526,527,528,529,530,531,532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549,550,551,552,553,554,555,556,557,558,559,560,561,562,563,564,565,566,567,568,569],\"y\":[0.6865237392485142,0.686425045132637,0.6872888244688511,0.6891384143382311,0.6890955120325089,0.6881166063249111,0.6866885144263506,0.6858656946569681,0.6854580845683813,0.6852439250797033,0.6817798893898726,0.68027263879776,0.6777513939887285,0.6762075889855623,0.6732428800314665,0.6706841848790646,0.6684142742305994,0.6632789615541697,0.6594116520136595,0.6539776399731636,0.6468625627458096,0.6424537748098373,0.6325577422976494,0.6252582427114248,0.6148165250197053,0.6034222282469273,0.5916789416223764,0.5780648826621473,0.5650827740319073,0.5509862350299954,0.5397343207150698,0.5230952729471028,0.5083497571758926,0.4940788126550615,0.47986697498708963,0.45987875084392726,0.4411213987041265,0.4228363879956305,0.40442125126719475,0.3858776041306555,0.3702065022662282,0.3561475188471377,0.3427967829629779,0.3243143199943006,0.30585192993748933,0.28815178701188415,0.27043405338190496,0.2522502130595967,0.23453703080303967,0.22279571858234704,0.20605352998245507,0.1915244017727673,0.1776075200177729,0.16126626057666726,0.15034648278378882,0.141350283898646,0.1319289528473746,0.13514851915533654,0.1264158619742375,0.11997308701393194,0.11140032697585411,0.11307513320934959,0.10502100668963976,0.10063768981490284,0.09499555948423222,0.08847976749530062,0.08143956639105454,0.08865792193682864,0.08623304479988292,0.0842677759937942,0.08423010050319135,0.08290003833826631,0.07827100087888539,0.07729279599152505,0.07319843664299697,0.07193127815844491,0.07119633635738865,0.07311036885948852,0.07243317243410274,0.07226884068222716,0.07140147179597989,0.06872711499454454,0.06873175728833303,0.06798087700735778,0.06751375147723593,0.074663081089966,0.07394624134758487,0.07003165647620335,0.07022206374676898,0.057612499222159386,0.057345704597537406,0.05700549636094365,0.05709924300026614,0.048898308945354074,0.04796201307908632,0.047794809215702116,0.04739889991469681,0.046267083584098145,0.046061120432568714,0.03621481484151445,0.035965526796644554,0.03532853732758667,0.033552431894349866,0.03322576575737912,0.033303703836281784,0.03744215490587521,0.036421917291590944,0.036346628912724555,0.03918085293844342,0.03578945738263428,0.035262980876723304,0.034469734731828794,0.03434949062648229,0.03263814789534081,0.037899209142779,0.03751160991669167,0.03720993155729957,0.037475523800821975,0.03751636159722693,0.03643073754210491,0.04000473582709674,0.0404585132637294,0.04305602528620511,0.04471121763344854,0.04507358086993918,0.045265449487487786,0.04599592259910423,0.04636469921388198,0.047150712125585414,0.04788433403882664,0.04767566261580214,0.048048217489849776,0.0521157716284506,0.05207707607769407,0.052266679384047166,0.052259833144489676,0.051875392004149035,0.04248532211931888,0.04244678067334462,0.04226207855390385,0.038829728815471753,0.043659641029080376,0.04373357445001602,0.043680635993951,0.043537169563933276,0.04390130308456719,0.037903006857959554,0.03780816326616332,0.037864692421862856,0.030117246918962337,0.030223219931940548,0.03098171972669661,0.027465718740131706,0.02679249460925348,0.02413696493022144,0.02215696472558193,0.02146542906120885,0.02157758553221356,0.021443131132400595,0.021054174329037778,0.020089460173039697,0.019208076322684065,0.0193866243789671,0.01893079638830386,0.014851126616122201,0.014918310698703863,0.014721707892022096,0.014681984481285326,0.014928380391211249,0.015055481810122728,0.014995847319369204,0.015014240852906369,0.014951737510273233,0.01903784033493139,0.019102482532616705,0.019158503084327094,0.019152620268869214,0.01869836870173458,0.018465156317688525,0.018415001446555834,0.018283880526723806,0.024615504771645647,0.024346432757738512,0.029871365630242508,0.029178627781220712,0.03514485379855614,0.035278510928037576,0.03522189968498424,0.035319352042279206,0.035172183692338876,0.03442118182283593,0.03430058496451238,0.03466799550369615,0.034682885532674845,0.034594612479850184,0.03445657031261362,0.03460302218445577,0.034487088487367146,0.03510369402647484,0.03516957773535978,0.03484307728649583,0.0346122515402385,0.034938417353259865,0.03513456935615977,0.03565993719530525,0.026828242996998597,0.02677050495549338,0.026783509041706566,0.026744388182123657,0.02686028344760416,0.027116939025290776,0.027085888403235003,0.027100930143205915,0.020771691655681934,0.020949592981196474,0.014667318428109866,0.014612141232646536,0.008748895597818773,0.00854199638706632,0.0085203884227667,0.008448489272268489,0.008189469095668755,0.008138457327731885,0.008129056528559886,0.00771153317327844,0.007571915251901373,0.007347589322307613,0.00735360560065601,0.007016705589194316,0.00693649283493869,0.006221828036359511,0.005991543803247623,0.006014415936078876,0.006080039871449117,0.0057181845913873985,0.005481816340761725,0.004894786623481195,0.004622918822860811,0.010677082180336583,0.01051523177739,0.010570781676506158,0.010376322348747635,0.010086480480822502,0.010929679581749951,0.010864296698855469,0.010828249596670503,0.010632934576278785,0.012575813805597136,0.012619045071915025,0.012279834951186785,0.012276178949832683,0.01806009238862316,0.026722743652499048,0.02664860292497906,0.026637290578946704,0.026636357582901837,0.02662426897950354,0.026614699247147655,0.026663431319320807,0.02664961446498637,0.026854608757275855,0.026855438627535477,0.02704152425576467,0.02703725706669502,0.026974125968990847,0.026917561248410493,0.026942807497107424,0.02689726050448371,0.02700563883263385,0.026951090669172117,0.020832495374634163,0.020859161635598866,0.02087373238100554,0.02089431091735605,0.02102529112744378,0.02017088100910769,0.020231620244885562,0.020357108976895688,0.020469229533773614,0.01840106757299509,0.01847652978176484,0.01847754690243164,0.01843414650647901,0.01776622617035173,0.013802288187434897,0.013800027878460241,0.014012095820362447,0.014122250093350885,0.014115804839093471,0.01414357927205856,0.014056548294320237,0.014036010754352901,0.013820931300870143,0.013885244177799905,0.013672138109541265,0.013686784554010956,0.014303483472758671,0.01444873754735454,0.01466371611240902,0.014860715167742455,0.014758219203940826,0.015154242246353533,0.015178739042312372,0.01514363817841513,0.015063114609802142,0.01505729355267249,0.014920805449946783,0.015176446951954858,0.015253077403031057,0.015075857412739424,0.01490708026176435,0.015243769143125974,0.015132930428080726,0.015165526616328862,0.015622996201273054,0.010663599139661528,0.006052186465240084,0.006213841425051214,0.0060252370494708885,0.005815929132950259,0.010981055766023928,0.011243287608522223,0.01125645088905003,0.011238664566917578,0.011242710115766386,0.011238299161050236,0.011402982305298792,0.01131449983586208,0.010857587552891346,0.010661102223821217,0.010443378047057195,0.01059301661371137,0.010578078890830511,0.010187413641688181,0.01022931698753382,0.0102376414979517,0.010222046461421996,0.010271604391164146,0.010436683893203735,0.010251224259263836,0.010134840558748692,0.010188261730945669,0.010321391331672203,0.010613329526677262,0.015989603285561316,0.015911251215584343,0.015580406437948113,0.015480036276130704,0.015300918519642437,0.015188100620434852,0.015349145618529292,0.015409229828946991,0.018797018139594,0.01857370168363559,0.018724518802628154,0.018770163413137197,0.01875474588450743,0.018794298521243036,0.01874725475499872,0.018711136573983822,0.018537797179305926,0.018762672421871684,0.01905350518791238,0.01875661795202177,0.018749993309029378,0.018726379526924575,0.02882173887701356,0.02888986310790642,0.035253937952802517,0.035355952437384985,0.03518172231633798,0.03533044991854695,0.035587601454608375,0.035598922815552214,0.035605039756774204,0.042873417394730495,0.03749746434550616,0.03750284644047497,0.03738732760393759,0.037375423416960984,0.037523210638028104,0.03749482412968064,0.04183157787338132,0.042126280248339754,0.03418052795313997,0.03409253565041581,0.03417980945232557,0.03417739589349367,0.03417815218199394,0.034149377952417126,0.03404788510306389,0.03405534926059772,0.03439424121097545,0.03423821909018443,0.03412544203820289,0.03442062111207633,0.034359028533799574,0.03883131462862366,0.028751268841006095,0.028678081838734215,0.02262360919485218,0.030244384044635808,0.030246333775721723,0.030033423707209295,0.029800936488754814,0.03053924814958009,0.03081466666117194,0.02291757611237699,0.022923770957277156,0.023377137789793778,0.023381393250019755,0.023551907142973505,0.023453139496268705,0.029044544979115017,0.02491895119601395,0.02460156120650936,0.029614880462759174,0.030144066317006946,0.03021320205880329,0.030258208957093302,0.030332654667290626,0.030299186295451364,0.030283320465969155,0.030576994406146696,0.03620768157634302,0.03667337407023297,0.03665004327558563,0.03631594273247174,0.03633430734043941,0.03191612129739951,0.03198999747110065,0.032023325220507104,0.03176534035446821,0.0241552020816016,0.02443166481316439,0.02453981526559801,0.028949913048563758,0.028387499569362262,0.028059917403879808,0.03619371289823903,0.04313101598381763,0.04296372658427572,0.042964646039763466,0.04280828846094664,0.04273922513311845,0.03735882229011622,0.03705867987082456,0.03702422854985343,0.03138924486847827,0.031131756644754205,0.030806723960267846,0.03074737513816217,0.03117688850761624,0.03116105110530043,0.031210573775751982,0.03827974442538107,0.03231602691812441,0.03179324726443156,0.03158900167545653,0.03167975070027751,0.03221774053599802,0.03250095568728284,0.03216224358038744,0.032166518474696204,0.032155853128642775,0.03217005384794902,0.036200591901433654,0.03607789090892766,0.031791788089321926,0.03187025513034314,0.03185717233282048,0.02372119621213642,0.016864146284206072,0.016569816201808862,0.016944327326200437,0.01717047612328315,0.017161700954602566,0.01697883228189312,0.017413751018466428,0.017727548442053376,0.018177043977630092,0.018298054910701467,0.01830345141570433,0.018296327772986842,0.01779616665953654,0.017960046647203853,0.018035735494777327,0.013608381876110798,0.018420295036776224,0.018423099205392646,0.01872950948381913,0.018880550112953642,0.018532835212681675,0.01820684808990336,0.01822980830911547,0.018311102387087885,0.01828570506768301,0.018209024710813537,0.014194121322361752,0.01419213080953341,0.014569381572073326,0.014254335386794992,0.01419626573624555,0.02427459518003161,0.02418583015241893,0.024992319606099045,0.024751282104261918,0.024570985126047162,0.024578252403443912,0.024640104933496332,0.024133307040756335,0.02403173813581816,0.023596734357852256,0.023401573180308333,0.023560200552310562,0.0276794238416187,0.02773304603397264,0.0275496054055111,0.03304455123361549,0.030249491243012017,0.02549110217296402,0.025584830946172588,0.025401225269888528,0.025294911378296092,0.02509480039952905,0.025096363664488308,0.02519989485881524,0.025721007805259433,0.02586115972371772,0.025767927822016645,0.02548971914802678,0.025546554825268686,0.025103908497840166,0.025202036325936206,0.02545432145416271,0.015752486579003744,0.016181664021132747,0.015770847679959843,0.015624081632267917,0.015664206966903294,0.016402802379161585,0.01640386749204481,0.016412185541412327,0.016414522549894173,0.01648592434503371,0.016543500394618604,0.0164182506268844,0.012294140680751298,0.012241520664247219,0.012250958825461566,0.00703314584097825,0.007767121627693996,0.007759452346363105,0.0077057284652255476,0.007572458227514289,0.007412039271002868,0.007409638386889128,0.007413061164697865,0.007517141511925729,0.00730756610937533,0.0074085067499254365,0.0076622331216640305,0.007690704722335795,0.007809527833160246,0.00777602470407146,0.007658920374524314,0.00750995224370854,0.007332698536629323,0.006896500093716895,0.00650875528663164],\"type\":\"scatter\"},{\"mode\":\"lines\",\"name\":\"Validation mean loss\",\"x\":[0,32,64,96,128,160,192,224,256,288,320,352,384,416,448,480,512],\"y\":[0.6812585173948262,0.3984275852326935,0.10453808608625789,0.06684361393868991,0.03923574438515085,0.025485901165315787,0.02551632691495758,0.02528142244702026,0.024585734349207494,0.022595413594156274,0.022492603888596713,0.022804336058410223,0.02269940179604627,0.022345766912017596,0.02222743330620449,0.022126684603144018,0.022100691047802247],\"type\":\"scatter\"}],                        {\"title\":{\"text\":\"\\u041f\\u043e\\u0438\\u0441\\u043a \\u0433\\u0438\\u043f\\u0435\\u0440\\u043f\\u0430\\u0440\\u0430\\u043c\\u0435\\u0442\\u0440\\u043e\\u0432: \\u043a\\u0440\\u043e\\u0441\\u0441-\\u0432\\u0430\\u043b\\u0438\\u0434\\u0430\\u0446\\u0438\\u044f (\\\"opt_learning_rate\\\"=1.4634158668829792e-05; \\\"scheduler_type\\\"=cosine, KFold=2) Siamese-Bi-Encoder: Train (per batch) and Validation (per 32 batches) Losses\"},\"xaxis\":{\"title\":{\"text\":\"Batch Number\"}},\"yaxis\":{\"title\":{\"text\":\"Train Loss (SMA)\"}},\"xaxis2\":{\"anchor\":\"y2\",\"overlaying\":\"x\",\"side\":\"top\",\"title\":{\"text\":\"Validation Interval (in Batches)\"}},\"yaxis2\":{\"overlaying\":\"y\",\"side\":\"right\",\"title\":{\"text\":\"Validation Loss\"}},\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"legend\":{\"title\":{\"text\":\"Loss Type\"}},\"height\":600,\"width\":800},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('853d8f77-60fb-4c14-9f5c-16cd3d251a7b');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-02-25 05:30:00,405] Trial 2 finished with value: 0.02106863793289866 and parameters: {'opt_learning_rate': 1.4634158668829792e-05, 'scheduler_type': 'cosine'}. Best is trial 0 with value: 0.020892692084228497.\n",
            "INFO:chat_util_module:Поиск гиперпараметров: кросс-валидация для набора параметров \"opt_learning_rate\"=5.338949588464445e-06; \"scheduler_type\"=linear\n",
            "INFO:chat_util_module:Поиск гиперпараметров: кросс-валидация - обучение на KFold 1\n",
            "INFO:chat_util_module:Training step     0/602, loss =  0.695\n",
            "INFO:chat_util_module:Validation step     0/602, val_loss =  0.692\n",
            "INFO:chat_util_module:Training step    32/602, loss =  0.673\n",
            "INFO:chat_util_module:Validation step    32/602, val_loss =  0.676\n",
            "INFO:chat_util_module:Training step    64/602, loss =  0.595\n",
            "INFO:chat_util_module:Validation step    64/602, val_loss =  0.568\n",
            "INFO:chat_util_module:Training step    96/602, loss =  0.127\n",
            "INFO:chat_util_module:Validation step    96/602, val_loss =  0.138\n",
            "INFO:chat_util_module:Training step   128/602, loss =  0.045\n",
            "INFO:chat_util_module:Validation step   128/602, val_loss =  0.070\n",
            "INFO:chat_util_module:Training step   160/602, loss =  0.018\n",
            "INFO:chat_util_module:Validation step   160/602, val_loss =  0.063\n",
            "INFO:chat_util_module:Training step   192/602, loss =  0.205\n",
            "INFO:chat_util_module:Validation step   192/602, val_loss =  0.055\n",
            "INFO:chat_util_module:Training step   224/602, loss =  0.237\n",
            "INFO:chat_util_module:Validation step   224/602, val_loss =  0.049\n",
            "INFO:chat_util_module:Training step   256/602, loss =  0.020\n",
            "INFO:chat_util_module:Validation step   256/602, val_loss =  0.047\n",
            "INFO:chat_util_module:Training step   288/602, loss =  0.272\n",
            "INFO:chat_util_module:Validation step   288/602, val_loss =  0.033\n",
            "INFO:chat_util_module:Training step   320/602, loss =  0.189\n",
            "INFO:chat_util_module:Validation step   320/602, val_loss =  0.034\n",
            "INFO:chat_util_module:Training step   352/602, loss =  0.009\n",
            "INFO:chat_util_module:Validation step   352/602, val_loss =  0.031\n",
            "INFO:chat_util_module:Training step   384/602, loss =  0.013\n",
            "INFO:chat_util_module:Validation step   384/602, val_loss =  0.030\n",
            "INFO:chat_util_module:Training step   416/602, loss =  0.014\n",
            "INFO:chat_util_module:Validation step   416/602, val_loss =  0.030\n",
            "INFO:chat_util_module:Training step   448/602, loss =  0.007\n",
            "INFO:chat_util_module:Validation step   448/602, val_loss =  0.031\n",
            "INFO:chat_util_module:Training step   480/602, loss =  0.007\n",
            "INFO:chat_util_module:Validation step   480/602, val_loss =  0.031\n",
            "INFO:chat_util_module:Training step   512/602, loss =  0.007\n",
            "INFO:chat_util_module:Validation step   512/602, val_loss =  0.030\n",
            "INFO:chat_util_module:Training step   544/602, loss =  0.006\n",
            "INFO:chat_util_module:Validation step   544/602, val_loss =  0.030\n",
            "INFO:chat_util_module:Training step   576/602, loss =  0.007\n",
            "INFO:chat_util_module:Validation step   576/602, val_loss =  0.030\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"80496f8c-acbc-4df4-87e3-600aaddbf4e6\" class=\"plotly-graph-div\" style=\"height:600px; width:800px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"80496f8c-acbc-4df4-87e3-600aaddbf4e6\")) {                    Plotly.newPlot(                        \"80496f8c-acbc-4df4-87e3-600aaddbf4e6\",                        [{\"mode\":\"lines\",\"name\":\"Train batch losses\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518,519,520,521,522,523,524,525,526,527,528,529,530,531,532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549,550,551,552,553,554,555,556,557,558,559,560,561,562,563,564,565,566,567,568,569],\"y\":[0.6868772618472576,0.6861986815929413,0.6847016476094723,0.6846572943031788,0.6837729476392269,0.6826706621795893,0.6828525979071856,0.6821342017501593,0.6811000611633062,0.6796874478459358,0.6804436277598143,0.67918611317873,0.6787100117653608,0.6781758442521095,0.6763082072138786,0.6734916716814041,0.6706193592399359,0.6712121944874525,0.6681736875325441,0.6681359875947237,0.6678396929055452,0.6664665918797255,0.6654486283659935,0.6645938251167536,0.6641078870743513,0.6623090617358685,0.6592269875109196,0.6586635857820511,0.6572765745222569,0.6558004356920719,0.6537361107766628,0.6518123038113117,0.6494873054325581,0.6470352672040462,0.6442042347043753,0.6422160658985376,0.6385891903191805,0.6354430038481951,0.6315843909978867,0.6271729357540607,0.6219023177400231,0.617817503400147,0.6112966518849134,0.6049417806789279,0.5977736636996269,0.5903806993737817,0.5832629716023803,0.5772662693634629,0.5711869588121772,0.5593459252268076,0.5518419742584229,0.5405088234692812,0.5272110356017947,0.5170976808294654,0.5048975264653563,0.4949332932010293,0.4806622564792633,0.46766218869015574,0.45630093198269606,0.4405508367344737,0.42642462998628616,0.41140268882736564,0.39774195617064834,0.38310539349913597,0.3716616560705006,0.35702295089140534,0.3427725767251104,0.32764173694886267,0.3141836510039866,0.2997566550038755,0.28557201148942113,0.2732101259753108,0.2602229225449264,0.24641376757062972,0.2353054948616773,0.2273756603244692,0.2165272431448102,0.2049771612510085,0.19491196260787547,0.18629243620671332,0.1752625284716487,0.16707711783237755,0.15778755908831954,0.1498593350406736,0.1434055567951873,0.13521794020198286,0.1343019304331392,0.12504975066985935,0.1196121679386124,0.11426259682048112,0.10876488406211138,0.10465862590353936,0.10016426828224212,0.09660732687916607,0.09294708201196045,0.08986363431904465,0.08327490137889981,0.0807373266434297,0.07827598589938134,0.07579229096882045,0.07320292410440743,0.07112974254414439,0.06889618490822613,0.0656956461025402,0.06406956340651959,0.06293451332021505,0.059482307522557676,0.05474679789040238,0.05293702718336135,0.05181940918555483,0.06310384132666513,0.05996100482298061,0.06581233296310529,0.06404369883239269,0.06892482726834714,0.07654800964519382,0.08186578436288983,0.0808867888408713,0.07389395090285689,0.07751010823994875,0.07692596438573673,0.08914589887717739,0.08907647634623572,0.08874403109075502,0.08828143321443349,0.09467127348762006,0.09427763166604564,0.09351163695100695,0.09347087662899867,0.09262108482653275,0.09272585093276575,0.09913779416820034,0.0987002698238939,0.09805913449963555,0.09779695590259507,0.09742386365542188,0.10720553860301152,0.10676397610222921,0.10652137879515067,0.10646171111147851,0.11229371011722833,0.11255747807445005,0.10511784284608439,0.10512716375524178,0.09837470838101581,0.09884022013284266,0.09339305653702468,0.09114969416987151,0.09210503601934761,0.09795976494206116,0.09783643728587776,0.09347826999146491,0.09357436373829842,0.08056406944524497,0.08006179862422869,0.08009051746921614,0.07989303802605718,0.07322355022188276,0.07426925544859841,0.07428943971171975,0.07422413059975952,0.08005230780690908,0.07971283560618758,0.07290722639299929,0.07290397066390142,0.08318208623677492,0.0830610329285264,0.08315522270277143,0.07309644354972988,0.07309895131038502,0.07315786019898951,0.07290670246584341,0.06744363595498726,0.06697491888189688,0.0608479484799318,0.06582342827459797,0.06576860358472914,0.0739998008357361,0.0737735201837495,0.06730325549142435,0.06024660135153681,0.060545361251570284,0.06598556996323168,0.06932325451634824,0.07422146160388365,0.07420880312565714,0.07418373494874686,0.07998681650497019,0.08004965732106939,0.08013399800984189,0.08583883655956015,0.08619237277889624,0.08613984170369804,0.08714410965330899,0.08707486663479358,0.08685956348199397,0.08690230792853981,0.07660163979744539,0.07662241120124236,0.07656298513757065,0.07637900568079203,0.07631978468270972,0.07641161500941962,0.07658975967206061,0.07562202721601352,0.07705757097573951,0.08180024864850566,0.08145042340038344,0.08128145994851366,0.0751143813249655,0.08121409005252644,0.08108322659973055,0.08089359517907724,0.07456076133530587,0.06930727924918756,0.06590826506726444,0.06087571708485484,0.060846353706438094,0.060837290599010885,0.054963903850875795,0.054961815709248185,0.05438436081749387,0.04840432040509768,0.047843372012721375,0.04856029796064831,0.041788821836235,0.04148211202118546,0.041625026089604944,0.041709007520694286,0.04177216865355149,0.04175080877030268,0.041785698966123164,0.042311945755500346,0.04784279764862731,0.047591356677003205,0.047532511700410396,0.047550962219247594,0.04640165498130955,0.04142077118740417,0.042578174179652706,0.04228543085628189,0.03939456105581485,0.0330941159336362,0.0331436236447189,0.03395275681396015,0.033738077036105096,0.03347680816659704,0.033113665267592296,0.03279476836905815,0.037857276533031836,0.03755454739439301,0.03726469029788859,0.03697157828719355,0.03698051569517702,0.03597065823851153,0.03965244529535994,0.03854206204414368,0.046410190989263356,0.04628040411625989,0.04616076001548208,0.04579101284616627,0.04562926813377999,0.04553235074854456,0.04526029227417894,0.04461592572624795,0.03869090470834635,0.038612086646026,0.03834389601252042,0.03837813425343484,0.037709179130615667,0.03791914353496395,0.03169995895586908,0.03169201058335602,0.03171246897545643,0.03140737733338028,0.031455865886528045,0.030410202918574214,0.030394895060453564,0.030284126638434827,0.03765885790926404,0.04201566378469579,0.03668360921437852,0.036981082492275164,0.03701420288416557,0.036911322036758065,0.03684550625621341,0.03690251585794613,0.03304899547947571,0.03300968708936125,0.030428779893554747,0.030545900663128123,0.030656112678116187,0.035268004721729085,0.035207510023610666,0.0349839512782637,0.035026044613914564,0.03495815579663031,0.03496864382759668,0.034870214585680515,0.03499055985594168,0.034973657224327326,0.03519595947000198,0.034901575825642794,0.036355957767227665,0.036433751753065735,0.036470047634793445,0.036339729878818616,0.03623980368138291,0.036442382115637884,0.036345983389765024,0.03646165505051613,0.029006117081735283,0.024633591703604907,0.03240487695438787,0.036746250465512276,0.03667675313772634,0.03667305107228458,0.03658238932257518,0.03667408003821038,0.036641976243117824,0.03723233952769078,0.031599550682585686,0.03674822728498839,0.03645898567629047,0.03721263285842724,0.037058715912280604,0.0372079016524367,0.03731576359132305,0.0373771806480363,0.038429862062912434,0.038484941207570955,0.03824465950310696,0.037985523566021584,0.03781205812992994,0.03814296673226636,0.03675018476496916,0.0367079811549047,0.036639067679061554,0.03671690776536707,0.036465788405621424,0.036162421441986226,0.036693071117042564,0.03657336063042749,0.03660701330227312,0.03654634415579494,0.02890964392281603,0.024107915072818287,0.024162817091564648,0.02423665653623175,0.02433949820988346,0.024248869114671834,0.02411325451976154,0.023482264296035282,0.02359493546828162,0.018234539093100466,0.023321070839301683,0.01802676731313113,0.018123278030543588,0.01843431634188164,0.01876423707290087,0.018838344360119663,0.01772641080606263,0.017673471607849933,0.01791482322732918,0.01813896611565724,0.024149585544364527,0.023882563458755612,0.02376384977833368,0.02374650805722922,0.02445254407939501,0.024358181370189413,0.024417359978542663,0.024501782521838322,0.024090140126645565,0.02426114390254952,0.02421371360833291,0.024761560503975488,0.024634772868012078,0.024724234230234288,0.024536167024052702,0.024727711468585767,0.02459039476525504,0.024655540895764716,0.024885851496946998,0.024899612777517177,0.02492844003427308,0.024901161290472373,0.019726981001440436,0.019598716316977516,0.019548778247553855,0.019068152614636347,0.018555016518803313,0.01848490789416246,0.018329164566239342,0.02631510142236948,0.0263071489171125,0.026099235547007993,0.020160011161351576,0.020173424331005663,0.020118384141824208,0.020170424293610267,0.019330334311234765,0.01947809375997167,0.01943044712243136,0.019309063151013106,0.01923418781370856,0.01889766415115446,0.019173838591086678,0.01872665541304741,0.018685248869587667,0.018652068698429503,0.0185649400082184,0.01820114789006766,0.018166786452638917,0.017848467789008282,0.017646358362981118,0.017545561378938146,0.017342804465442896,0.017456078858231194,0.017578650629729964,0.017511234094854444,0.017523616435937583,0.017504907329566777,0.01727729121921584,0.017277457140153274,0.0172492376586888,0.009147557051619515,0.009039787721121684,0.00913319128449075,0.009056590060936287,0.00922889812500216,0.009198998915962875,0.00909622383187525,0.009306208841735497,0.009085028505069204,0.009050208653206937,0.009054422756889835,0.008988157787825912,0.009012259659357369,0.008931088115787134,0.008775692855124362,0.008717871634871699,0.008633175486465916,0.008721804682863876,0.008653398515889421,0.008694447809830308,0.008663050073664635,0.008561108727008104,0.008696073986357078,0.0086995794554241,0.008847364078974351,0.008674665543367155,0.008725731080630794,0.00866853169281967,0.008646575413877144,0.008641659762361087,0.00856275983096566,0.00866566323384177,0.008739335477002896,0.008562476898077875,0.008558137429645285,0.00852578369085677,0.010225514852209017,0.010294326304574497,0.010229052015347406,0.010079420550027862,0.01013956633687485,0.010153838840778917,0.01020335397333838,0.010203868092503399,0.010087608330650255,0.009896784540615045,0.01007250408292748,0.009948923136107624,0.00996996030153241,0.009900385019136593,0.009901391953462735,0.009991288796300068,0.010144173254957423,0.01074007962597534,0.02020741516025737,0.020195918667013757,0.019915221055271104,0.019924591382732615,0.01995583181269467,0.025788084545638412,0.031219219759805128,0.031490245994064026,0.038015035053831525,0.03804016920912545,0.037995501174009405,0.03810885126586072,0.037938549532555044,0.038005895679816604,0.0360839627974201,0.0360244122275617,0.03609867904742714,0.041037798961042427,0.04094507977424655,0.041030012973351404,0.04093787903548218,0.041002000274602324,0.041053269247640856,0.041213833435904235,0.041108011137112044,0.04112070630071685,0.041076233464991674,0.04116749957029242,0.041252112059737556,0.041152221674565226,0.041195756173692644,0.040744446363532916,0.031075761100510135,0.03106153967382852,0.031130412011407316,0.031363460831926204,0.031369639254990034,0.02544897711777594,0.020029396153404377,0.01975809175928589,0.013175205225707032,0.013052232287009247,0.018432364784530364,0.018398331172647886,0.018580661257146858,0.018548347012256272,0.01844869698106777,0.018630217484314926,0.018663336624740623,0.013689024839550257,0.013792119279969484,0.013638909949804656,0.013651684406795539,0.01818380293843802,0.018117328319931403,0.01789740435197018,0.017895099023007788,0.017969197942875326,0.018087707518134266,0.018060190632240847,0.017983110403292812,0.018012657907092944,0.018014718225458637,0.01798836948000826,0.026018487667897716,0.026049733642139472,0.0261391917738365,0.025916447208146565,0.026220469750114717,0.026244255393976346,0.03145865528495051,0.03146671775903087,0.031413312259246595,0.031541975869913585,0.026193314130068757,0.02674386631406378,0.02663076191674918,0.026519483159063384,0.026602496509440243,0.026448619188158773,0.03191416348272469,0.03191722644260153,0.031872425955953076,0.031904887917335145,0.03203178026888054,0.027327322954079136,0.027426727494457737,0.02755565824918449,0.027681065315846354,0.02759228111244738],\"type\":\"scatter\"},{\"mode\":\"lines\",\"name\":\"Validation mean loss\",\"x\":[0,32,64,96,128,160,192,224,256,288,320,352,384,416,448,480,512],\"y\":[0.683865254800581,0.6222943781667769,0.35320769828369847,0.10401304347743821,0.06656291855706453,0.05916392226220786,0.05232778654056307,0.048436299852092454,0.04040811437977311,0.03374439287595018,0.032645142368393706,0.03074711926344881,0.030293162418815592,0.0305458384026863,0.03082195692192887,0.030515947631340586,0.029850664775411713],\"type\":\"scatter\"}],                        {\"title\":{\"text\":\"\\u041f\\u043e\\u0438\\u0441\\u043a \\u0433\\u0438\\u043f\\u0435\\u0440\\u043f\\u0430\\u0440\\u0430\\u043c\\u0435\\u0442\\u0440\\u043e\\u0432: \\u043a\\u0440\\u043e\\u0441\\u0441-\\u0432\\u0430\\u043b\\u0438\\u0434\\u0430\\u0446\\u0438\\u044f (\\\"opt_learning_rate\\\"=5.338949588464445e-06; \\\"scheduler_type\\\"=linear, KFold=1) Siamese-Bi-Encoder: Train (per batch) and Validation (per 32 batches) Losses\"},\"xaxis\":{\"title\":{\"text\":\"Batch Number\"}},\"yaxis\":{\"title\":{\"text\":\"Train Loss (SMA)\"}},\"xaxis2\":{\"anchor\":\"y2\",\"overlaying\":\"x\",\"side\":\"top\",\"title\":{\"text\":\"Validation Interval (in Batches)\"}},\"yaxis2\":{\"overlaying\":\"y\",\"side\":\"right\",\"title\":{\"text\":\"Validation Loss\"}},\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"legend\":{\"title\":{\"text\":\"Loss Type\"}},\"height\":600,\"width\":800},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('80496f8c-acbc-4df4-87e3-600aaddbf4e6');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:chat_util_module:Поиск гиперпараметров: кросс-валидация - обучение на KFold 2\n",
            "INFO:chat_util_module:Training step     0/602, loss =  0.696\n",
            "INFO:chat_util_module:Validation step     0/602, val_loss =  0.704\n",
            "INFO:chat_util_module:Training step    32/602, loss =  0.694\n",
            "INFO:chat_util_module:Validation step    32/602, val_loss =  0.693\n",
            "INFO:chat_util_module:Training step    64/602, loss =  0.673\n",
            "INFO:chat_util_module:Validation step    64/602, val_loss =  0.667\n",
            "INFO:chat_util_module:Training step    96/602, loss =  0.474\n",
            "INFO:chat_util_module:Validation step    96/602, val_loss =  0.468\n",
            "INFO:chat_util_module:Training step   128/602, loss =  0.076\n",
            "INFO:chat_util_module:Validation step   128/602, val_loss =  0.102\n",
            "INFO:chat_util_module:Training step   160/602, loss =  0.161\n",
            "INFO:chat_util_module:Validation step   160/602, val_loss =  0.052\n",
            "INFO:chat_util_module:Training step   192/602, loss =  0.020\n",
            "INFO:chat_util_module:Validation step   192/602, val_loss =  0.043\n",
            "INFO:chat_util_module:Training step   224/602, loss =  0.017\n",
            "INFO:chat_util_module:Validation step   224/602, val_loss =  0.032\n",
            "INFO:chat_util_module:Training step   256/602, loss =  0.009\n",
            "INFO:chat_util_module:Validation step   256/602, val_loss =  0.030\n",
            "INFO:chat_util_module:Training step   288/602, loss =  0.013\n",
            "INFO:chat_util_module:Validation step   288/602, val_loss =  0.026\n",
            "INFO:chat_util_module:Training step   320/602, loss =  0.013\n",
            "INFO:chat_util_module:Validation step   320/602, val_loss =  0.026\n",
            "INFO:chat_util_module:Training step   352/602, loss =  0.007\n",
            "INFO:chat_util_module:Validation step   352/602, val_loss =  0.034\n",
            "INFO:chat_util_module:Training step   384/602, loss =  0.012\n",
            "INFO:chat_util_module:Validation step   384/602, val_loss =  0.029\n",
            "INFO:chat_util_module:Training step   416/602, loss =  0.008\n",
            "INFO:chat_util_module:Validation step   416/602, val_loss =  0.025\n",
            "INFO:chat_util_module:Training step   448/602, loss =  0.173\n",
            "INFO:chat_util_module:Validation step   448/602, val_loss =  0.023\n",
            "INFO:chat_util_module:Training step   480/602, loss =  0.171\n",
            "INFO:chat_util_module:Validation step   480/602, val_loss =  0.023\n",
            "INFO:chat_util_module:Training step   512/602, loss =  0.255\n",
            "INFO:chat_util_module:Validation step   512/602, val_loss =  0.022\n",
            "INFO:chat_util_module:Training step   544/602, loss =  0.019\n",
            "INFO:chat_util_module:Validation step   544/602, val_loss =  0.022\n",
            "INFO:chat_util_module:Training step   576/602, loss =  0.007\n",
            "INFO:chat_util_module:Validation step   576/602, val_loss =  0.022\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"0ecce1e3-4c76-41e1-ada3-c654a00a1165\" class=\"plotly-graph-div\" style=\"height:600px; width:800px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"0ecce1e3-4c76-41e1-ada3-c654a00a1165\")) {                    Plotly.newPlot(                        \"0ecce1e3-4c76-41e1-ada3-c654a00a1165\",                        [{\"mode\":\"lines\",\"name\":\"Train batch losses\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518,519,520,521,522,523,524,525,526,527,528,529,530,531,532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549,550,551,552,553,554,555,556,557,558,559,560,561,562,563,564,565,566,567,568,569],\"y\":[0.7030206546187401,0.7029420118778944,0.7024368103593588,0.701029172167182,0.700889652594924,0.7013087831437588,0.6999041344970465,0.699984734877944,0.700547244399786,0.6997069343924522,0.699215155094862,0.6987645663321018,0.6983616817742586,0.6968443263322115,0.6964174509048462,0.6952885426580906,0.6950406543910503,0.6948000453412533,0.6942826993763447,0.6931690964847803,0.6929977424442768,0.6928974073380232,0.6917638033628464,0.6907449923455715,0.689720381051302,0.6893964763730764,0.6879629865288734,0.6873882431536913,0.6857379265129566,0.6846431493759155,0.6838014088571072,0.6833404470235109,0.6822933498769999,0.6816649474203587,0.6805382594466209,0.6800174601376057,0.6786185745149851,0.6774453856050968,0.6765528209507465,0.6754787843674421,0.6742709148675203,0.6736385449767113,0.6730718463659286,0.6708357688039541,0.669624449685216,0.6684792842715979,0.6676812395453453,0.6660727728158236,0.6647216062992811,0.6633308231830597,0.6616895776242018,0.6598648726940155,0.657034682109952,0.6542817447334528,0.6527411136776209,0.6503755152225494,0.6476028896868229,0.6443915460258722,0.6421395875513554,0.6390233412384987,0.6352637335658073,0.631399255245924,0.6277042403817177,0.62180329952389,0.6159456055611372,0.6097130486741662,0.6040333034470677,0.5981663577258587,0.5916031086817384,0.5834667989984155,0.5767398485913873,0.570857273414731,0.5626189298927784,0.5527002532035112,0.5426377169787884,0.5325255440548062,0.5221826583147049,0.5114990957081318,0.5000333525240421,0.48796726670116186,0.47581049939617515,0.4634642763994634,0.45114376209676266,0.4377830792218447,0.4271420305594802,0.4140736563131213,0.40021382505074143,0.38647007616236806,0.37525003030896187,0.36128332559019327,0.35132663790136576,0.3374907081015408,0.32455569924786687,0.3134837416000664,0.2990736074279994,0.2868365263566375,0.27836225321516395,0.26592597970739007,0.2536304737441242,0.242821856867522,0.23154602688737214,0.22591615677811205,0.2143507821019739,0.20198995107784867,0.19248741958290339,0.1836938343476504,0.1812822117935866,0.1741939338389784,0.1698518304619938,0.16227866685949266,0.15466018789447844,0.1487338125007227,0.1491607759380713,0.14306677889544517,0.13888350978959352,0.13434808095917106,0.12761036946903914,0.12325522699393332,0.11914007249288261,0.11557752289809287,0.11623501195572317,0.1132386161480099,0.10600729659199715,0.10275418718811125,0.09990886389277875,0.09551220701541752,0.09864560991991311,0.10223864379804581,0.09660284512210637,0.0992674786830321,0.09772609558422118,0.09468603739514947,0.09301595255965367,0.08724573830841109,0.08608400798402727,0.08431103453040123,0.0823532811482437,0.08221287064952776,0.07499997009290382,0.07349158474244177,0.06865147675853223,0.0677426652982831,0.0672457457985729,0.06684772542212158,0.05957029230194166,0.05893610819475725,0.056773882650304586,0.0563048833864741,0.061994109593797475,0.061527284036856145,0.06083804712397978,0.060491487733088434,0.053656374802812934,0.05353448528330773,0.05324436124647036,0.05310831038514152,0.05267286696471274,0.06241433008108288,0.0571915294858627,0.051098131691105664,0.05076379724778235,0.04633650078903884,0.04744708363432437,0.052896628389135,0.052537012204993516,0.05282571126008406,0.05273346876492724,0.05307399417506531,0.05288787023164332,0.051445819553919137,0.05090760614257306,0.050704370194580406,0.05022817227290943,0.05019879405153915,0.061003867944236845,0.060361556126736104,0.0603431977215223,0.060010696353856474,0.06730908068129793,0.06696046818979084,0.0603905210737139,0.06012782239122316,0.05998949351487681,0.05969076347537339,0.05920467904070392,0.059482970100361854,0.05927344711381011,0.059152514761080965,0.05877543182577938,0.04826441558543593,0.04869187233271077,0.04861295857699588,0.048388700175564736,0.048298065667040646,0.04660829220665619,0.040624508692417294,0.04053710983134806,0.03968140188953839,0.0393338113790378,0.03898210742045194,0.04547811241354793,0.045576043252367526,0.04549867758760229,0.04552136186975986,0.04538963077357039,0.045208932395325974,0.033795728493714705,0.033533783367602155,0.03341900304076262,0.03309091861592606,0.02524863847065717,0.025459622556809336,0.02540714555652812,0.025342970358906314,0.025561962713254616,0.025246614415664226,0.025155227951472625,0.02420114615233615,0.024251088761957362,0.02374654493178241,0.023691463487921283,0.023347998096141964,0.02256946623674594,0.022510421375045553,0.02247204736340791,0.022229514725040644,0.022206580499187112,0.02210132940672338,0.021974832488922402,0.021876357088331133,0.0228429609851446,0.022496750520076603,0.015691230044467375,0.015456770837772638,0.01548454724252224,0.015262809203704819,0.015448320162249729,0.015370308421552181,0.015206959913484752,0.021961921476759017,0.021836432220879942,0.021782609284855425,0.021715051087085158,0.02135514683322981,0.02758885972434655,0.02742541956831701,0.0270151260192506,0.027066205453593284,0.027053313970100135,0.026941078365780413,0.026700488931965083,0.026888416847214103,0.026886837935307994,0.032514605030883104,0.032488036988070235,0.03228758921613917,0.03205747219908517,0.032186047566938214,0.032276119556627236,0.032254678997560404,0.03224263135052752,0.038451697197160684,0.03734182626067195,0.03741783996520098,0.037443442808580585,0.037377994318376295,0.03717251705529634,0.037191066090599634,0.037001171105657704,0.036957386808353476,0.036914374053594656,0.030344929909915663,0.03038879188534338,0.030708904305356555,0.03063169504457619,0.03025405344669707,0.023818980145733804,0.023831660131691024,0.023764271900290623,0.02361632723477669,0.024290539498906583,0.02442310465266928,0.024607651750557125,0.02449327416252345,0.030432903324253857,0.024592411689809524,0.024606367005617358,0.024915724570746534,0.02496715757297352,0.024949591228505597,0.024841394973918796,0.024573724876972847,0.024549906709580682,0.01836541101511102,0.018309258346562274,0.018147508541005664,0.018092662226990797,0.02077020135766361,0.02071717732178513,0.020662310198531486,0.020728255811263807,0.020775455588591285,0.021429403088404797,0.022123359187389724,0.02196700450440403,0.027681433988618664,0.033079565488151275,0.033095387218054384,0.03362412450951524,0.03363363063544966,0.033642160589806736,0.033779678371502087,0.03316626860760152,0.033162404026370496,0.033089489297708496,0.03298475901829079,0.026860477213631384,0.02701632320531644,0.026887035579420626,0.026594778639264405,0.034828166622901335,0.03466392350674141,0.04016462933213916,0.04015448913560249,0.04004859062843025,0.04010723490500823,0.04011927658575587,0.039993796512135305,0.04004139079188462,0.037398127067717724,0.0373816734936554,0.03729951407876797,0.03710429668717552,0.0371574552700622,0.03659934182360303,0.035689058087882586,0.035583241246058606,0.029741043559624813,0.024382141869864427,0.024452226338326,0.023982782280654646,0.023932759460876696,0.029429591246298514,0.02929627762932796,0.029260700146551244,0.029087046757922508,0.03516961394052487,0.035139843515935354,0.03525916751823388,0.035244043509010226,0.04043184861075133,0.040510518330847844,0.03219009246095084,0.0323437756014755,0.026676706038415432,0.02676964018610306,0.026886754349106923,0.026618156902259216,0.02658022107789293,0.02669583984243218,0.026596113239065744,0.02647535438882187,0.026466189126949757,0.02636952980537899,0.03476770133420359,0.03478415023710113,0.0347327862837119,0.03463064742390998,0.03963322110939771,0.0395824879524298,0.0394641223247163,0.03941268677590415,0.039261871454073116,0.03914110180630814,0.033873462802148424,0.034202120164991356,0.034008666494628415,0.034092039917595685,0.028786829323507845,0.02882426988799125,0.02879951271461323,0.028653376110014506,0.023560549117974006,0.023552704384201206,0.023652097341255285,0.023516453758929856,0.023506793033448048,0.024124554081936367,0.023930794166517444,0.02404563240997959,0.02396647079149261,0.023854388506151736,0.023715205636108294,0.023792007341398858,0.023882304434664547,0.024008043488720432,0.026906047394732013,0.034144089062465355,0.03397862896963488,0.03398413714603521,0.029002288967603818,0.028813437005737796,0.02876977859705221,0.028809748197090812,0.028916677736560814,0.029040606081252918,0.02872744741034694,0.028401083429344,0.028414031039574184,0.028365624413709156,0.03638901961676311,0.03630698216147721,0.03631475334987044,0.03645827107538935,0.036315063101937994,0.036162335745757446,0.03625625153654255,0.04140306019689888,0.04136176018801052,0.041085272750933655,0.04127232158498373,0.041186897971783765,0.041228193789720535,0.04163905562018044,0.04197281616507098,0.04190363851375878,0.0419230233237613,0.04198779709986411,0.030873183073708788,0.023566801275592297,0.023731792040052824,0.02914806925400626,0.029166780659579672,0.029119979386450723,0.029238265633466654,0.02948520985955838,0.029421462284517474,0.02934733136498835,0.03721948385646101,0.03735282762499992,0.03741244746197481,0.03749917600362096,0.02849908740608953,0.02849606539530214,0.028454521976527758,0.030088002342381515,0.030102003089268692,0.030038970930036157,0.030001367151271552,0.02993857505498454,0.02996057871496305,0.029636565246619284,0.029497202311176807,0.029921897599706426,0.03465782752027735,0.03447430633241311,0.03414707549382001,0.03410436927515548,0.034273648299858905,0.03424304838699754,0.034089117936673574,0.034112258566892706,0.03974153507442679,0.03548901061003562,0.04850493652338628,0.04875438113231212,0.04858727246755734,0.04827861377270892,0.04835080704651773,0.04834394245699514,0.040930010567535646,0.04081408392812591,0.04086299579648767,0.0453616503655212,0.04551269969670102,0.04569460992934182,0.04612908361013979,0.044608257099753246,0.0445890178962145,0.04557842369831633,0.04550465852662455,0.04815152571245562,0.04855415319616441,0.04846991926024202,0.04897831966809463,0.04902712155308109,0.044303436879999936,0.04437763523310423,0.04473591654095799,0.04491905828763265,0.04466094703821,0.0491492740547983,0.053678649172070436,0.05365508377144579,0.047976787041989155,0.04675545789359603,0.03830145452229772,0.03803542535752058,0.037993581194314174,0.03815713412768673,0.03812762700545136,0.03822382076759823,0.03776633468805812,0.0378138818196021,0.03767830369179137,0.03297762147849426,0.03330362949054688,0.03311770186701324,0.03275211596337613,0.03256234881700948,0.032599961501546204,0.03446213714778423,0.03454987230361439,0.02717493279487826,0.02683825563872233,0.026940898067550734,0.02666996739571914,0.026199078405625187,0.026188937612459995,0.030394093148061074,0.03000440246250946,0.03014234204601962,0.03077052348817233,0.026465921037015505,0.02233824868744705,0.022239460187847726,0.022155705737532116,0.022318823597743176,0.018023806318524294,0.018059171896311454,0.018225560168502852,0.01805541288922541,0.01809391417191364,0.017986300343181938,0.02287446812260896,0.023097629367839545,0.02333858047495596,0.023755051952321082,0.02330676026758738,0.02357851831766311,0.02343268551339861,0.02353504649363458,0.023607490278664045,0.02139472977432888,0.021409951747045852,0.021016778948251158,0.02147694569430314,0.021678424265701324,0.02161812674603425,0.02161986734427046,0.021696815732866526,0.01730741889332421,0.01761840604012832,0.01757608144544065,0.016983101231744513,0.017007067246595398,0.016680531349265948,0.016764961561420932,0.0169246033183299,0.01680379078607075,0.016419692401541397,0.016416131824371405,0.02375673562346492,0.024198260871344246,0.024179422136512585,0.024354649256565608,0.01945060169964563,0.01947932089387905,0.019306581394630484,0.018983758622198366],\"type\":\"scatter\"},{\"mode\":\"lines\",\"name\":\"Validation mean loss\",\"x\":[0,32,64,96,128,160,192,224,256,288,320,352,384,416,448,480,512],\"y\":[0.6983182109966626,0.6800812552636644,0.5677519764169505,0.2850392110416808,0.07687369707594331,0.04744150711570022,0.037515264955129586,0.03091035599695005,0.027973444132982098,0.026030382998921967,0.02981570961597403,0.03162333552696219,0.02732119866239953,0.023997844931703566,0.022660426408140623,0.022418302612068237,0.022315870283018374],\"type\":\"scatter\"}],                        {\"title\":{\"text\":\"\\u041f\\u043e\\u0438\\u0441\\u043a \\u0433\\u0438\\u043f\\u0435\\u0440\\u043f\\u0430\\u0440\\u0430\\u043c\\u0435\\u0442\\u0440\\u043e\\u0432: \\u043a\\u0440\\u043e\\u0441\\u0441-\\u0432\\u0430\\u043b\\u0438\\u0434\\u0430\\u0446\\u0438\\u044f (\\\"opt_learning_rate\\\"=5.338949588464445e-06; \\\"scheduler_type\\\"=linear, KFold=2) Siamese-Bi-Encoder: Train (per batch) and Validation (per 32 batches) Losses\"},\"xaxis\":{\"title\":{\"text\":\"Batch Number\"}},\"yaxis\":{\"title\":{\"text\":\"Train Loss (SMA)\"}},\"xaxis2\":{\"anchor\":\"y2\",\"overlaying\":\"x\",\"side\":\"top\",\"title\":{\"text\":\"Validation Interval (in Batches)\"}},\"yaxis2\":{\"overlaying\":\"y\",\"side\":\"right\",\"title\":{\"text\":\"Validation Loss\"}},\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"legend\":{\"title\":{\"text\":\"Loss Type\"}},\"height\":600,\"width\":800},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('0ecce1e3-4c76-41e1-ada3-c654a00a1165');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-02-25 05:42:29,623] Trial 3 finished with value: 0.02589993287427846 and parameters: {'opt_learning_rate': 5.338949588464445e-06, 'scheduler_type': 'linear'}. Best is trial 0 with value: 0.020892692084228497.\n",
            "INFO:chat_util_module:Поиск в пространстве гиперпараметров завершен.\n",
            "INFO:chat_util_module:Лучший Learning Rate: 1.0029518072924353e-05\n",
            "INFO:chat_util_module:Лучший Scheduler Type: linear\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user_opt_lr = best_params['opt_learning_rate']\n",
        "scheduler_type = best_params['scheduler_type']"
      ],
      "metadata": {
        "id": "WkiCpsrQjtKF"
      },
      "id": "WkiCpsrQjtKF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bi_encoder_model, all_train_batch_losses, all_mean_val_losses_per_val_interval =  SiameseBiEncoderTrainingPipeline(preprocessed_data, constants, chat_util).train(val_interval=32, n_epochs=1, user_opt_lr=user_opt_lr, user_scheduler_type=scheduler_type)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "hNHbtK1neSc-",
        "outputId": "1ac43ef2-2a7b-401a-cb09-39f5d572c9df"
      },
      "id": "hNHbtK1neSc-",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:chat_util_module:Установлены данные гиперпараметров. Начать обучение модели..\n",
            "INFO:chat_util_module:Training step     0/963, loss =  0.695\n",
            "INFO:chat_util_module:Validation step     0/963, val_loss =  0.692\n",
            "INFO:chat_util_module:Training step    32/963, loss =  0.659\n",
            "INFO:chat_util_module:Validation step    32/963, val_loss =  0.683\n",
            "INFO:chat_util_module:Training step    64/963, loss =  0.544\n",
            "INFO:chat_util_module:Validation step    64/963, val_loss =  0.552\n",
            "INFO:chat_util_module:Training step    96/963, loss =  0.036\n",
            "INFO:chat_util_module:Validation step    96/963, val_loss =  0.066\n",
            "INFO:chat_util_module:Training step   128/963, loss =  0.009\n",
            "INFO:chat_util_module:Validation step   128/963, val_loss =  0.055\n",
            "INFO:chat_util_module:Training step   160/963, loss =  0.057\n",
            "INFO:chat_util_module:Validation step   160/963, val_loss =  0.031\n",
            "INFO:chat_util_module:Training step   192/963, loss =  0.009\n",
            "INFO:chat_util_module:Validation step   192/963, val_loss =  0.025\n",
            "INFO:chat_util_module:Training step   224/963, loss =  0.009\n",
            "INFO:chat_util_module:Validation step   224/963, val_loss =  0.025\n",
            "INFO:chat_util_module:Training step   256/963, loss =  0.003\n",
            "INFO:chat_util_module:Validation step   256/963, val_loss =  0.024\n",
            "INFO:chat_util_module:Training step   288/963, loss =  0.005\n",
            "INFO:chat_util_module:Validation step   288/963, val_loss =  0.025\n",
            "INFO:chat_util_module:Training step   320/963, loss =  0.005\n",
            "INFO:chat_util_module:Validation step   320/963, val_loss =  0.023\n",
            "INFO:chat_util_module:Training step   352/963, loss =  0.008\n",
            "INFO:chat_util_module:Validation step   352/963, val_loss =  0.033\n",
            "INFO:chat_util_module:Training step   384/963, loss =  0.002\n",
            "INFO:chat_util_module:Validation step   384/963, val_loss =  0.022\n",
            "INFO:chat_util_module:Training step   416/963, loss =  0.004\n",
            "INFO:chat_util_module:Validation step   416/963, val_loss =  0.024\n",
            "INFO:chat_util_module:Training step   448/963, loss =  0.006\n",
            "INFO:chat_util_module:Validation step   448/963, val_loss =  0.022\n",
            "INFO:chat_util_module:Training step   480/963, loss =  0.001\n",
            "INFO:chat_util_module:Validation step   480/963, val_loss =  0.023\n",
            "INFO:chat_util_module:Training step   512/963, loss =  0.002\n",
            "INFO:chat_util_module:Validation step   512/963, val_loss =  0.021\n",
            "INFO:chat_util_module:Training step   544/963, loss =  0.005\n",
            "INFO:chat_util_module:Validation step   544/963, val_loss =  0.021\n",
            "INFO:chat_util_module:Training step   576/963, loss =  0.001\n",
            "INFO:chat_util_module:Validation step   576/963, val_loss =  0.021\n",
            "INFO:chat_util_module:Training step   608/963, loss =  0.002\n",
            "INFO:chat_util_module:Validation step   608/963, val_loss =  0.021\n",
            "INFO:chat_util_module:Training step   640/963, loss =  0.006\n",
            "INFO:chat_util_module:Validation step   640/963, val_loss =  0.021\n",
            "INFO:chat_util_module:Training step   672/963, loss =  0.001\n",
            "INFO:chat_util_module:Validation step   672/963, val_loss =  0.021\n",
            "INFO:chat_util_module:Training step   704/963, loss =  0.005\n",
            "INFO:chat_util_module:Validation step   704/963, val_loss =  0.021\n",
            "INFO:chat_util_module:Training step   736/963, loss =  0.103\n",
            "INFO:chat_util_module:Validation step   736/963, val_loss =  0.021\n",
            "INFO:chat_util_module:Training step   768/963, loss =  0.005\n",
            "INFO:chat_util_module:Validation step   768/963, val_loss =  0.021\n",
            "INFO:chat_util_module:Training step   800/963, loss =  0.001\n",
            "INFO:chat_util_module:Validation step   800/963, val_loss =  0.021\n",
            "INFO:chat_util_module:Training step   832/963, loss =  0.111\n",
            "INFO:chat_util_module:Validation step   832/963, val_loss =  0.021\n",
            "INFO:chat_util_module:Training step   864/963, loss =  0.014\n",
            "INFO:chat_util_module:Validation step   864/963, val_loss =  0.021\n",
            "INFO:chat_util_module:Training step   896/963, loss =  0.002\n",
            "INFO:chat_util_module:Validation step   896/963, val_loss =  0.021\n",
            "INFO:chat_util_module:Training step   928/963, loss =  0.001\n",
            "INFO:chat_util_module:Validation step   928/963, val_loss =  0.021\n",
            "INFO:chat_util_module:Training step   960/963, loss =  0.005\n",
            "INFO:chat_util_module:Validation step   960/963, val_loss =  0.021\n",
            "INFO:chat_util_module:Epoch 1: Mean train loss (per batch) = 0.0745, Last Validation Loss (per all val dataset) = 0.0214\n",
            "INFO:chat_util_module:Обучение завершено, последний результат функции потерь на валидационном наборе: 0.021387616454051708\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"231c3604-f129-4045-bf6b-71a2f362187e\" class=\"plotly-graph-div\" style=\"height:600px; width:800px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"231c3604-f129-4045-bf6b-71a2f362187e\")) {                    Plotly.newPlot(                        \"231c3604-f129-4045-bf6b-71a2f362187e\",                        [{\"mode\":\"lines\",\"name\":\"Train batch losses\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518,519,520,521,522,523,524,525,526,527,528,529,530,531,532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549,550,551,552,553,554,555,556,557,558,559,560,561,562,563,564,565,566,567,568,569,570,571,572,573,574,575,576,577,578,579,580,581,582,583,584,585,586,587,588,589,590,591,592,593,594,595,596,597,598,599,600,601,602,603,604,605,606,607,608,609,610,611,612,613,614,615,616,617,618,619,620,621,622,623,624,625,626,627,628,629,630,631,632,633,634,635,636,637,638,639,640,641,642,643,644,645,646,647,648,649,650,651,652,653,654,655,656,657,658,659,660,661,662,663,664,665,666,667,668,669,670,671,672,673,674,675,676,677,678,679,680,681,682,683,684,685,686,687,688,689,690,691,692,693,694,695,696,697,698,699,700,701,702,703,704,705,706,707,708,709,710,711,712,713,714,715,716,717,718,719,720,721,722,723,724,725,726,727,728,729,730,731,732,733,734,735,736,737,738,739,740,741,742,743,744,745,746,747,748,749,750,751,752,753,754,755,756,757,758,759,760,761,762,763,764,765,766,767,768,769,770,771,772,773,774,775,776,777,778,779,780,781,782,783,784,785,786,787,788,789,790,791,792,793,794,795,796,797,798,799,800,801,802,803,804,805,806,807,808,809,810,811,812,813,814,815,816,817,818,819,820,821,822,823,824,825,826,827,828,829,830,831,832,833,834,835,836,837,838,839,840,841,842,843,844,845,846,847,848,849,850,851,852,853,854,855,856,857,858,859,860,861,862,863,864,865,866,867,868,869,870,871,872,873,874,875,876,877,878,879,880,881,882,883,884,885,886,887,888,889,890,891,892,893,894,895,896,897,898,899,900,901,902,903,904,905,906,907,908,909,910,911,912,913,914,915,916,917,918,919,920,921,922,923,924,925,926,927,928,929,930],\"y\":[0.6897714082151651,0.688637025654316,0.6884539276361465,0.688494049012661,0.6876566223800182,0.6883209347724915,0.6885106898844242,0.6867731753736734,0.6867692098021507,0.6863163039088249,0.6860370188951492,0.6863160189241171,0.6851638350635767,0.6840165965259075,0.6830308884382248,0.6815736349672079,0.6807137001305819,0.6801181603223085,0.6794153023511171,0.6767692249268293,0.6759753413498402,0.6753907930105925,0.6750770434737206,0.6734255142509937,0.6729900389909744,0.6713806297630072,0.6694242227822542,0.6687697321176529,0.6671861484646797,0.6655539460480213,0.6613468267023563,0.6591567900031805,0.6553630884736776,0.6517513804137707,0.6478681173175573,0.6438064500689507,0.6394836511462927,0.6343137007206678,0.6269736113026738,0.6213643327355385,0.613245815038681,0.6046132333576679,0.5939517840743065,0.5843705460429192,0.5786669049412012,0.568372692912817,0.5560862431302667,0.542970132548362,0.5297135710716248,0.5145367719233036,0.503984316252172,0.4898374145850539,0.47442270815372467,0.4583558882586658,0.44165340485051274,0.42524711531586945,0.40937233273871243,0.39231787831522524,0.3754342943429947,0.3581154318526387,0.3408834736328572,0.3233776115812361,0.3069028976606205,0.2892891549272463,0.27274981094524264,0.25687881116755307,0.24068888823967427,0.22411630424903706,0.20819614600623026,0.1921769636683166,0.1780244919937104,0.164188711787574,0.15147832327056676,0.14015007496345788,0.13028672622749582,0.11891346296761185,0.1047527402988635,0.09532973956083879,0.08916171285090968,0.0820461795956362,0.07497912930557504,0.07029371644603088,0.06096049680490978,0.0558208784495946,0.05152846433338709,0.04675847358885221,0.042714545503258705,0.040363933658227324,0.03616584706469439,0.03390423805103637,0.03128408847260289,0.02885904340655543,0.02690828437334858,0.025171592977130786,0.023787665588315576,0.022274009650573134,0.020923843956552446,0.020088401361135766,0.018877588590839878,0.01822401679237373,0.017558938096044585,0.026697403081925586,0.02621557770180516,0.02569174709788058,0.025138187484117225,0.0340964917850215,0.03365258959820494,0.0332708329660818,0.04079302871832624,0.040462835429934785,0.03868351617711596,0.039575771312229335,0.03940865467302501,0.04868402564898133,0.05612325182300992,0.05611811453127302,0.056055726076010615,0.05592145165428519,0.055908581387484446,0.055372814647853374,0.05548413857468404,0.055470139253884554,0.05559173799701966,0.06255426627467386,0.06271080297301523,0.06301603795145638,0.06315297592664137,0.06357408943586051,0.06375179591123015,0.06525010222685523,0.06535012621316127,0.06551034835865721,0.0657038823410403,0.05610909857205115,0.06171277505927719,0.06210506362549495,0.062185401999158785,0.05268741166219115,0.05269183745258488,0.05307161799282767,0.04537913275999017,0.05039188370574266,0.05038137803785503,0.049246438531554304,0.04935362304968294,0.039934612446813844,0.032339993442292325,0.032284089174936526,0.03216043482825626,0.03196910078986548,0.03830101728090085,0.0380967446253635,0.037846173989237286,0.03765959535667207,0.03756513296684716,0.030651498076622374,0.030423315227380954,0.030199915476259775,0.030241845597629435,0.029946756301796995,0.029937254599644803,0.02842744872032199,0.028337542942608707,0.028074470930732787,0.027984617656329647,0.02779267047299072,0.022155523009132594,0.02182031940901652,0.02177467301953584,0.0214613817515783,0.021529972465941682,0.02112100666272454,0.02083511218370404,0.015589263115543872,0.022600185533519834,0.022580338671104982,0.02234613556356635,0.022083943113102578,0.02238671224040445,0.022224832166102715,0.02213526658306364,0.022250273206736892,0.01566443521005567,0.015612628194503486,0.015729903258034028,0.01570211714715697,0.021947027562418953,0.021767446407466196,0.021831336271134205,0.021619993742206134,0.021334285294869915,0.021057050398667343,0.02072667168249609,0.020750687639520038,0.02061264395888429,0.020699735570815392,0.022776182580855675,0.02278039358498063,0.022682171082124114,0.022527827837620862,0.022450336953625083,0.02255655474436935,0.02240630579763092,0.022436527113313787,0.022457520026364364,0.02785730321193114,0.020707169896923006,0.020925808828906156,0.020877276350802276,0.021020728432631586,0.020629239552363288,0.020610645464330446,0.020617472277081106,0.02045798335893778,0.020465269139094744,0.02037637322791852,0.02038344371248968,0.02040914109966252,0.01401749394426588,0.014160614664433524,0.014146605390124023,0.014240657241316512,0.01419182498648297,0.014192011418344919,0.014148335983918514,0.013955509450170211,0.014017385714396369,0.013947289822681341,0.011645798302197363,0.011651654007437173,0.011648509120277595,0.011609498578764033,0.011558204605535138,0.01142142059688922,0.011373693210771307,0.011317121869069524,0.011300350437522866,0.005848766952112783,0.005760697153164074,0.005442268768092617,0.005506353256350849,0.005188205810554791,0.005066436235210858,0.009491016346146353,0.009455494306166656,0.009440544883545954,0.009423523712030146,0.009601764468243346,0.009357836985145696,0.00927850503649097,0.00967870581371244,0.009525424342427868,0.009431021513591986,0.009276086908357684,0.009195520826324355,0.009167966243694536,0.009422855720913503,0.009468961026868783,0.009945933619746938,0.00987026985239936,0.009901727746182587,0.018658983062778134,0.018573970068246126,0.01855478792276699,0.018570248532341793,0.018605291719723027,0.019153976631059777,0.019123567202768754,0.019056838602409698,0.01903854034753749,0.01901040405209642,0.01900338906852994,0.01890439089766005,0.018891238534706645,0.018873620188969653,0.014415271631150972,0.014383632864337415,0.014401425498363096,0.022298850475635845,0.022167588940646965,0.022263587008637842,0.02222275934764184,0.02177843368554022,0.021784997479699086,0.021733967456384562,0.021715914968808647,0.021841002242581453,0.021885436617594678,0.021719568721891847,0.02172108683589613,0.02756874725309899,0.027574301173444837,0.027729552632081322,0.018880548916058615,0.019180432813300285,0.019331415322085377,0.019393575472349767,0.019337360783538315,0.018731856514932588,0.018776821714709513,0.01893723787361523,0.019076686941843946,0.019229933554015588,0.019198307636543177,0.019390528708754573,0.019613943324657157,0.02499147885828279,0.02502540261775721,0.030151101665978786,0.0347155779672903,0.026891815919952933,0.027007656324713025,0.027135957359860186,0.027104818509542383,0.03137532656546682,0.0369544358109124,0.04159243456524564,0.045530921284807846,0.04578944527020212,0.04586141485197004,0.04587062358041294,0.04598624023492448,0.04026122376671992,0.040950972674181685,0.040819583635311574,0.04082900984212756,0.04057745699537918,0.042440746547072195,0.04246561981562991,0.04763987608021125,0.04770494096010225,0.048797893679875415,0.05058753194316523,0.05132752081408398,0.051218286076618824,0.05126341074355878,0.05184167146217078,0.052247555257054046,0.04685334927489748,0.046802854449197184,0.04170039654854918,0.03750854501413414,0.037401992121885996,0.037582381009997334,0.037711709206632804,0.03770436930790311,0.03365795229183277,0.02859931004786631,0.024418502020125743,0.02046769001026405,0.020239716039213818,0.020495045821007807,0.020998143976612482,0.02080527885846095,0.02009149368677754,0.019862125293002464,0.01981564131710911,0.019949737637944054,0.019855347207339946,0.017810155241022585,0.017850492393336026,0.012932746478327317,0.012931877437949879,0.011761370387830539,0.015032072824396892,0.014353556278365431,0.014365912651555846,0.014451559272856684,0.013747715263889404,0.013104139463393949,0.013078112442599377,0.013045934600086184,0.012976985610293923,0.012517848947027232,0.012544209865154698,0.012196375675557647,0.011796271814091597,0.011776648654631572,0.01145887438178761,0.010925152026175056,0.01051948017993709,0.010510528896702453,0.010351570694183465,0.010018401102570351,0.009420870308531448,0.009479948319494724,0.009510621399385855,0.009073330882529262,0.009290465197409503,0.009101484258280834,0.016209430159506155,0.016197517285036156,0.016108476269437233,0.015812905432539992,0.015805398099473678,0.015752400569908787,0.010562410439888481,0.010350523611123208,0.010284929154295241,0.010186872943449998,0.010199900414590957,0.010187702406255994,0.010181849251239328,0.010141076116269687,0.010205195179878501,0.010201889199379366,0.010135984455700964,0.010269765880366322,0.01025190984364599,0.010306834486982552,0.010445283500303049,0.010553591557254549,0.010446872638567584,0.01051818346240907,0.010595882169582183,0.010594821203994798,0.010630133579979884,0.01068748349280213,0.010776406266813865,0.010813618388056057,0.010555483622738393,0.016540833494218532,0.009412800194695592,0.01596803171923966,0.01601380184365553,0.01601914953425876,0.016130721454828745,0.01609949944395339,0.016477789518830832,0.016484275918628555,0.016612130111752776,0.02128433689722442,0.021555400704528438,0.02155937246789108,0.021560759101703297,0.021573714075202588,0.02149926130005042,0.021493378095328808,0.025744054175447673,0.0262081763939932,0.026260721977450885,0.026393450032628607,0.026950958847010043,0.026774739686516114,0.02703764068792225,0.04330056689286721,0.04333422906711348,0.04329692094688653,0.043233991287706885,0.04309055319026811,0.04325253985734889,0.04316979873692617,0.0436273088271264,0.037644360589183634,0.038284801066765795,0.03174513373232912,0.03158507594343973,0.03224679793129326,0.03207289499187027,0.03208268660819158,0.03190539078786969,0.03188816033798503,0.0320387541942182,0.027465970699267928,0.027092798889498226,0.02726535461988533,0.027445552394055994,0.027426097614807077,0.027433828054199694,0.031628793047275394,0.03039425559109077,0.02974669223476667,0.02983271792618325,0.02965087322081672,0.038699324599292595,0.03902849463338498,0.03888369283231441,0.02254779331269674,0.02289557679614518,0.022851753114082385,0.022864777190989116,0.022868601598020177,0.022745313828636426,0.022926779798581265,0.02246177933557192,0.022461776454292703,0.023321035965636838,0.02331082569435239,0.023307636089157313,0.022907408856553957,0.023139759970945306,0.023423512277076952,0.0234777571313316,0.023482299046008848,0.023248321158462204,0.02316227529081516,0.023363103646261152,0.02330217889539199,0.02315408761933213,0.02317561363815912,0.023261808415554697,0.01922982684118324,0.016280621730402345,0.01629299798150896,0.016160647515789606,0.021732242850703187,0.01699055040080566,0.016880379771464504,0.016785896783403587,0.01679629231512081,0.01634547274443321,0.016400816806708463,0.016383522106480086,0.016485507410834543,0.01638432193431072,0.016236178642429877,0.016217542251979467,0.01622553220295231,0.014723220465384657,0.014719923419761471,0.01494015251955716,0.014675516751594841,0.014508688487694599,0.014362683228682727,0.01406332944316091,0.014131762152828742,0.014568636142939795,0.014485292122117244,0.014281962219683919,0.014365187314979266,0.014336283777083736,0.014318912701128284,0.014358009637362557,0.014268767186877085,0.014207043761416571,0.014186042255460052,0.014173362527799327,0.008595386458182475,0.00382261076811119,0.0035961230532848276,0.0036291365904617123,0.0036973205860704184,0.00795180986460764,0.00803099328186363,0.008425377713138005,0.008314582584716845,0.008261154398496728,0.008278553053969517,0.00826397308264859,0.008489556857966818,0.008698681769601535,0.008836745233566035,0.00871238573017763,0.013355081231566146,0.013429689555778168,0.013358306932786945,0.01334140252583893,0.013270796414872166,0.01277549679070944,0.012783011872670613,0.01294569574383786,0.012806229031411931,0.0127959528908832,0.012786562008841429,0.01264854252076475,0.01286555448314175,0.012851312811108073,0.012958060946402838,0.013334996427147416,0.013326523920113686,0.01325461426313268,0.013251993597805267,0.013237533687060932,0.013147578047210118,0.008846819353493629,0.008868647400959162,0.017735169338266132,0.017770405778719578,0.017855043268355075,0.017835078295320272,0.017871289630420506,0.02325057247071527,0.023173176814452745,0.02304418559288024,0.023204003107821336,0.022581286375498166,0.022434910180891166,0.02236235475356807,0.022441225166403456,0.022439165364630753,0.02252406122352113,0.02256026774921338,0.022639630227786256,0.022568319880519994,0.022572389989363728,0.02277329858043231,0.022931151514058,0.022672072831483092,0.02270817705357331,0.02259434789448278,0.022203857097338187,0.022409621455153683,0.022245379874220816,0.022511796309117926,0.022598309918976156,0.022707427331624785,0.022711236822942737,0.02256192676941282,0.013431624985969393,0.01354185455784318,0.013496863150066929,0.013638446656841552,0.013963663823233219,0.008835966047627153,0.008721165144379484,0.008713212566362927,0.008609651562437648,0.004604372228641296,0.004595583817717852,0.009448958295251941,0.009450696754356613,0.009450591940549202,0.009439406989258714,0.009428494035091717,0.00924315659358399,0.009289429017371731,0.00933828973211348,0.009252991483663209,0.009127905505010858,0.0091389790395624,0.009203306326526217,0.009205668698996305,0.009600865178072127,0.014125334728305461,0.01456204960049945,0.014314508815004956,0.014246786719013471,0.014129002909612609,0.014496304174826946,0.014585080516553717,0.014454750409640837,0.01431610817235196,0.014483404920611065,0.014301520332082873,0.013941039884230122,0.013537807404645719,0.01376674574567005,0.013804615173285129,0.02234568012136151,0.022314951227599522,0.022408131586416857,0.018122357800166355,0.028906916373671265,0.029040827474091202,0.028992353516514413,0.02895689986689831,0.028877940167149063,0.029048050608253106,0.029004413005168317,0.02898217920665047,0.03441430969905923,0.03465220470025088,0.03464384762264672,0.03891997263417579,0.038868486328283325,0.034359667071839795,0.03451553170452826,0.03450058544694912,0.034680031647440046,0.03477359618045739,0.03439993808569852,0.0386728725861758,0.038675357049214654,0.03879945199878421,0.03893814557523001,0.039105085143091856,0.03911251929457649,0.039458639377699,0.04129242141425493,0.04126273433575989,0.03255081055976916,0.03257396113622235,0.032470395515701966,0.031897195880446816,0.02106570232353988,0.021403270129667362,0.02164846290179412,0.021874142592423595,0.022151551300339634,0.021947967365122167,0.02666353762469953,0.026570260255539324,0.02110603530672961,0.02084308418488945,0.020933741190674482,0.0166780323452258,0.01634998896770412,0.016236616800597403,0.01563468073072727,0.0156413924160006,0.015384705428004963,0.01890933075264911,0.019162766453518998,0.015360116311057936,0.015578416441712761,0.018642181737959618,0.018274118137924233,0.018114646958565572,0.01810315494367387,0.01767102437588619,0.01584625777468318,0.015864877437707037,0.01690235709611443,0.01703949025613838,0.017073616894776933,0.017081718069675844,0.018316657762625255,0.017848995466920314,0.017725973633787362,0.017505291009001667,0.01723740889428882,0.01722395206161309,0.012670589640038088,0.012675097928877221,0.013032403956458438,0.013528843031963333,0.013724472039029934,0.01370341488654958,0.013694871980987955,0.013588561370852403,0.01359742092245142,0.014086524046433624,0.014086377996136434,0.010745442603365518,0.010506067228561733,0.009929356107022613,0.009707204673759406,0.0066257902908546384,0.006707465709041571,0.0066912632501043845,0.00669056455444661,0.007055585792841157,0.0068037880409974605,0.006773320481443079,0.005777580812718952,0.005804393458674895,0.006176406295708148,0.010379731818829896,0.009688080452178838,0.009786833114048932,0.009748084186867345,0.01414991456840653,0.014802844230871415,0.021602790420729434,0.021444421934575075,0.024905625061364844,0.024555759686336387,0.024327535829797853,0.024075168395938817,0.02462925110012293,0.02463079337758245,0.028823717875638977,0.029361831926507875,0.028868655444966862,0.03219311527573154,0.03192743854378932,0.03466271316210623,0.03494017043340136,0.03548908151424257,0.03537236889678752,0.035562555996875744,0.035698101462912746,0.03581706341356039,0.03616363956825808,0.036194612472172594,0.044277446846535895,0.04457259037735639,0.04439542155887466,0.044000529600452865,0.03979374204209307,0.03924858038953971,0.03925776768301148,0.043739263506722637,0.03933743196466821,0.03913247615491855,0.03596636659858632,0.03618871853177552,0.03358274315905874,0.033948362553928746,0.033659667809843086,0.033975765443756245,0.033414182587875985,0.033777317261410644,0.02958692691390752,0.029040197227004683,0.02903538931059302,0.02572235823754454,0.02573603513155831,0.023328456438321155,0.023091580005711876,0.022539324017998297,0.0259770574994036,0.026257758298015688,0.0261054656439228,0.02601170936759445,0.025314534083008766,0.025303760441602208,0.017455489592975937,0.032455258289701305,0.03498193475388689,0.04349981018822291,0.044285739393671975,0.0442502909572795,0.04434073007723782,0.03995381950517185,0.040183181470638374,0.04036616004668758,0.03672949661267921,0.03717196729849093,0.03632832138100639,0.03597183783494984,0.03637484098726418,0.03592980709072435,0.03847707514796639,0.038418659947637934,0.038888833551027346,0.03904398650774965,0.0391519849326869,0.04063419414887903,0.04348255514196353,0.04313673191063572,0.0434125661777216,0.043597524680080824,0.04057557320629712,0.040030021395068616,0.04003412359452341,0.040034928781096824,0.04001445339599741,0.040575434864877025,0.04063046782175661,0.02529145150037948,0.022905071498826146,0.014368048556207214,0.014095228027144913,0.014257058006478474,0.014280163362855092,0.014081614855967928,0.013958699499198701,0.013423687261820305,0.01347915119913523,0.013087151473882841,0.013088964060443686,0.016778257326222956,0.01637344438859145,0.016820247798023047,0.014281182717240881,0.014702547683555167,0.014244327358028386,0.017438914197555277,0.017345043474051636,0.015862359054153785,0.012991116138437064,0.013642936286487384,0.013607948971184669,0.013425260669464478,0.013039682457019808,0.013511865781765664,0.013871889077563537,0.015780773770529777,0.015787987049407093,0.015244184894982027,0.014967008668463677,0.014969030333304545,0.015204828738205833,0.016501901092851767,0.015984656780346995,0.015855284644203493,0.015638936536561232,0.01563770303982892,0.015521958859608276,0.016995931680867216,0.01698152590324753,0.017031979634339223,0.017679976856015855,0.017195638127304846,0.017550352691614535,0.027252510910329875,0.02759142571085249,0.026875477542489534,0.027101213327114237,0.02408074996128562,0.030291110273537925,0.030274486045527738,0.031858440812357,0.03184290000717738,0.03156872288673185,0.03176941291167168,0.031747019456815906,0.031612049278919585,0.03153394929540809,0.029858528505428694,0.030474361916276393,0.03112026403323398,0.03113415669213282,0.031215926981531084,0.031580971815856174,0.031018384062917903,0.031265727629943285,0.031485014158533886,0.03167198744995403,0.03166874646922224,0.031676132519351086,0.03010777972303913,0.030072227582422784,0.029753310074738692,0.029091542601236142,0.025857474334770814,0.025753106427146122,0.01560668778984109,0.015276958602044033,0.016514020342583535,0.01627176330293878,0.016005477704311488,0.009781519882380962,0.009797727845580084,0.008207319686334813,0.008169719807483489,0.008325680253619794,0.008269689256849233,0.008384016269701533,0.00818628235720098],\"type\":\"scatter\"},{\"mode\":\"lines\",\"name\":\"Validation mean loss\",\"x\":[0,32,64,96,128,160,192,224,256,288,320,352,384,416,448,480,512,544,576,608,640,672,704,736,768,800,832],\"y\":[0.49829623879115115,0.3390771482778419,0.17616889099262004,0.044292607605776114,0.03401496795636961,0.026392388314779663,0.024921014189335643,0.02448430129762109,0.026475498224903263,0.02597500803383817,0.025592180771180296,0.025361774708951065,0.02271675173582314,0.02247926119575615,0.021817529756811067,0.021542253395693697,0.021235503809052203,0.021094016092916352,0.021022001220576594,0.020940143406510455,0.02095333077777921,0.020924497770782678,0.02101374653586345,0.021143057858798442,0.021125898334556126,0.02133511333966423,0.021378382622105885],\"type\":\"scatter\"}],                        {\"title\":{\"text\":\"\\u0422\\u0440\\u0435\\u043d\\u0438\\u0440\\u043e\\u0432\\u043a\\u0430 Siamese-Bi-Encoder: Train (per batch) and Validation (per 32 batches) Losses\"},\"xaxis\":{\"title\":{\"text\":\"Batch Number\"}},\"yaxis\":{\"title\":{\"text\":\"Train Loss (SMA)\"}},\"xaxis2\":{\"anchor\":\"y2\",\"overlaying\":\"x\",\"side\":\"top\",\"title\":{\"text\":\"Validation Interval (in Batches)\"}},\"yaxis2\":{\"overlaying\":\"y\",\"side\":\"right\",\"title\":{\"text\":\"Validation Loss\"}},\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"legend\":{\"title\":{\"text\":\"Loss Type\"}},\"height\":600,\"width\":800},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('231c3604-f129-4045-bf6b-71a2f362187e');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Сохранение Siamese-Bi-Encoder в файловую систему"
      ],
      "metadata": {
        "id": "TPOlYrn6U5eP"
      },
      "id": "TPOlYrn6U5eP"
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(bi_encoder_model.state_dict(), constants.BI_ENCODER_MODEL_PATH_AUX)"
      ],
      "metadata": {
        "id": "2858h0uzVEPm"
      },
      "id": "2858h0uzVEPm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Тренировка Cross-Encoder"
      ],
      "metadata": {
        "id": "zhZZXZzfR8Pk"
      },
      "id": "zhZZXZzfR8Pk"
    },
    {
      "cell_type": "code",
      "source": [
        "cross_encoder_pipeline = CrossEncoderTrainingPipeline(preprocessed_data, constants, chat_util)"
      ],
      "metadata": {
        "id": "3RSV2CwZQngs"
      },
      "id": "3RSV2CwZQngs",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cross_encoder_model, all_train_batch_losses, all_mean_val_losses_per_val_interval = cross_encoder_pipeline.train(val_interval=32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "vZ8TyQuyQquV",
        "outputId": "a91e1775-d651-4e82-b628-9a4b7da1a0ef"
      },
      "id": "vZ8TyQuyQquV",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:chat_util_module:Training step     0/963, loss =  0.572\n",
            "INFO:chat_util_module:Validation step     0/963, val_loss =  0.823\n",
            "INFO:chat_util_module:Training step    32/963, loss =  0.198\n",
            "INFO:chat_util_module:Validation step    32/963, val_loss =  0.238\n",
            "INFO:chat_util_module:Training step    64/963, loss =  0.164\n",
            "INFO:chat_util_module:Validation step    64/963, val_loss =  0.159\n",
            "INFO:chat_util_module:Training step    96/963, loss =  0.087\n",
            "INFO:chat_util_module:Validation step    96/963, val_loss =  0.067\n",
            "INFO:chat_util_module:Training step   128/963, loss =  0.008\n",
            "INFO:chat_util_module:Validation step   128/963, val_loss =  0.029\n",
            "INFO:chat_util_module:Training step   160/963, loss =  0.015\n",
            "INFO:chat_util_module:Validation step   160/963, val_loss =  0.014\n",
            "INFO:chat_util_module:Training step   192/963, loss =  0.010\n",
            "INFO:chat_util_module:Validation step   192/963, val_loss =  0.009\n",
            "INFO:chat_util_module:Training step   224/963, loss =  0.011\n",
            "INFO:chat_util_module:Validation step   224/963, val_loss =  0.013\n",
            "INFO:chat_util_module:Training step   256/963, loss =  0.053\n",
            "INFO:chat_util_module:Validation step   256/963, val_loss =  0.012\n",
            "INFO:chat_util_module:Training step   288/963, loss =  0.003\n",
            "INFO:chat_util_module:Validation step   288/963, val_loss =  0.015\n",
            "INFO:chat_util_module:Training step   320/963, loss =  0.003\n",
            "INFO:chat_util_module:Validation step   320/963, val_loss =  0.007\n",
            "INFO:chat_util_module:Training step   352/963, loss =  0.004\n",
            "INFO:chat_util_module:Validation step   352/963, val_loss =  0.008\n",
            "INFO:chat_util_module:Training step   384/963, loss =  0.003\n",
            "INFO:chat_util_module:Validation step   384/963, val_loss =  0.005\n",
            "INFO:chat_util_module:Training step   416/963, loss =  0.059\n",
            "INFO:chat_util_module:Validation step   416/963, val_loss =  0.007\n",
            "INFO:chat_util_module:Training step   448/963, loss =  0.001\n",
            "INFO:chat_util_module:Validation step   448/963, val_loss =  0.007\n",
            "INFO:chat_util_module:Training step   480/963, loss =  0.003\n",
            "INFO:chat_util_module:Validation step   480/963, val_loss =  0.008\n",
            "INFO:chat_util_module:Training step   512/963, loss =  0.051\n",
            "INFO:chat_util_module:Validation step   512/963, val_loss =  0.005\n",
            "INFO:chat_util_module:Training step   544/963, loss =  0.006\n",
            "INFO:chat_util_module:Validation step   544/963, val_loss =  0.008\n",
            "INFO:chat_util_module:Training step   576/963, loss =  0.005\n",
            "INFO:chat_util_module:Validation step   576/963, val_loss =  0.005\n",
            "INFO:chat_util_module:Training step   608/963, loss =  0.066\n",
            "INFO:chat_util_module:Validation step   608/963, val_loss =  0.007\n",
            "INFO:chat_util_module:Training step   640/963, loss =  0.055\n",
            "INFO:chat_util_module:Validation step   640/963, val_loss =  0.006\n",
            "INFO:chat_util_module:Training step   672/963, loss =  0.011\n",
            "INFO:chat_util_module:Validation step   672/963, val_loss =  0.005\n",
            "INFO:chat_util_module:Training step   704/963, loss =  0.002\n",
            "INFO:chat_util_module:Validation step   704/963, val_loss =  0.007\n",
            "INFO:chat_util_module:Training step   736/963, loss =  0.001\n",
            "INFO:chat_util_module:Validation step   736/963, val_loss =  0.005\n",
            "INFO:chat_util_module:Training step   768/963, loss =  0.001\n",
            "INFO:chat_util_module:Validation step   768/963, val_loss =  0.006\n",
            "INFO:chat_util_module:Training step   800/963, loss =  0.001\n",
            "INFO:chat_util_module:Validation step   800/963, val_loss =  0.005\n",
            "INFO:chat_util_module:Training step   832/963, loss =  0.001\n",
            "INFO:chat_util_module:Validation step   832/963, val_loss =  0.005\n",
            "INFO:chat_util_module:Training step   864/963, loss =  0.001\n",
            "INFO:chat_util_module:Validation step   864/963, val_loss =  0.005\n",
            "INFO:chat_util_module:Training step   896/963, loss =  0.002\n",
            "INFO:chat_util_module:Validation step   896/963, val_loss =  0.005\n",
            "INFO:chat_util_module:Training step   928/963, loss =  0.002\n",
            "INFO:chat_util_module:Validation step   928/963, val_loss =  0.005\n",
            "INFO:chat_util_module:Training step   960/963, loss =  0.003\n",
            "INFO:chat_util_module:Validation step   960/963, val_loss =  0.005\n",
            "INFO:chat_util_module:Epoch 1: Mean train loss (per batch) = 0.0334, Last Validation Loss (per all val dataset) = 0.0050\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"a059510c-c5e3-4fde-b32b-fd7c9f0f5531\" class=\"plotly-graph-div\" style=\"height:600px; width:800px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"a059510c-c5e3-4fde-b32b-fd7c9f0f5531\")) {                    Plotly.newPlot(                        \"a059510c-c5e3-4fde-b32b-fd7c9f0f5531\",                        [{\"mode\":\"lines\",\"name\":\"Train batch losses\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518,519,520,521,522,523,524,525,526,527,528,529,530,531,532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549,550,551,552,553,554,555,556,557,558,559,560,561,562,563,564,565,566,567,568,569,570,571,572,573,574,575,576,577,578,579,580,581,582,583,584,585,586,587,588,589,590,591,592,593,594,595,596,597,598,599,600,601,602,603,604,605,606,607,608,609,610,611,612,613,614,615,616,617,618,619,620,621,622,623,624,625,626,627,628,629,630,631,632,633,634,635,636,637,638,639,640,641,642,643,644,645,646,647,648,649,650,651,652,653,654,655,656,657,658,659,660,661,662,663,664,665,666,667,668,669,670,671,672,673,674,675,676,677,678,679,680,681,682,683,684,685,686,687,688,689,690,691,692,693,694,695,696,697,698,699,700,701,702,703,704,705,706,707,708,709,710,711,712,713,714,715,716,717,718,719,720,721,722,723,724,725,726,727,728,729,730,731,732,733,734,735,736,737,738,739,740,741,742,743,744,745,746,747,748,749,750,751,752,753,754,755,756,757,758,759,760,761,762,763,764,765,766,767,768,769,770,771,772,773,774,775,776,777,778,779,780,781,782,783,784,785,786,787,788,789,790,791,792,793,794,795,796,797,798,799,800,801,802,803,804,805,806,807,808,809,810,811,812,813,814,815,816,817,818,819,820,821,822,823,824,825,826,827,828,829,830,831,832,833,834,835,836,837,838,839,840,841,842,843,844,845,846,847,848,849,850,851,852,853,854,855,856,857,858,859,860,861,862,863,864,865,866,867,868,869,870,871,872,873,874,875,876,877,878,879,880,881,882,883,884,885,886,887,888,889,890,891,892,893,894,895,896,897,898,899,900,901,902,903,904,905,906,907,908,909,910,911,912,913,914,915,916,917,918,919,920,921,922,923,924,925,926,927,928,929,930],\"y\":[0.40708086965605617,0.39539421955123544,0.3887096126563847,0.3713916945271194,0.3644388378597796,0.346478215418756,0.3290219334885478,0.32182506565004587,0.31332976184785366,0.2952322200872004,0.28278461331501603,0.26983441272750497,0.2563827228732407,0.2581318598240614,0.25256349286064506,0.2513108910061419,0.24784141639247537,0.24863517889752984,0.24890140816569328,0.24797932291403413,0.2486773319542408,0.24867177195847034,0.24675997253507376,0.24566206568852067,0.2447599326260388,0.24444758286699653,0.24055286450311542,0.23760576406493783,0.23664930695667863,0.23498090403154492,0.2342517557553947,0.23225348955020308,0.23058395832777023,0.22954341443255544,0.22731944592669606,0.22543882159516215,0.22177058458328247,0.21860730997286737,0.21665300778113306,0.21155527303926647,0.20709489774890244,0.2050643393304199,0.20038553420454264,0.19762127101421356,0.19324906542897224,0.18844760744832456,0.1812388415564783,0.1770794073236175,0.17039924924029037,0.16503720422042534,0.1581257726647891,0.15308541763806716,0.14625354867894202,0.13991462858393788,0.13585721561685205,0.1320162822958082,0.1274526547640562,0.12226979550905526,0.11502065847162157,0.11324236437212676,0.10616263397969306,0.09996324212988839,0.0938764366437681,0.08851096458965912,0.08322900597704574,0.08082460396690294,0.07607847003964707,0.07102714153006673,0.06682439430733211,0.06492837160476483,0.06031655127299018,0.05561531180865131,0.053782212402438745,0.051077059557428584,0.04977828517439775,0.04638477475964464,0.044212063861778006,0.04219038292649202,0.04273320737411268,0.039600729389349,0.03931693031336181,0.03808325922000222,0.03777821631229017,0.03662521416845266,0.03812923208170105,0.03761617474083323,0.035442493346636184,0.03744995985471178,0.03652828613121528,0.03457613829232287,0.03555299462459516,0.033389545322279446,0.03386822580068838,0.03484134863538202,0.03382196788152214,0.03386708527978044,0.034094275717507116,0.03162169958523009,0.03174752123595681,0.03155358425283339,0.03148262253671419,0.03306522096681874,0.0333331805159105,0.03333734274201561,0.030770808560191654,0.03049585314875003,0.02986495448567439,0.029337278319871984,0.02927868331607897,0.028820539839216508,0.03074131849280093,0.0303235446481267,0.032198287270148285,0.03316802038170863,0.03401977851171978,0.033231383393285796,0.031298109592171386,0.03284831580822356,0.03564210599870421,0.031608099554432556,0.032029345486080274,0.0318471543432679,0.03149021227727644,0.030906278814654797,0.029727762026595883,0.028945849611773156,0.03083675702509936,0.030470659155980684,0.031739296988234855,0.031942147892550565,0.03178914058662485,0.03196165988629218,0.0319269679748686,0.02949850146251265,0.027989416310447268,0.02810692625644151,0.027954280623816885,0.027134799645864405,0.026910712113021873,0.026852806375245564,0.026662642660085112,0.026653370397980325,0.023959707163157873,0.025059074323507957,0.022698498563840985,0.02074710682791192,0.01978787808911875,0.019435609865467995,0.019296990474686027,0.01687969986232929,0.015943329053698108,0.015617674071108922,0.014771210655453615,0.01461223789374344,0.013507493262295611,0.013375636233831756,0.013291123192175291,0.012859381007729098,0.010771812158054672,0.01369929280190263,0.011904081286047585,0.011769243006710894,0.014120629828539677,0.013968873492558487,0.014299496207968332,0.014607829347369261,0.014622595917899162,0.014620723188272677,0.014579591501387767,0.015075170711497776,0.015166866753133945,0.015272577220457606,0.015308316331356764,0.015263731838786043,0.01530904277751688,0.014197119104210287,0.014254666180931963,0.0163860660395585,0.016419850711827166,0.016302988660754636,0.016500877303769812,0.017554580932483077,0.01575550631969236,0.016403051820816472,0.016583820557571016,0.019746136356843635,0.019750603547436185,0.019979849181254394,0.019903523876564577,0.019891066331183538,0.019868574243446346,0.01735367930814391,0.019495324660965707,0.01950567447784124,0.017261987486563157,0.017420847834728193,0.017600860381207895,0.01729115811031079,0.017307688140135724,0.017516231215267908,0.01761005509615643,0.017314072225417476,0.01710502614150755,0.017241934780031443,0.017337980287265964,0.017408014347893186,0.01734499930171296,0.017841835928265937,0.01783196434553247,0.015754479696624912,0.015794230086612515,0.01570966724830214,0.01544795828522183,0.014337108870677184,0.014067719013837632,0.013386208818701562,0.013206307783548255,0.011928112253372092,0.011813704513770062,0.011466196658147965,0.011767909141781274,0.013560879269789439,0.013590965267212596,0.013102326018270105,0.010960411877022125,0.012279614937142469,0.012056598832714371,0.012012409322778694,0.011417555011576042,0.01130572214606218,0.01126835028117057,0.012411955118295737,0.01230219592252979,0.011912362140719779,0.012118275721149985,0.011900245539436582,0.011928200510737952,0.011988005622697528,0.01181413647645968,0.01135663980312529,0.011452834336523665,0.0117440993017226,0.013885070173273562,0.013973204386275029,0.014028360670636175,0.014254150435590418,0.014311234426713781,0.0142550852142449,0.01426064464249066,0.014017893550771987,0.014112633416516474,0.014269655537646031,0.014182457318383968,0.012532281045423588,0.013391588483500527,0.013466836313455133,0.013358702923142118,0.011811665473942412,0.011804689795098966,0.011680496882036095,0.011720630147465272,0.01181623291267897,0.011933291996683693,0.010418368899991037,0.010367966711783083,0.01066155179796624,0.010605463987303665,0.010624115759128472,0.010552984236710472,0.010388581384177087,0.010431445036374498,0.010247067839372903,0.010114032804267481,0.009891751484246925,0.009211433964082971,0.009261137805879116,0.009821158484555781,0.009633060239139013,0.011092942222603597,0.011234435260121245,0.011260427076194901,0.01105608756915899,0.010980549523083027,0.010841442555829417,0.010726828993938398,0.010604941315250471,0.009707517325296067,0.009558996593113989,0.011330667955917306,0.011328525688441005,0.011284189109574072,0.01122733481315663,0.011217761879379395,0.01107298244460253,0.01102217875450151,0.011028933680790942,0.011116957612102851,0.012654137011850253,0.012501419740146957,0.012460057740099728,0.012402296939399093,0.012510608154116198,0.012521536722488236,0.012507167703006417,0.012485708357417025,0.01238543848739937,0.010920721440925263,0.010925090173259377,0.012203098216559738,0.013864167456631549,0.01237929101625923,0.01257819077000022,0.012698615057161078,0.011603035061853006,0.011730590529623441,0.011637863994110376,0.011601214893744327,0.013098654286295641,0.01310251642280491,0.013154094114725012,0.0113739839871414,0.011397353671782184,0.011410870429244824,0.011462413014669437,0.01140679714444559,0.011327715521474602,0.011208779793378199,0.011250003739405656,0.01120056394211133,0.00939327120067901,0.0094035590554995,0.009363746354210889,0.009297930657339748,0.009202099245158024,0.009269670736102853,0.009268351815990172,0.010761843150248751,0.012506850835052319,0.012395266385283321,0.012375190053717233,0.010498249735974241,0.00888560800376581,0.008973592841357458,0.008650798197777476,0.008477652299916372,0.008171523077180609,0.008010843434021808,0.008011429235921241,0.007973483690875582,0.00835805460519623,0.008337941850186326,0.008392909017857164,0.00839625336084282,0.00836165117652854,0.008371289804927073,0.009287557113566436,0.009275363248889334,0.00937837440505973,0.009399822967679938,0.00945761274851975,0.009438319484615931,0.009396541328897001,0.009704913729365217,0.009702392202598276,0.009764690097654238,0.009747027710545808,0.009629740576201584,0.009634629175707232,0.00811930049530929,0.006313521349511575,0.006300248449406354,0.0061487880630011205,0.0061463713900593575,0.006052915305190254,0.005907297185331117,0.005884430298465304,0.007563371247670148,0.00745603761242819,0.00747541315286071,0.007572737977170618,0.007594799182697898,0.005736256000091089,0.005744603335188003,0.005643052092636935,0.005608956700598355,0.0073502281520632096,0.007334390465985052,0.006375681245117448,0.006376125071255956,0.006314387996098958,0.006286311778239906,0.0061946412024553865,0.0061868584307376295,0.006152855079562869,0.0073898346672649495,0.007332488847168861,0.007298125510715181,0.0072848673262342345,0.007342463006352773,0.00736701461210032,0.00735377205273835,0.007420984060445335,0.009440314814128214,0.009478432290052297,0.009545137760142097,0.009594523959094658,0.00956068751111161,0.009564486936142202,0.00789387192344293,0.007944785353174666,0.007939234896184644,0.007858326058340026,0.007822222793038236,0.007805790581187466,0.007777590846671956,0.007902630713942926,0.007916377064248081,0.006121074206021149,0.006218970251211431,0.006216861460416112,0.006221548974281177,0.00810836903838208,0.009881276906526182,0.009826688576140441,0.009844026993960142,0.009939842988387682,0.008450336405076087,0.009148891080258181,0.009190924425638514,0.009299033266870538,0.009248397047485923,0.010688715232390678,0.010695494638639502,0.01062480077962391,0.008653926743136253,0.008621119006420486,0.008506029058480635,0.008503632467181887,0.008524484910594765,0.008741901598114055,0.008775731228524819,0.008745317987632006,0.008728996675927192,0.008690193615620956,0.00872158908896381,0.008660166742629372,0.008778164839895908,0.008674668464664137,0.008680662056576693,0.008720503992662998,0.008591690380853834,0.008601257632108172,0.00857300370989833,0.0072330822731601074,0.005413365151980543,0.005438564332507667,0.005429908780570258,0.005353610036763712,0.005256467860817793,0.0062876336869521765,0.006205252871950506,0.006058110609956202,0.006047791315722861,0.0045852856510464335,0.004579520022161887,0.004594672829625779,0.004529011830527452,0.0045956346239108825,0.004573522581267753,0.0045239389892230975,0.004515777416600031,0.004277991452909191,0.004209281347357319,0.004190951558484812,0.0041966556400439,0.0041692241156852106,0.004104319939870038,0.004141691353652277,0.005706398844267824,0.005727489688069909,0.00568706646845385,0.007191003240222926,0.007198836041425238,0.007195199619673076,0.007215742663902347,0.006700823762002983,0.006851352940429933,0.006821559920354048,0.008176769657438854,0.008156660289387219,0.008193014560674783,0.006463950610850588,0.006475963318735012,0.006676503047856386,0.006690180269288248,0.006671739107332542,0.006672823432381847,0.006633759743635892,0.0066451989969209535,0.006567755530340946,0.008303792745209648,0.008362762649994693,0.008399283809922053,0.00840052461171581,0.01020260488621716,0.0116852035807824,0.013218305257396423,0.013324621913852752,0.013368633417485398,0.013556851316025131,0.012178027167465189,0.01221618367890187,0.012305423946600058,0.010918020236204029,0.010961719877741416,0.011046328401789651,0.011210438033231185,0.011178039350852487,0.011139725496832398,0.011196896170076798,0.009847537088717218,0.00988689334008086,0.009861429634838714,0.009898587934003444,0.009913375935866497,0.009746162031660788,0.009796273203392047,0.011547361784323584,0.01153501340377261,0.011658808136417065,0.011704588774591684,0.011708657406416023,0.010004515806940617,0.00997323662522831,0.011704754393576877,0.011716930195689201,0.009930322776199318,0.009546133587718941,0.007992181224835804,0.007942656473460374,0.0079082344454946,0.0077217011275934055,0.007399201989755966,0.007337056133110309,0.00725179279470467,0.007198716590210097,0.007155452065489953,0.007061791253363481,0.006941829542483902,0.006965819116885541,0.006864862607471878,0.0068879698555974755,0.006901917466166196,0.00692061221707263,0.006916589831234887,0.006962108134757727,0.0069644151808461174,0.006923359011125285,0.006876062696392182,0.005088260390039068,0.0051147563208360225,0.006642421605647542,0.006590742690605111,0.006588638701941818,0.008221374984714203,0.00957209007901838,0.007821024650183972,0.007829883150407113,0.007927636470412835,0.006870122568216175,0.006892949942994164,0.006878648066049209,0.006874157850688789,0.006869627974083414,0.006885301812872058,0.006911451986525208,0.006972798058995977,0.008878181863110512,0.008862233484251192,0.00881451323220972,0.009824219159781933,0.009761217112099985,0.009808220664126566,0.00977451924336492,0.011217558192583965,0.011180279343534494,0.011175001080118818,0.01115199398554978,0.011169471341418102,0.011282530635071453,0.011332571870298125,0.011368151743226917,0.01134810526491492,0.009686669567599893,0.009685662647825666,0.009740778372361092,0.008104716969683068,0.0067389723590167705,0.006672307457847637,0.006619826737733092,0.006565608266100753,0.006536368913657498,0.006531795326736756,0.006588198673853185,0.006610166357859271,0.006567562097188784,0.00655522819943144,0.006539309597428655,0.006479367897554766,0.006163345584354829,0.006148877811938291,0.007684838965360541,0.007335490379773546,0.007438447490130784,0.007396576129394816,0.007394906369881937,0.005889436120924074,0.007607162406202406,0.007645200170372846,0.007624929865414742,0.007668049816857092,0.007577611213491764,0.007495005742384819,0.007506862799345981,0.007526163972215727,0.009345637659862405,0.009368290779093513,0.009324041489890078,0.010913919304584851,0.01086570024381217,0.010891282287047943,0.01092336164401786,0.010896633908487274,0.012094088704543537,0.012090459176761215,0.013303738147442346,0.013269157896502293,0.014333822657135897,0.014970080397688434,0.015127459695577272,0.015262997721947613,0.013889551262764144,0.01527995735341392,0.014117146229182254,0.013429979770080536,0.013360438801100827,0.013436558312605484,0.01344480573425244,0.013457822429700173,0.011822048492831527,0.011897052439962863,0.013802890660372213,0.013775658031590865,0.013813709347232361,0.01381593823498406,0.013801102855723002,0.01387904137118312,0.012123374932343722,0.01209127967194945,0.012155868282206939,0.010575928254183964,0.010646364538843045,0.010662150230928091,0.010692661457142094,0.010670596642739838,0.009464166821999243,0.009482344983553048,0.008178335170669015,0.00818779002656811,0.007157132189604454,0.00657030385627877,0.0064347558000008576,0.006322972069028765,0.006021238674293272,0.004617934795533074,0.00428406487844768,0.0042904904221359175,0.00426231995515991,0.004271015277481638,0.0042497102040215395,0.00425279589035199,0.0041974821251642425,0.004069851609528996,0.002178530798119027,0.00212098705014796,0.002078867419186281,0.00206504499874427,0.0020435453261598013,0.0033313546955469064,0.003318743511044886,0.0033058171466109343,0.0032405326564912684,0.0032164551594178192,0.0031663484624004923,0.0031416717101819813,0.003087356912146788,0.004772782573127188,0.004766436584759504,0.004737715236842632,0.004797827823495027,0.004813914423721144,0.006117548145994078,0.006100758313550614,0.0077250881513464265,0.007689502188441111,0.0076584302660194226,0.010927143808658002,0.010912965994066326,0.011008548975951271,0.011054082962800749,0.011033749877242371,0.01102547474874882,0.01109034196997527,0.011031421901861904,0.011097468486696016,0.012659577594604343,0.01274367257792619,0.0127163663655665,0.012724376285405015,0.01277355976162653,0.011380738609659602,0.01145223902312864,0.011480076131192618,0.011506695025673253,0.0115266207667446,0.013179045296055847,0.013196737150792615,0.01324061733794224,0.011773893684221548,0.011755904952224228,0.011755301920857164,0.011702961170158233,0.011930734230190865,0.010649892623405322,0.010705728620450827,0.009034907850946183,0.009041774328579777,0.009042485631653108,0.005812959570903331,0.005804823373182444,0.005689368506864412,0.0056502029292460065,0.005588570336840348,0.0055703550642647315,0.005496038003911963,0.005536889817449264,0.005484804740262916,0.003912050826329505,0.005581023458944401,0.005792073779957718,0.005796584455310949,0.005800525783342891,0.005842761840540334,0.007109217613106011,0.007122156164768967,0.008568720817493158,0.008525948092938052,0.0068597545814554906,0.00686316396422626,0.006818197967731976,0.006589390823137364,0.006593304164198344,0.006574354390977533,0.006547009654241265,0.006304232147158473,0.006356591058647609,0.006262786355364369,0.006243026982701849,0.006237114059331361,0.0062504840989277,0.006363515329212532,0.006453928899645689,0.006458721929448075,0.006446854740715935,0.006432025673348107,0.006433651167753851,0.006441562818508828,0.006394022413587663,0.006408877499779919,0.006377344649081351,0.00462920682184631,0.0044365064313751645,0.004441197852429468,0.004395033978653373,0.004380730348202633,0.0030277755540737417,0.0045677681009692606,0.0030929127642593812,0.0031184367871901486,0.0031241458091244567,0.004610813466570107,0.004685844389314298,0.005114962052175542,0.005107253193273209,0.005253948176687118,0.005293827009154484,0.0053559280386252794,0.0067529837288020644,0.00674678095492709,0.0068026952521904605,0.006808581261793734,0.006798533537221374,0.006655485816736473,0.006572519017936429,0.0065743397681217175,0.006624957368330797,0.006635423400439322,0.00663764073033235,0.0066214089492859785,0.006631935109908227,0.006643985369009897,0.006680364633211866,0.006690241436444921,0.006673113972283318,0.0066648012416408164,0.006672617959338822,0.006643504451858462,0.006634389546888997,0.005078854772364139,0.005072495236163377,0.005075725892311311,0.006796852636398398,0.005317590688719065,0.0070264814949041465,0.0067600303245853866,0.006756421340469387,0.006620723828746122,0.006600985436307383,0.00659985450511158,0.005129452716573724,0.0051375631392147625,0.00512277049892873,0.005161541057532304,0.005167880477529252,0.00515423475735588,0.005843632367032114,0.005822022652864689,0.005829260004247772,0.005833718492795015,0.005832945824295166,0.005840293300934718,0.005836131893374841,0.0057935104978241725,0.005745151131122839,0.005769154253357556,0.005780014287665836,0.0057710746477823704,0.005796194018330425,0.005815984182845568,0.005788837761429022,0.005776134759798879,0.005791675506770844,0.005764791723777307,0.004061132698552683,0.004044799126859289,0.002293772777193226,0.002110423556587193,0.002154123332729796,0.002137096069418476,0.002168912435081438,0.0037006480797572294,0.0036743491491506575,0.00366276563363499,0.0037889572813583072,0.003743460965779377,0.003762982832995476,0.0037731949414592236,0.003081475333601702,0.00307762625743635,0.0030452849823632278,0.003133041587716434,0.0031836727139307186,0.0031634348270017654,0.0032018091915233526,0.0032055208321253303,0.0032153002775885398,0.004666134404033073,0.004711472111011972,0.004775939756655134,0.004740081229101634,0.005088736274046823,0.005129038077939185,0.005140026089065941,0.005130163419380551,0.005160929933481384,0.005139298473295639,0.005125008263348718,0.005080640266896808,0.00507745252980385,0.005035976708313683,0.0050293014173803385,0.006740883294696687,0.006563889979588566,0.006590070854144869,0.006612197112190188,0.006464563624831499,0.006483632167146425,0.006500187189885764,0.006512700079838396,0.006505826613647514,0.006496945925391628,0.006469068301157677,0.006429846123864991,0.006386525421476108,0.006390559603460133,0.00637028414348606,0.006375965022016317,0.0063710989052196965,0.00487091664399486,0.0048695700315875,0.0068147094279993325,0.0068222789086576086,0.006465926544478862,0.006427291036743554,0.006423607284887112,0.007847715982279624,0.007858772716645035,0.00791226415822166,0.00790648481779499,0.007961443450767547,0.007968952815645025,0.007956287841807352,0.007993614233782864,0.006242131441467791,0.004821175087272422,0.00480166692432249,0.004799171692866366,0.004826026575756259,0.0048218861666100565,0.00483536305182497,0.004851749166846275],\"type\":\"scatter\"},{\"mode\":\"lines\",\"name\":\"Validation mean loss\",\"x\":[0,32,64,96,128,160,192,224,256,288,320,352,384,416,448,480,512,544,576,608,640,672,704,736,768,800,832],\"y\":[0.3218686993900953,0.12322441561517589,0.0672081179746704,0.02969005482779242,0.016361341963092704,0.012249274561493231,0.012421415058323046,0.011901081726208611,0.010580210561810459,0.008839118436344318,0.006907090103825896,0.006869755651727193,0.006821789421160228,0.006791268054646376,0.006953923157190458,0.006544109193480882,0.006263797424260973,0.006562865978477357,0.005864191354197813,0.006371902537817635,0.00590947913905027,0.005858950187599226,0.005816491220405575,0.005221987705702142,0.005268680326412606,0.004953056340252196,0.004957292242824869],\"type\":\"scatter\"}],                        {\"title\":{\"text\":\"Cross-Encoder: Train (per batch) and Validation (per 32 batches) Losses\"},\"xaxis\":{\"title\":{\"text\":\"Batch Number\"}},\"yaxis\":{\"title\":{\"text\":\"Train Loss (SMA)\"}},\"xaxis2\":{\"anchor\":\"y2\",\"overlaying\":\"x\",\"side\":\"top\",\"title\":{\"text\":\"Validation Interval (in Batches)\"}},\"yaxis2\":{\"overlaying\":\"y\",\"side\":\"right\",\"title\":{\"text\":\"Validation Loss\"}},\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"legend\":{\"title\":{\"text\":\"Loss Type\"}},\"height\":600,\"width\":800},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('a059510c-c5e3-4fde-b32b-fd7c9f0f5531');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Сохранение Cross-Encoder в файловую систему"
      ],
      "metadata": {
        "id": "zTHsTs82VPDA"
      },
      "id": "zTHsTs82VPDA"
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(cross_encoder_model.state_dict(), constants.CROSS_ENCODER_MODEL_PATH_AUX)"
      ],
      "metadata": {
        "id": "8JPQzOCyVPgl"
      },
      "id": "8JPQzOCyVPgl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Создание эмбеддингов и индексов на основе обученных моделей (сохранение в файловую систему)"
      ],
      "metadata": {
        "id": "n21oBjx8VoIM"
      },
      "id": "n21oBjx8VoIM"
    },
    {
      "cell_type": "code",
      "source": [
        "target_char_questions_and_answers = load(constants.TARGET_CHAR_PROCESSED_QA_PATH)\n",
        "target_char_answers = load(constants.TARGET_CHAR_PROCESSED_ANSWERS_PATH)\n",
        "\n",
        "chat_service_accelerator = ChatServiceAccelerator(bi_encoder_model, cross_encoder_model, target_char_questions_and_answers, target_char_answers,\n",
        "                 constants, chat_util)\n",
        "\n",
        "training_data_embeddings = chat_service_accelerator.preprocess_training_data_embeddings(target_char_questions_and_answers, path=constants.TARGET_CHAR_QA_PAIRS_EMBEDDINGS_PATH_AUX)\n",
        "chat_service_accelerator.preprocess_answers_embeddings(target_char_answers, path=constants.TARGET_CHAR_ANSWERS_EMBEDDINGS_PATH_AUX)\n",
        "chat_service_accelerator.create_faiss_index(training_data_embeddings, gpu_index=constants.GPU_FAISS_INDEX, path=constants.TARGET_CHAR_QA_PAIRS_FAISS_INDEX_PATH_AUX)\n",
        "chat_service_accelerator.create_faiss_psa_index(training_data_embeddings, gpu_index=constants.GPU_FAISS_INDEX, path=constants.TARGET_CHAR_QA_PAIRS_FAISS_PSA_INDEX_PATH_AUX)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y--0fj-ptkQa",
        "outputId": "9ac29548-940f-43aa-9749-1b69c1be0de4"
      },
      "id": "Y--0fj-ptkQa",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<faiss.swigfaiss_avx2.IndexFlatL2; proxy of <Swig Object of type 'faiss::IndexFlatL2 *' at 0x7b9e220467c0> >"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}